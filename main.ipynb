{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIDbkpD/XURz4VRmbeDCcX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XG0fJzBf8Aq5","colab_type":"code","colab":{}},"source":["# Initial Steps\n","# Don't forget to change the runtime to GPU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uq4rB9Ol8aKl","colab_type":"code","outputId":"9d279edf-4ebe-4903-a859-f0743600dbc2","executionInfo":{"status":"ok","timestamp":1581323605927,"user_tz":-330,"elapsed":43301,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aR1qs30I8aPP","colab_type":"code","colab":{}},"source":["#path \n","import os\n","user_id = 2\n","\n","if user_id==0: # Chirag\n","  os.chdir('/content/drive/My Drive/IIITD_Course/Sem_6/DL/DL_Group/Assignments/Assignment_1')\n","elif user_id==1: # Prakhar\n","  os.chdir('/content/drive/My Drive/IIITD_Course/Sem_6/DL/DL_Group/Assignments/Assignment_1')\n","elif user_id==2: # Akash\n","  os.chdir('/content/drive/My Drive/DL_Group/Assignments/Assignment_1/Datasets/Q3')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7lvb0cz8aF9","colab_type":"code","colab":{}},"source":["#importing libraries\n","\n","import json\n","import csv\n","\n","import collections\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torchvision import transforms\n","from retinanet import model\n","from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n","    Normalizer\n","from torch.utils.data import DataLoader\n","from retinanet import coco_eval\n","from retinanet import csv_eval"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"urMZw_rBiwT4","colab_type":"code","outputId":"a997578f-6245-469d-af9f-17893ab81511","executionInfo":{"status":"ok","timestamp":1581323630683,"user_tz":-330,"elapsed":66381,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["!apt-get install tk-dev python-tk\n","!pip install pycocotools"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n","\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n","\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n","tk-dev is already the newest version (8.6.0+9).\n","python-tk is already the newest version (2.7.17-1~18.04).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nrZ_Vcch8aTv","colab_type":"code","colab":{}},"source":["#cleaning the annotations json file -> removing other classes & invalid bounding box \n","# bounding box dimensions are in int\n","mainIds = [11,6,33,16,3,10,9,5] # IDs of given classes\n","mainClasses = [\"bird\",\"bobcat\",\"car\",\"cat\",\"raccoon\",\"rabbit\",\"coyote\",\"squirrel\"]\n","\n","with open('train_annotations.json') as data_file:    \n","\tdata = json.load(data_file)\n","\t# print(data['categories'])\n","\t# print(data['info'])\n","\t# print(data['images'])\n","\tx=data['annotations']\n","\ty=[]\n","\tfor v in x:\n","\t\t\t\n","\t\t\tif(v['category_id'] in mainIds):\n","\t\t\t\tclasss=mainClasses[mainIds.index(v['category_id'])]\n","\t\t\t\tpathe=\"train/\"+classs+\"/\"+v['image_id']+\".jpg\"\n","\t\t\t\ta=True\n","\t\t\t\ttry:\n","\t\t\t\t\tqq=v['bbox']\n","\t\t\t\texcept:\n","\t\t\t\t\ta=False\n","\t\t\t\tif(a==True):\n","\t\t\t\t\tif(int(v['bbox'][2])>int(v['bbox'][0])):\n","\t\t\t\t\t\tif(int(v['bbox'][3])>int(v['bbox'][1])):\n","\t\t\t\t\t\t\tff=[pathe,int(v['bbox'][0]),int(v['bbox'][1]),int(v['bbox'][2]),int(v['bbox'][3]),classs]\n","\t\t\t\t\t\tif(int(v['bbox'][3])==int(v['bbox'][1])):\n","\t\t\t\t\t\t\ta=True\n","\t\t\t\t\t\tif(int(v['bbox'][3])<int(v['bbox'][1])):\n","\t\t\t\t\t\t\tff=[pathe,int(v['bbox'][0]),int(v['bbox'][3]),int(v['bbox'][2]),int(v['bbox'][1]),classs]\n","\t\t\t\t\tif(int(v['bbox'][2])==int(v['bbox'][0])):\n","\t\t\t\t\t\ta=True\n","\t\t\t\t\tif(int(v['bbox'][2])<int(v['bbox'][0])):\n","\t\t\t\t\t\tif(int(v['bbox'][3])>int(v['bbox'][1])):\n","\t\t\t\t\t\t\tff=[pathe,int(v['bbox'][2]),int(v['bbox'][1]),int(v['bbox'][0]),int(v['bbox'][3]),classs]\n","\t\t\t\t\t\tif(int(v['bbox'][3])==int(v['bbox'][1])):\n","\t\t\t\t\t\t\ta=True\n","\t\t\t\t\t\tif(int(v['bbox'][3])<int(v['bbox'][1])):\n","\t\t\t\t\t\t\tff=[pathe,int(v['bbox'][2]),int(v['bbox'][3]),int(v['bbox'][0]),int(v['bbox'][1]),classs]\n","\t\t\t\t\ty.append(ff)\n","\t# print(y)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFEVC-GOE1CS","colab_type":"code","outputId":"229bffd0-f7ce-48ce-890d-6fa72639913a","executionInfo":{"status":"ok","timestamp":1581323648558,"user_tz":-330,"elapsed":83902,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# cleaning the dataset- taking data points which have the images\n","from os import listdir\n","from os.path import isfile, join\n","birdfiles = [f for f in listdir(\"train/bird\") if isfile(join(\"train/bird\", f))]\n","rabbitfiles = [f for f in listdir(\"train/rabbit\") if isfile(join(\"train/rabbit\", f))]\n","raccoonfiles = [f for f in listdir(\"train/raccoon\") if isfile(join(\"train/raccoon\", f))]\n","bobcatfiles = [f for f in listdir(\"train/bobcat\") if isfile(join(\"train/bobcat\", f))]\n","carfiles = [f for f in listdir(\"train/car\") if isfile(join(\"train/car\", f))]\n","catfiles = [f for f in listdir(\"train/cat\") if isfile(join(\"train/cat\", f))]\n","coyotefiles = [f for f in listdir(\"train/coyote\") if isfile(join(\"train/coyote\", f))]\n","squirrelfiles = [f for f in listdir(\"train/squirrel\") if isfile(join(\"train/squirrel\", f))]\n","\n","yy=[]\n","for v in y:\n","  if(v[5]==\"bird\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in birdfiles):\n","      yy.append(v)\n","  if(v[5]==\"rabbit\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in rabbitfiles):\n","      yy.append(v)\n","  if(v[5]==\"raccoon\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in raccoonfiles):\n","      yy.append(v)\n","  if(v[5]==\"bobcat\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in bobcatfiles):\n","      yy.append(v)\n","  if(v[5]==\"car\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in carfiles):\n","      yy.append(v)\n","  if(v[5]==\"cat\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in catfiles):\n","      yy.append(v)\n","  if(v[5]==\"coyote\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in coyotefiles):\n","      yy.append(v)\n","  if(v[5]==\"squirrel\"):\n","    lak=v[0].split('/')\n","    if(lak[-1] in squirrelfiles):\n","      yy.append(v)\n","print(len(y))\n","print(len(yy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["8798\n","2105\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zKsY856uwlws","colab_type":"code","outputId":"3709229a-8315-4030-ed23-2a929d3f0491","executionInfo":{"status":"ok","timestamp":1581323648560,"user_tz":-330,"elapsed":83689,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(birdfiles)+len(squirrelfiles)+len(coyotefiles)+len(catfiles)+len(carfiles)+len(bobcatfiles)+len(raccoonfiles)+len(rabbitfiles))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1969\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kk4Jin7pw9HR","colab_type":"code","outputId":"cfcadc30-3760-4e9b-f63a-262b4fec005e","executionInfo":{"status":"ok","timestamp":1581323650178,"user_tz":-330,"elapsed":85163,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["# creating csv files for training as per the standards set by the precoded model \n","filename=\"annotations.csv\"\n","with open(filename, 'w') as csvfile: \n","    csvwriter = csv.writer(csvfile)  \n","    csvwriter.writerows(yy)\n","\n","# bird,11\n","# bobcat,6\n","# car,33\n","# cat,16\n","# raccoon,3\n","# rabbit,10\n","# coyote,9\n","# squirrel,5\n","\n","rows=[]\n","a=0\n","for i in range(len(mainIds)):\n","  rows.append([mainClasses[i],a])\n","  a+=1\n","\n","print(rows)\n","filename=\"classes.csv\"\n","with open(filename, 'w') as csvfile: \n","    csvwriter = csv.writer(csvfile)  \n","    csvwriter.writerows(rows)\n","\n","\n","## splitting train validation set\n","a0=[]\n","a1=[]\n","a2=[]\n","a3=[]\n","a4=[]\n","a5=[]\n","a6=[]\n","a7=[]\n","\n","for i in yy:\n","  if(i[5]=='car'):\n","    a2.append(i)\n","  if(i[5]=='cat'):\n","    a3.append(i)\n","  if(i[5]=='bobcat'):\n","    a1.append(i)\n","  if(i[5]=='squirrel'):\n","    a7.append(i)\n","  if(i[5]=='raccoon'):\n","    a4.append(i)\n","  if(i[5]=='rabbit'):\n","    a5.append(i)\n","  if(i[5]=='coyote'):\n","    a6.append(i)\n","  if(i[5]=='bird'):\n","    a0.append(i)\n","\n","yyy_train=[]\n","yyy_val=[]\n","yyy_train+=a1[:(80*len(a1)//100)+1]\n","yyy_val+=a1[(80*len(a1)//100)+1:]\n","yyy_train+=a2[:(80*len(a2)//100)+1]\n","yyy_val+=a2[(80*len(a2)//100)+1:]\n","yyy_train+=a3[:(80*len(a3)//100)+1]\n","yyy_val+=a3[(80*len(a3)//100)+1:]\n","yyy_train+=a4[:(80*len(a4)//100)+1]\n","yyy_val+=a4[(80*len(a4)//100)+1:]\n","yyy_train+=a5[:(80*len(a5)//100)+1]\n","yyy_val+=a5[(80*len(a5)//100)+1:]\n","yyy_train+=a6[:(80*len(a6)//100)+1]\n","yyy_val+=a6[(80*len(a6)//100)+1:]\n","yyy_train+=a7[:(80*len(a7)//100)+1]\n","yyy_val+=a7[(80*len(a7)//100)+1:]\n","yyy_train+=a0[:(80*len(a0)//100)+1]\n","yyy_val+=a0[(80*len(a0)//100)+1:]\n","\n","filename=\"annotations_train.csv\"\n","with open(filename, 'w') as csvfile: \n","    csvwriter = csv.writer(csvfile)  \n","    csvwriter.writerows(yyy_train)\n","filename=\"annotations_val.csv\"\n","with open(filename, 'w') as csvfile: \n","    csvwriter = csv.writer(csvfile)  \n","    csvwriter.writerows(yyy_val)\n","\n","print(len(yy))\n","print(len(yyy_train))\n","print(len(yyy_val))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[['bird', 0], ['bobcat', 1], ['car', 2], ['cat', 3], ['raccoon', 4], ['rabbit', 5], ['coyote', 6], ['squirrel', 7]]\n","2105\n","1688\n","417\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0RA3Kxlc8aYo","colab_type":"code","outputId":"ee4ee8f1-7519-4090-f41c-9aece3d0e029","executionInfo":{"status":"ok","timestamp":1581323664390,"user_tz":-330,"elapsed":99174,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["retinanet = model.resnet50(num_classes=80, pretrained=True)\n","retinanet.load_state_dict(torch.load('coco_resnet_50_map_0_335_state_dict.pt'))\n","# x=retinanet.state_dict().keys()\n","# print(x)\n","# print(retinanet)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"FOCR7g6pW2Xu","colab_type":"code","outputId":"80d818a8-50dd-4301-9b0e-c1d21532d032","executionInfo":{"status":"ok","timestamp":1581323668446,"user_tz":-330,"elapsed":103028,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[" #modifying last layer of pretrained retinanet and loading weights to retinanet2 \n","retinanet2 = model.resnet50(num_classes=8, pretrained=True)\n","feature_size=256\n","num_anchors=9\n","num_classes=8\n","retinanet.classificationModel.output=nn.Conv2d(feature_size, num_anchors * num_classes, kernel_size=3, padding=1)\n","retinanet.num_classes=8\n","torch.save(retinanet.state_dict(), 'pretrained_weights_after_modifying_last_layer.pt')\n","retinanet2.load_state_dict(torch.load('pretrained_weights_after_modifying_last_layer.pt'))\n","print(retinanet2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (fpn): PyramidFeatures(\n","    (P5_1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (P5_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n","    (P5_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (P4_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (P4_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n","    (P4_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (P3_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (P3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (P6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (P7_1): ReLU()\n","    (P7_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  )\n","  (regressionModel): RegressionModel(\n","    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act1): ReLU()\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act2): ReLU()\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act3): ReLU()\n","    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act4): ReLU()\n","    (output): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (classificationModel): ClassificationModel(\n","    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act1): ReLU()\n","    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act2): ReLU()\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act3): ReLU()\n","    (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (act4): ReLU()\n","    (output): Conv2d(256, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (output_act): Sigmoid()\n","  )\n","  (anchors): Anchors()\n","  (regressBoxes): BBoxTransform()\n","  (clipBoxes): ClipBoxes()\n","  (focalLoss): FocalLoss()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cr1-13bK0NMZ","colab_type":"code","colab":{}},"source":["# print(retinanet.state_dict()['classificationModel.output.weight'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6b0xMIFl0T0C","colab_type":"code","colab":{}},"source":["# print(retinanet2.state_dict()['classificationModel.output.weight'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3e27vs7G8aWl","colab_type":"code","colab":{}},"source":["#random  re-assignment of last layer - evaluation\n","dataset_val = CSVDataset(train_file='annotations_val.csv', class_list='classes.csv',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n","retinanet2 = torch.nn.DataParallel(retinanet2).cuda()\n","retinanet2.training = False\n","retinanet2.eval()\n","retinanet2.module.freeze_bn()\n","# retinanet2.num_classes=8\n","use_gpu = True\n","if use_gpu:\n","    retinanet2 = retinanet2.cuda()\n","mAP = csv_eval.evaluate(dataset_val, retinanet2)\n","print(mAP)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0SpCrMMrSL6","colab_type":"code","outputId":"f0b1ea06-2c48-48ea-e403-92763b3440a6","executionInfo":{"status":"ok","timestamp":1581276589792,"user_tz":-330,"elapsed":3122,"user":{"displayName":"Akash Sharma","photoUrl":"","userId":"17863093696646821487"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# slicing the weights of last layer of retinanet (pretrained) and loading to retinanet3 and \n","retinanet = model.resnet50(num_classes=80, pretrained=True)\n","retinanet.load_state_dict(torch.load('coco_resnet_50_map_0_335_state_dict.pt'))\n","\n","pretrained_dict = retinanet.state_dict()\n","pretrained_dict['classificationModel.output.weight']=retinanet.state_dict()['classificationModel.output.weight'][slice(72)] \n","pretrained_dict['classificationModel.output.bias']=retinanet.state_dict()['classificationModel.output.bias'][slice(72)] \n","\n","\n","retinanet3 = model.resnet50(num_classes=8, pretrained=True)\n","retinanet3.load_state_dict(pretrained_dict)\n","# print(retinanet3.state_dict())\n","\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"_lWVr4wnKWG0","colab_type":"code","colab":{}},"source":["# slicing the weights of last layer of retinanet (pretrained) and loading to retinanet3  - evaluation\n","dataset_val = CSVDataset(train_file='annotations_val.csv', class_list='classes.csv',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n","retinanet3 = torch.nn.DataParallel(retinanet3).cuda()\n","retinanet3.training = False\n","retinanet3.eval()\n","retinanet3.module.freeze_bn()\n","# retinanet2.num_classes=8\n","use_gpu = True\n","if use_gpu:\n","    retinanet3 = retinanet3.cuda()\n","mAP = csv_eval.evaluate(dataset_val, retinanet3)\n","print(mAP)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"64YMHtjA13RW","colab_type":"code","outputId":"81e26b5c-df7d-410e-8adc-c1e575e8fb98","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## training of retinanet_new\n","\n","dataset_train = CSVDataset(train_file='annotations_train.csv', class_list='classes.csv',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n","dataset_val = CSVDataset(train_file='annotations_val.csv', class_list='classes.csv',transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n","sampler = AspectRatioBasedSampler(dataset_train, batch_size=2, drop_last=False)\n","dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)\n","# retinanet - specify model and also change the weights\n","# retinanet_new = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n","#retinanet 2\n","retinanet_new = model.resnet50(num_classes=8, pretrained=True)\n","# retinanet_new.load_state_dict(torch.load('pretrained_weights_after_modifying_last_layer.pt'))\n","retinanet_new=torch.load('retinanet2_9_epochs.pt')\n","# retinanet_new=retinanet3\n","# retinanet_new = model.resnet50(num_classes=8, pretrained=True)\n","# retinanet_new.load_state_dict(pretrained_dict)\n","\n","#freezing of any layer\n","#----\n","\n","\n","use_gpu = True\n","if use_gpu:\n","    retinanet_new = retinanet_new.cuda()\n","\n","retinanet_new = torch.nn.DataParallel(retinanet_new).cuda()\n","retinanet_new.training = True\n","optimizer = optim.Adam(retinanet_new.parameters(), lr=(1e-6))\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n","\n","loss_hist = collections.deque(maxlen=500)\n","\n","retinanet_new.train()\n","retinanet_new.module.freeze_bn()\n","loss_forplot=[]\n","for epoch_num in range(5):\n","\n","    retinanet_new.train()\n","    retinanet_new.module.freeze_bn()\n","\n","    epoch_loss = []\n","\n","    for iter_num, data in enumerate(dataloader_train):\n","        try:\n","            optimizer.zero_grad()\n","\n","            classification_loss, regression_loss = retinanet_new([data['img'].cuda().float(), data['annot']])\n","\n","            classification_loss = classification_loss.mean()\n","            regression_loss = regression_loss.mean()\n","\n","            loss = classification_loss + regression_loss\n","\n","            if bool(loss == 0):\n","                continue\n","\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(retinanet_new.parameters(), 0.1)\n","\n","            optimizer.step()\n","\n","            loss_hist.append(float(loss))\n","\n","            epoch_loss.append(float(loss))\n","\n","            print(\n","                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n","                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n","\n","            del classification_loss\n","            del regression_loss\n","        except Exception as e:\n","            print(e)\n","            continue\n","    print(epoch_num)\n","    print('Evaluating dataset')\n","    retinanet_new.eval()\n","    mAP = csv_eval.evaluate(dataset_val, retinanet_new) \n","    scheduler.step(np.mean(epoch_loss))\n","    loss_forplot.append(np.mean(epoch_loss))\n","    print(np.mean(epoch_loss))\n","    print(\"---------------------------------------\")\n","    torch.save(retinanet_new.module, 'retinanet2_{}_epochs.pt'.format(epoch_num+10))\n","\n","retinanet_new.eval()\n","print(loss_forplot)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0 | Iteration: 0 | Classification loss: 0.09807 | Regression loss: 0.09434 | Running loss: 0.19241\n","Epoch: 0 | Iteration: 1 | Classification loss: 0.08192 | Regression loss: 0.01997 | Running loss: 0.14715\n","Epoch: 0 | Iteration: 2 | Classification loss: 0.17243 | Regression loss: 0.34511 | Running loss: 0.27061\n","Epoch: 0 | Iteration: 3 | Classification loss: 0.14315 | Regression loss: 0.28497 | Running loss: 0.30999\n","Epoch: 0 | Iteration: 4 | Classification loss: 0.01855 | Regression loss: 0.02331 | Running loss: 0.25637\n","Epoch: 0 | Iteration: 5 | Classification loss: 0.00001 | Regression loss: 0.00057 | Running loss: 0.21374\n","Epoch: 0 | Iteration: 6 | Classification loss: 0.35384 | Regression loss: 0.20020 | Running loss: 0.26235\n","Epoch: 0 | Iteration: 7 | Classification loss: 0.23805 | Regression loss: 0.28558 | Running loss: 0.29501\n","Epoch: 0 | Iteration: 8 | Classification loss: 0.09666 | Regression loss: 0.18526 | Running loss: 0.29356\n","Epoch: 0 | Iteration: 9 | Classification loss: 0.21887 | Regression loss: 0.16997 | Running loss: 0.30308\n","Epoch: 0 | Iteration: 10 | Classification loss: 0.00001 | Regression loss: 0.00047 | Running loss: 0.27558\n","Epoch: 0 | Iteration: 11 | Classification loss: 0.29605 | Regression loss: 0.15928 | Running loss: 0.29055\n","Epoch: 0 | Iteration: 12 | Classification loss: 0.19795 | Regression loss: 0.20051 | Running loss: 0.29886\n","Epoch: 0 | Iteration: 13 | Classification loss: 0.27841 | Regression loss: 0.30381 | Running loss: 0.31910\n","Epoch: 0 | Iteration: 14 | Classification loss: 0.00001 | Regression loss: 0.00029 | Running loss: 0.29784\n","Epoch: 0 | Iteration: 15 | Classification loss: 0.16016 | Regression loss: 0.04973 | Running loss: 0.29235\n","Epoch: 0 | Iteration: 16 | Classification loss: 0.25224 | Regression loss: 0.21367 | Running loss: 0.30256\n","Epoch: 0 | Iteration: 17 | Classification loss: 0.17855 | Regression loss: 0.30323 | Running loss: 0.31251\n","Epoch: 0 | Iteration: 18 | Classification loss: 0.17099 | Regression loss: 0.12037 | Running loss: 0.31140\n","Epoch: 0 | Iteration: 19 | Classification loss: 0.13713 | Regression loss: 0.15712 | Running loss: 0.31054\n","Epoch: 0 | Iteration: 20 | Classification loss: 0.13131 | Regression loss: 0.15538 | Running loss: 0.30941\n","Epoch: 0 | Iteration: 21 | Classification loss: 0.24008 | Regression loss: 0.16551 | Running loss: 0.31378\n","Epoch: 0 | Iteration: 22 | Classification loss: 0.20720 | Regression loss: 0.20136 | Running loss: 0.31790\n","Epoch: 0 | Iteration: 23 | Classification loss: 0.29489 | Regression loss: 0.68738 | Running loss: 0.34558\n","Epoch: 0 | Iteration: 24 | Classification loss: 0.27314 | Regression loss: 0.42034 | Running loss: 0.35950\n","Epoch: 0 | Iteration: 25 | Classification loss: 0.16222 | Regression loss: 0.32098 | Running loss: 0.36425\n","Epoch: 0 | Iteration: 26 | Classification loss: 0.22604 | Regression loss: 0.35432 | Running loss: 0.37226\n","Epoch: 0 | Iteration: 27 | Classification loss: 0.02994 | Regression loss: 0.01795 | Running loss: 0.36067\n","Epoch: 0 | Iteration: 28 | Classification loss: 0.44554 | Regression loss: 0.33875 | Running loss: 0.37528\n","Epoch: 0 | Iteration: 29 | Classification loss: 0.34604 | Regression loss: 0.33305 | Running loss: 0.38541\n","Epoch: 0 | Iteration: 30 | Classification loss: 0.06149 | Regression loss: 0.09605 | Running loss: 0.37806\n","Epoch: 0 | Iteration: 31 | Classification loss: 0.11621 | Regression loss: 0.00000 | Running loss: 0.36987\n","Epoch: 0 | Iteration: 32 | Classification loss: 0.08623 | Regression loss: 0.05967 | Running loss: 0.36309\n","Epoch: 0 | Iteration: 33 | Classification loss: 0.00024 | Regression loss: 0.00082 | Running loss: 0.35244\n","Epoch: 0 | Iteration: 34 | Classification loss: 0.16999 | Regression loss: 0.15728 | Running loss: 0.35172\n","Epoch: 0 | Iteration: 35 | Classification loss: 0.46664 | Regression loss: 0.32918 | Running loss: 0.36406\n","Epoch: 0 | Iteration: 36 | Classification loss: 0.00000 | Regression loss: 0.00058 | Running loss: 0.35423\n","Epoch: 0 | Iteration: 37 | Classification loss: 0.00001 | Regression loss: 0.00104 | Running loss: 0.34494\n","Epoch: 0 | Iteration: 38 | Classification loss: 0.34283 | Regression loss: 0.22044 | Running loss: 0.35054\n","Epoch: 0 | Iteration: 39 | Classification loss: 0.09293 | Regression loss: 0.06705 | Running loss: 0.34577\n","Epoch: 0 | Iteration: 40 | Classification loss: 0.13111 | Regression loss: 0.21515 | Running loss: 0.34578\n","Epoch: 0 | Iteration: 41 | Classification loss: 0.08151 | Regression loss: 0.04945 | Running loss: 0.34067\n","Epoch: 0 | Iteration: 42 | Classification loss: 0.22153 | Regression loss: 0.15871 | Running loss: 0.34159\n","Epoch: 0 | Iteration: 43 | Classification loss: 0.33431 | Regression loss: 0.33388 | Running loss: 0.34901\n","Epoch: 0 | Iteration: 44 | Classification loss: 0.21720 | Regression loss: 0.13917 | Running loss: 0.34918\n","Epoch: 0 | Iteration: 45 | Classification loss: 0.00001 | Regression loss: 0.00085 | Running loss: 0.34160\n","Epoch: 0 | Iteration: 46 | Classification loss: 0.09907 | Regression loss: 0.23475 | Running loss: 0.34144\n","Epoch: 0 | Iteration: 47 | Classification loss: 0.30507 | Regression loss: 0.14157 | Running loss: 0.34363\n","Epoch: 0 | Iteration: 48 | Classification loss: 0.00000 | Regression loss: 0.00019 | Running loss: 0.33662\n","Epoch: 0 | Iteration: 49 | Classification loss: 0.04616 | Regression loss: 0.04738 | Running loss: 0.33176\n","Epoch: 0 | Iteration: 50 | Classification loss: 0.32568 | Regression loss: 0.29236 | Running loss: 0.33737\n","Epoch: 0 | Iteration: 51 | Classification loss: 0.15497 | Regression loss: 0.11060 | Running loss: 0.33599\n","Epoch: 0 | Iteration: 52 | Classification loss: 0.33440 | Regression loss: 0.40596 | Running loss: 0.34362\n","Epoch: 0 | Iteration: 53 | Classification loss: 0.23891 | Regression loss: 0.17037 | Running loss: 0.34484\n","Epoch: 0 | Iteration: 54 | Classification loss: 0.36000 | Regression loss: 0.43997 | Running loss: 0.35311\n","Epoch: 0 | Iteration: 55 | Classification loss: 0.05470 | Regression loss: 0.09733 | Running loss: 0.34952\n","Epoch: 0 | Iteration: 56 | Classification loss: 0.08492 | Regression loss: 0.09455 | Running loss: 0.34654\n","Epoch: 0 | Iteration: 57 | Classification loss: 0.00020 | Regression loss: 0.00031 | Running loss: 0.34057\n","Epoch: 0 | Iteration: 58 | Classification loss: 0.08734 | Regression loss: 0.01626 | Running loss: 0.33656\n","Epoch: 0 | Iteration: 59 | Classification loss: 0.16991 | Regression loss: 0.13602 | Running loss: 0.33605\n","Epoch: 0 | Iteration: 60 | Classification loss: 0.28694 | Regression loss: 0.41512 | Running loss: 0.34205\n","Epoch: 0 | Iteration: 61 | Classification loss: 0.00001 | Regression loss: 0.00031 | Running loss: 0.33653\n","Epoch: 0 | Iteration: 62 | Classification loss: 0.00556 | Regression loss: 0.00000 | Running loss: 0.33128\n","Epoch: 0 | Iteration: 63 | Classification loss: 0.00884 | Regression loss: 0.00000 | Running loss: 0.32624\n","Epoch: 0 | Iteration: 64 | Classification loss: 0.12762 | Regression loss: 0.13028 | Running loss: 0.32519\n","Epoch: 0 | Iteration: 65 | Classification loss: 0.00451 | Regression loss: 0.00000 | Running loss: 0.32033\n","Epoch: 0 | Iteration: 66 | Classification loss: 0.33436 | Regression loss: 0.26392 | Running loss: 0.32448\n","Epoch: 0 | Iteration: 67 | Classification loss: 0.00000 | Regression loss: 0.00038 | Running loss: 0.31972\n","Epoch: 0 | Iteration: 68 | Classification loss: 0.20555 | Regression loss: 0.16045 | Running loss: 0.32039\n","Epoch: 0 | Iteration: 69 | Classification loss: 0.13122 | Regression loss: 0.10193 | Running loss: 0.31914\n","Epoch: 0 | Iteration: 70 | Classification loss: 0.32140 | Regression loss: 0.22429 | Running loss: 0.32233\n","Epoch: 0 | Iteration: 71 | Classification loss: 0.00001 | Regression loss: 0.00024 | Running loss: 0.31786\n","Epoch: 0 | Iteration: 72 | Classification loss: 0.42946 | Regression loss: 0.40130 | Running loss: 0.32488\n","Epoch: 0 | Iteration: 73 | Classification loss: 0.20861 | Regression loss: 0.46186 | Running loss: 0.32955\n","Epoch: 0 | Iteration: 74 | Classification loss: 0.12288 | Regression loss: 0.11096 | Running loss: 0.32828\n","Epoch: 0 | Iteration: 75 | Classification loss: 0.00001 | Regression loss: 0.00041 | Running loss: 0.32396\n","Epoch: 0 | Iteration: 76 | Classification loss: 0.14476 | Regression loss: 0.15626 | Running loss: 0.32367\n","Epoch: 0 | Iteration: 77 | Classification loss: 0.26398 | Regression loss: 0.22946 | Running loss: 0.32584\n","Epoch: 0 | Iteration: 78 | Classification loss: 0.11536 | Regression loss: 0.18748 | Running loss: 0.32555\n","Epoch: 0 | Iteration: 79 | Classification loss: 0.14343 | Regression loss: 0.14803 | Running loss: 0.32512\n","Epoch: 0 | Iteration: 80 | Classification loss: 0.29992 | Regression loss: 0.28379 | Running loss: 0.32832\n","Epoch: 0 | Iteration: 81 | Classification loss: 0.00001 | Regression loss: 0.00044 | Running loss: 0.32432\n","Epoch: 0 | Iteration: 82 | Classification loss: 0.15786 | Regression loss: 0.05740 | Running loss: 0.32300\n","Epoch: 0 | Iteration: 83 | Classification loss: 0.71336 | Regression loss: 0.54646 | Running loss: 0.33416\n","Epoch: 0 | Iteration: 84 | Classification loss: 0.14167 | Regression loss: 0.09906 | Running loss: 0.33306\n","Epoch: 0 | Iteration: 85 | Classification loss: 0.06965 | Regression loss: 0.13425 | Running loss: 0.33156\n","Epoch: 0 | Iteration: 86 | Classification loss: 0.00000 | Regression loss: 0.00063 | Running loss: 0.32775\n","Epoch: 0 | Iteration: 87 | Classification loss: 0.16796 | Regression loss: 0.05802 | Running loss: 0.32660\n","Epoch: 0 | Iteration: 88 | Classification loss: 0.11691 | Regression loss: 0.03176 | Running loss: 0.32460\n","Epoch: 0 | Iteration: 89 | Classification loss: 0.32250 | Regression loss: 0.10704 | Running loss: 0.32576\n","Epoch: 0 | Iteration: 90 | Classification loss: 0.00012 | Regression loss: 0.00058 | Running loss: 0.32219\n","Epoch: 0 | Iteration: 91 | Classification loss: 0.10001 | Regression loss: 0.14714 | Running loss: 0.32137\n","Epoch: 0 | Iteration: 92 | Classification loss: 0.56889 | Regression loss: 0.34382 | Running loss: 0.32773\n","Epoch: 0 | Iteration: 93 | Classification loss: 0.28834 | Regression loss: 0.00000 | Running loss: 0.32731\n","Epoch: 0 | Iteration: 94 | Classification loss: 0.27275 | Regression loss: 0.08221 | Running loss: 0.32761\n","Epoch: 0 | Iteration: 95 | Classification loss: 0.00061 | Regression loss: 0.00000 | Running loss: 0.32420\n","Epoch: 0 | Iteration: 96 | Classification loss: 0.22382 | Regression loss: 0.41787 | Running loss: 0.32747\n","Epoch: 0 | Iteration: 97 | Classification loss: 0.18804 | Regression loss: 0.09516 | Running loss: 0.32702\n","Epoch: 0 | Iteration: 98 | Classification loss: 0.14234 | Regression loss: 0.13680 | Running loss: 0.32654\n","Epoch: 0 | Iteration: 99 | Classification loss: 0.41991 | Regression loss: 0.38601 | Running loss: 0.33133\n","Epoch: 0 | Iteration: 100 | Classification loss: 0.45644 | Regression loss: 0.25639 | Running loss: 0.33511\n","Epoch: 0 | Iteration: 101 | Classification loss: 0.44110 | Regression loss: 0.13374 | Running loss: 0.33746\n","Epoch: 0 | Iteration: 102 | Classification loss: 0.31925 | Regression loss: 0.16073 | Running loss: 0.33884\n","Epoch: 0 | Iteration: 103 | Classification loss: 0.00003 | Regression loss: 0.00044 | Running loss: 0.33559\n","Epoch: 0 | Iteration: 104 | Classification loss: 0.05343 | Regression loss: 0.04505 | Running loss: 0.33333\n","Epoch: 0 | Iteration: 105 | Classification loss: 0.26489 | Regression loss: 0.34034 | Running loss: 0.33590\n","Epoch: 0 | Iteration: 106 | Classification loss: 0.00000 | Regression loss: 0.00076 | Running loss: 0.33276\n","Epoch: 0 | Iteration: 107 | Classification loss: 0.02286 | Regression loss: 0.00000 | Running loss: 0.32989\n","Epoch: 0 | Iteration: 108 | Classification loss: 0.08567 | Regression loss: 0.09276 | Running loss: 0.32850\n","Epoch: 0 | Iteration: 109 | Classification loss: 0.09531 | Regression loss: 0.06497 | Running loss: 0.32697\n","Epoch: 0 | Iteration: 110 | Classification loss: 0.07548 | Regression loss: 0.30178 | Running loss: 0.32743\n","Epoch: 0 | Iteration: 111 | Classification loss: 0.00000 | Regression loss: 0.00086 | Running loss: 0.32451\n","Epoch: 0 | Iteration: 112 | Classification loss: 0.38568 | Regression loss: 0.22776 | Running loss: 0.32707\n","Epoch: 0 | Iteration: 113 | Classification loss: 0.32622 | Regression loss: 0.10881 | Running loss: 0.32802\n","Epoch: 0 | Iteration: 114 | Classification loss: 0.25184 | Regression loss: 0.31992 | Running loss: 0.33014\n","Epoch: 0 | Iteration: 115 | Classification loss: 0.29311 | Regression loss: 0.24664 | Running loss: 0.33194\n","Epoch: 0 | Iteration: 116 | Classification loss: 0.44466 | Regression loss: 0.36633 | Running loss: 0.33604\n","Epoch: 0 | Iteration: 117 | Classification loss: 0.00000 | Regression loss: 0.00029 | Running loss: 0.33319\n","Epoch: 0 | Iteration: 118 | Classification loss: 0.00001 | Regression loss: 0.00035 | Running loss: 0.33039\n","Epoch: 0 | Iteration: 119 | Classification loss: 0.50617 | Regression loss: 0.09551 | Running loss: 0.33266\n","Epoch: 0 | Iteration: 120 | Classification loss: 0.30089 | Regression loss: 0.28644 | Running loss: 0.33476\n","Epoch: 0 | Iteration: 121 | Classification loss: 0.08876 | Regression loss: 0.06255 | Running loss: 0.33326\n","Epoch: 0 | Iteration: 122 | Classification loss: 0.12861 | Regression loss: 0.07971 | Running loss: 0.33224\n","Epoch: 0 | Iteration: 123 | Classification loss: 0.43374 | Regression loss: 0.48161 | Running loss: 0.33694\n","Epoch: 0 | Iteration: 124 | Classification loss: 0.38360 | Regression loss: 0.25639 | Running loss: 0.33937\n","Epoch: 0 | Iteration: 125 | Classification loss: 0.27625 | Regression loss: 0.09580 | Running loss: 0.33963\n","Epoch: 0 | Iteration: 126 | Classification loss: 0.14594 | Regression loss: 0.17664 | Running loss: 0.33949\n","Epoch: 0 | Iteration: 127 | Classification loss: 0.17908 | Regression loss: 0.32785 | Running loss: 0.34080\n","Epoch: 0 | Iteration: 128 | Classification loss: 0.12450 | Regression loss: 0.06866 | Running loss: 0.33966\n","Epoch: 0 | Iteration: 129 | Classification loss: 0.13190 | Regression loss: 0.07153 | Running loss: 0.33861\n","Epoch: 0 | Iteration: 130 | Classification loss: 0.00009 | Regression loss: 0.00023 | Running loss: 0.33603\n","Epoch: 0 | Iteration: 131 | Classification loss: 0.39593 | Regression loss: 0.33686 | Running loss: 0.33903\n","Epoch: 0 | Iteration: 132 | Classification loss: 0.28631 | Regression loss: 0.17766 | Running loss: 0.33997\n","Epoch: 0 | Iteration: 133 | Classification loss: 0.33455 | Regression loss: 0.61814 | Running loss: 0.34454\n","Epoch: 0 | Iteration: 134 | Classification loss: 0.15460 | Regression loss: 0.10580 | Running loss: 0.34392\n","Epoch: 0 | Iteration: 135 | Classification loss: 0.19166 | Regression loss: 0.33738 | Running loss: 0.34528\n","Epoch: 0 | Iteration: 136 | Classification loss: 0.29750 | Regression loss: 0.13136 | Running loss: 0.34589\n","Epoch: 0 | Iteration: 137 | Classification loss: 0.15396 | Regression loss: 0.10180 | Running loss: 0.34524\n","Epoch: 0 | Iteration: 138 | Classification loss: 0.39784 | Regression loss: 0.17509 | Running loss: 0.34688\n","Epoch: 0 | Iteration: 139 | Classification loss: 0.22678 | Regression loss: 0.22448 | Running loss: 0.34762\n","Epoch: 0 | Iteration: 140 | Classification loss: 0.11606 | Regression loss: 0.17686 | Running loss: 0.34723\n","Epoch: 0 | Iteration: 141 | Classification loss: 0.00001 | Regression loss: 0.00096 | Running loss: 0.34480\n","Epoch: 0 | Iteration: 142 | Classification loss: 0.28059 | Regression loss: 0.07393 | Running loss: 0.34486\n","Epoch: 0 | Iteration: 143 | Classification loss: 0.28164 | Regression loss: 0.38186 | Running loss: 0.34708\n","Epoch: 0 | Iteration: 144 | Classification loss: 0.39487 | Regression loss: 0.40465 | Running loss: 0.35020\n","Epoch: 0 | Iteration: 145 | Classification loss: 0.18845 | Regression loss: 0.08404 | Running loss: 0.34966\n","Epoch: 0 | Iteration: 146 | Classification loss: 0.00162 | Regression loss: 0.00000 | Running loss: 0.34730\n","Epoch: 0 | Iteration: 147 | Classification loss: 0.33664 | Regression loss: 0.08643 | Running loss: 0.34781\n","Epoch: 0 | Iteration: 148 | Classification loss: 0.24625 | Regression loss: 0.19578 | Running loss: 0.34844\n","Epoch: 0 | Iteration: 149 | Classification loss: 0.34493 | Regression loss: 0.22625 | Running loss: 0.34993\n","Epoch: 0 | Iteration: 150 | Classification loss: 0.16496 | Regression loss: 0.10996 | Running loss: 0.34943\n","Epoch: 0 | Iteration: 151 | Classification loss: 0.18591 | Regression loss: 0.20184 | Running loss: 0.34968\n","Epoch: 0 | Iteration: 152 | Classification loss: 0.02315 | Regression loss: 0.01706 | Running loss: 0.34766\n","Epoch: 0 | Iteration: 153 | Classification loss: 0.64810 | Regression loss: 0.19033 | Running loss: 0.35085\n","Epoch: 0 | Iteration: 154 | Classification loss: 0.38928 | Regression loss: 0.30174 | Running loss: 0.35304\n","Epoch: 0 | Iteration: 155 | Classification loss: 1.04011 | Regression loss: 0.00000 | Running loss: 0.35744\n","Epoch: 0 | Iteration: 156 | Classification loss: 0.00002 | Regression loss: 0.00104 | Running loss: 0.35517\n","Epoch: 0 | Iteration: 157 | Classification loss: 0.28464 | Regression loss: 0.41978 | Running loss: 0.35739\n","Epoch: 0 | Iteration: 158 | Classification loss: 0.26261 | Regression loss: 0.17325 | Running loss: 0.35788\n","Epoch: 0 | Iteration: 159 | Classification loss: 0.30016 | Regression loss: 0.24239 | Running loss: 0.35903\n","Epoch: 0 | Iteration: 160 | Classification loss: 0.23262 | Regression loss: 0.37014 | Running loss: 0.36055\n","Epoch: 0 | Iteration: 161 | Classification loss: 0.19762 | Regression loss: 0.16528 | Running loss: 0.36056\n","Epoch: 0 | Iteration: 162 | Classification loss: 0.00000 | Regression loss: 0.00049 | Running loss: 0.35835\n","Epoch: 0 | Iteration: 163 | Classification loss: 0.36681 | Regression loss: 0.20854 | Running loss: 0.35968\n","Epoch: 0 | Iteration: 164 | Classification loss: 0.30010 | Regression loss: 0.28426 | Running loss: 0.36104\n","Epoch: 0 | Iteration: 165 | Classification loss: 0.14804 | Regression loss: 0.45732 | Running loss: 0.36251\n","Epoch: 0 | Iteration: 166 | Classification loss: 0.26861 | Regression loss: 0.19800 | Running loss: 0.36313\n","Epoch: 0 | Iteration: 167 | Classification loss: 0.10472 | Regression loss: 0.24294 | Running loss: 0.36304\n","Epoch: 0 | Iteration: 168 | Classification loss: 0.22300 | Regression loss: 0.18518 | Running loss: 0.36331\n","Epoch: 0 | Iteration: 169 | Classification loss: 0.16870 | Regression loss: 0.03984 | Running loss: 0.36240\n","Epoch: 0 | Iteration: 170 | Classification loss: 0.27035 | Regression loss: 0.10175 | Running loss: 0.36245\n","Epoch: 0 | Iteration: 171 | Classification loss: 0.23874 | Regression loss: 0.10093 | Running loss: 0.36232\n","Epoch: 0 | Iteration: 172 | Classification loss: 0.22286 | Regression loss: 0.46931 | Running loss: 0.36423\n","Epoch: 0 | Iteration: 173 | Classification loss: 0.24471 | Regression loss: 0.27893 | Running loss: 0.36514\n","Epoch: 0 | Iteration: 174 | Classification loss: 0.20163 | Regression loss: 0.00000 | Running loss: 0.36421\n","Epoch: 0 | Iteration: 175 | Classification loss: 0.00001 | Regression loss: 0.00068 | Running loss: 0.36214\n","Epoch: 0 | Iteration: 176 | Classification loss: 0.18069 | Regression loss: 0.11359 | Running loss: 0.36176\n","Epoch: 0 | Iteration: 177 | Classification loss: 0.13748 | Regression loss: 0.10507 | Running loss: 0.36109\n","Epoch: 0 | Iteration: 178 | Classification loss: 0.42334 | Regression loss: 0.25642 | Running loss: 0.36287\n","Epoch: 0 | Iteration: 179 | Classification loss: 0.14924 | Regression loss: 0.26699 | Running loss: 0.36317\n","Epoch: 0 | Iteration: 180 | Classification loss: 0.20854 | Regression loss: 0.21926 | Running loss: 0.36352\n","Epoch: 0 | Iteration: 181 | Classification loss: 0.16397 | Regression loss: 0.15857 | Running loss: 0.36330\n","Epoch: 0 | Iteration: 182 | Classification loss: 0.12186 | Regression loss: 0.10738 | Running loss: 0.36257\n","Epoch: 0 | Iteration: 183 | Classification loss: 0.31686 | Regression loss: 0.07745 | Running loss: 0.36274\n","Epoch: 0 | Iteration: 184 | Classification loss: 0.35796 | Regression loss: 0.31615 | Running loss: 0.36442\n","Epoch: 0 | Iteration: 185 | Classification loss: 0.17526 | Regression loss: 0.25581 | Running loss: 0.36478\n","Epoch: 0 | Iteration: 186 | Classification loss: 0.34671 | Regression loss: 0.40579 | Running loss: 0.36685\n","Epoch: 0 | Iteration: 187 | Classification loss: 0.06041 | Regression loss: 0.09747 | Running loss: 0.36574\n","Epoch: 0 | Iteration: 188 | Classification loss: 0.31321 | Regression loss: 0.24004 | Running loss: 0.36673\n","Epoch: 0 | Iteration: 189 | Classification loss: 0.00000 | Regression loss: 0.00018 | Running loss: 0.36481\n","Epoch: 0 | Iteration: 190 | Classification loss: 0.09770 | Regression loss: 0.16473 | Running loss: 0.36427\n","Epoch: 0 | Iteration: 191 | Classification loss: 0.10952 | Regression loss: 0.16422 | Running loss: 0.36380\n","Epoch: 0 | Iteration: 192 | Classification loss: 0.00017 | Regression loss: 0.00029 | Running loss: 0.36192\n","Epoch: 0 | Iteration: 193 | Classification loss: 0.16745 | Regression loss: 0.14529 | Running loss: 0.36166\n","Epoch: 0 | Iteration: 194 | Classification loss: 0.13567 | Regression loss: 0.13823 | Running loss: 0.36121\n","Epoch: 0 | Iteration: 195 | Classification loss: 0.30572 | Regression loss: 0.18835 | Running loss: 0.36189\n","Epoch: 0 | Iteration: 196 | Classification loss: 0.00002 | Regression loss: 0.00024 | Running loss: 0.36005\n","Epoch: 0 | Iteration: 197 | Classification loss: 0.44327 | Regression loss: 0.69315 | Running loss: 0.36398\n","Epoch: 0 | Iteration: 198 | Classification loss: 0.12358 | Regression loss: 0.08907 | Running loss: 0.36322\n","Epoch: 0 | Iteration: 199 | Classification loss: 0.10084 | Regression loss: 0.04056 | Running loss: 0.36211\n","Epoch: 0 | Iteration: 200 | Classification loss: 0.09039 | Regression loss: 0.14786 | Running loss: 0.36149\n","Epoch: 0 | Iteration: 201 | Classification loss: 0.13480 | Regression loss: 0.08041 | Running loss: 0.36077\n","Epoch: 0 | Iteration: 202 | Classification loss: 0.17483 | Regression loss: 0.11946 | Running loss: 0.36044\n","Epoch: 0 | Iteration: 203 | Classification loss: 0.25628 | Regression loss: 0.28996 | Running loss: 0.36135\n","Epoch: 0 | Iteration: 204 | Classification loss: 0.05160 | Regression loss: 0.08121 | Running loss: 0.36023\n","Epoch: 0 | Iteration: 205 | Classification loss: 0.08208 | Regression loss: 0.09725 | Running loss: 0.35936\n","Epoch: 0 | Iteration: 206 | Classification loss: 0.36939 | Regression loss: 0.35749 | Running loss: 0.36113\n","Epoch: 0 | Iteration: 207 | Classification loss: 0.47266 | Regression loss: 0.29833 | Running loss: 0.36310\n","Epoch: 0 | Iteration: 208 | Classification loss: 0.00001 | Regression loss: 0.00033 | Running loss: 0.36137\n","Epoch: 0 | Iteration: 209 | Classification loss: 0.21165 | Regression loss: 0.16159 | Running loss: 0.36142\n","Epoch: 0 | Iteration: 210 | Classification loss: 0.09709 | Regression loss: 0.11036 | Running loss: 0.36069\n","Epoch: 0 | Iteration: 211 | Classification loss: 0.29144 | Regression loss: 0.24398 | Running loss: 0.36152\n","Epoch: 0 | Iteration: 212 | Classification loss: 0.10620 | Regression loss: 0.08061 | Running loss: 0.36070\n","Epoch: 0 | Iteration: 213 | Classification loss: 0.08620 | Regression loss: 0.07635 | Running loss: 0.35977\n","Epoch: 0 | Iteration: 214 | Classification loss: 0.11554 | Regression loss: 0.24590 | Running loss: 0.35978\n","Epoch: 0 | Iteration: 215 | Classification loss: 0.00000 | Regression loss: 0.00129 | Running loss: 0.35812\n","Epoch: 0 | Iteration: 216 | Classification loss: 0.30281 | Regression loss: 0.33926 | Running loss: 0.35943\n","Epoch: 0 | Iteration: 217 | Classification loss: 0.19021 | Regression loss: 0.11718 | Running loss: 0.35919\n","Epoch: 0 | Iteration: 218 | Classification loss: 0.15907 | Regression loss: 0.41003 | Running loss: 0.36015\n","Epoch: 0 | Iteration: 219 | Classification loss: 0.00001 | Regression loss: 0.00060 | Running loss: 0.35851\n","Epoch: 0 | Iteration: 220 | Classification loss: 0.24533 | Regression loss: 0.11769 | Running loss: 0.35853\n","Epoch: 0 | Iteration: 221 | Classification loss: 0.00003 | Regression loss: 0.00044 | Running loss: 0.35692\n","Epoch: 0 | Iteration: 222 | Classification loss: 0.18504 | Regression loss: 0.12186 | Running loss: 0.35670\n","Epoch: 0 | Iteration: 223 | Classification loss: 0.24522 | Regression loss: 0.25792 | Running loss: 0.35735\n","Epoch: 0 | Iteration: 224 | Classification loss: 0.00000 | Regression loss: 0.00047 | Running loss: 0.35576\n","Epoch: 0 | Iteration: 225 | Classification loss: 0.21891 | Regression loss: 0.25876 | Running loss: 0.35630\n","Epoch: 0 | Iteration: 226 | Classification loss: 0.07650 | Regression loss: 0.08990 | Running loss: 0.35547\n","Epoch: 0 | Iteration: 227 | Classification loss: 0.40584 | Regression loss: 0.29859 | Running loss: 0.35700\n","Epoch: 0 | Iteration: 228 | Classification loss: 0.21889 | Regression loss: 0.16357 | Running loss: 0.35711\n","Epoch: 0 | Iteration: 229 | Classification loss: 0.13836 | Regression loss: 0.04725 | Running loss: 0.35636\n","Epoch: 0 | Iteration: 230 | Classification loss: 0.15805 | Regression loss: 0.16690 | Running loss: 0.35623\n","Epoch: 0 | Iteration: 231 | Classification loss: 0.06349 | Regression loss: 0.11627 | Running loss: 0.35547\n","Epoch: 0 | Iteration: 232 | Classification loss: 0.09914 | Regression loss: 0.07025 | Running loss: 0.35467\n","Epoch: 0 | Iteration: 233 | Classification loss: 0.09554 | Regression loss: 0.11040 | Running loss: 0.35403\n","Epoch: 0 | Iteration: 234 | Classification loss: 0.17497 | Regression loss: 0.00000 | Running loss: 0.35327\n","Epoch: 0 | Iteration: 235 | Classification loss: 0.11381 | Regression loss: 0.04770 | Running loss: 0.35246\n","Epoch: 0 | Iteration: 236 | Classification loss: 0.22598 | Regression loss: 0.17383 | Running loss: 0.35266\n","Epoch: 0 | Iteration: 237 | Classification loss: 0.17096 | Regression loss: 0.08924 | Running loss: 0.35227\n","Epoch: 0 | Iteration: 238 | Classification loss: 0.00000 | Regression loss: 0.00099 | Running loss: 0.35080\n","Epoch: 0 | Iteration: 239 | Classification loss: 0.55563 | Regression loss: 0.37606 | Running loss: 0.35322\n","Epoch: 0 | Iteration: 240 | Classification loss: 0.47175 | Regression loss: 0.57532 | Running loss: 0.35610\n","Epoch: 0 | Iteration: 241 | Classification loss: 0.56676 | Regression loss: 0.43638 | Running loss: 0.35877\n","Epoch: 0 | Iteration: 242 | Classification loss: 0.26679 | Regression loss: 0.30507 | Running loss: 0.35965\n","Epoch: 0 | Iteration: 243 | Classification loss: 0.34291 | Regression loss: 0.29578 | Running loss: 0.36079\n","Epoch: 0 | Iteration: 244 | Classification loss: 0.06214 | Regression loss: 0.14590 | Running loss: 0.36017\n","Epoch: 0 | Iteration: 245 | Classification loss: 0.19113 | Regression loss: 0.27918 | Running loss: 0.36062\n","Epoch: 0 | Iteration: 246 | Classification loss: 0.92982 | Regression loss: 0.00000 | Running loss: 0.36292\n","Epoch: 0 | Iteration: 247 | Classification loss: 0.51261 | Regression loss: 0.40127 | Running loss: 0.36514\n","Epoch: 0 | Iteration: 248 | Classification loss: 0.24650 | Regression loss: 0.11247 | Running loss: 0.36512\n","Epoch: 0 | Iteration: 249 | Classification loss: 0.04774 | Regression loss: 0.10402 | Running loss: 0.36427\n","Epoch: 0 | Iteration: 250 | Classification loss: 0.45386 | Regression loss: 0.22871 | Running loss: 0.36553\n","Epoch: 0 | Iteration: 251 | Classification loss: 0.54654 | Regression loss: 0.10635 | Running loss: 0.36667\n","Epoch: 0 | Iteration: 252 | Classification loss: 0.14374 | Regression loss: 0.07629 | Running loss: 0.36609\n","Epoch: 0 | Iteration: 253 | Classification loss: 0.17174 | Regression loss: 0.17170 | Running loss: 0.36600\n","Epoch: 0 | Iteration: 254 | Classification loss: 0.29629 | Regression loss: 0.23673 | Running loss: 0.36666\n","Epoch: 0 | Iteration: 255 | Classification loss: 0.31801 | Regression loss: 0.28841 | Running loss: 0.36760\n","Epoch: 0 | Iteration: 256 | Classification loss: 0.17756 | Regression loss: 0.25700 | Running loss: 0.36786\n","Epoch: 0 | Iteration: 257 | Classification loss: 0.23805 | Regression loss: 0.19215 | Running loss: 0.36810\n","Epoch: 0 | Iteration: 258 | Classification loss: 0.00002 | Regression loss: 0.00040 | Running loss: 0.36668\n","Epoch: 0 | Iteration: 259 | Classification loss: 0.00002 | Regression loss: 0.00031 | Running loss: 0.36527\n","Epoch: 0 | Iteration: 260 | Classification loss: 0.22094 | Regression loss: 0.08309 | Running loss: 0.36504\n","Epoch: 0 | Iteration: 261 | Classification loss: 0.29264 | Regression loss: 0.23901 | Running loss: 0.36567\n","Epoch: 0 | Iteration: 262 | Classification loss: 0.00028 | Regression loss: 0.00077 | Running loss: 0.36428\n","Epoch: 0 | Iteration: 263 | Classification loss: 0.15015 | Regression loss: 0.07657 | Running loss: 0.36376\n","Epoch: 0 | Iteration: 264 | Classification loss: 0.55043 | Regression loss: 0.15422 | Running loss: 0.36505\n","Epoch: 0 | Iteration: 265 | Classification loss: 0.15306 | Regression loss: 0.07710 | Running loss: 0.36454\n","Epoch: 0 | Iteration: 266 | Classification loss: 0.20238 | Regression loss: 0.06400 | Running loss: 0.36418\n","Epoch: 0 | Iteration: 267 | Classification loss: 0.00595 | Regression loss: 0.00000 | Running loss: 0.36284\n","Epoch: 0 | Iteration: 268 | Classification loss: 0.00000 | Regression loss: 0.00015 | Running loss: 0.36149\n","Epoch: 0 | Iteration: 269 | Classification loss: 0.33339 | Regression loss: 0.33197 | Running loss: 0.36262\n","Epoch: 0 | Iteration: 270 | Classification loss: 0.17202 | Regression loss: 0.13862 | Running loss: 0.36242\n","Epoch: 0 | Iteration: 271 | Classification loss: 0.19219 | Regression loss: 0.32053 | Running loss: 0.36298\n","Epoch: 0 | Iteration: 272 | Classification loss: 0.00000 | Regression loss: 0.00014 | Running loss: 0.36165\n","Epoch: 0 | Iteration: 273 | Classification loss: 0.30051 | Regression loss: 0.16570 | Running loss: 0.36203\n","Epoch: 0 | Iteration: 274 | Classification loss: 0.24090 | Regression loss: 0.40886 | Running loss: 0.36308\n","Epoch: 0 | Iteration: 275 | Classification loss: 0.00000 | Regression loss: 0.00023 | Running loss: 0.36176\n","Epoch: 0 | Iteration: 276 | Classification loss: 0.30205 | Regression loss: 0.34803 | Running loss: 0.36280\n","Epoch: 0 | Iteration: 277 | Classification loss: 0.19936 | Regression loss: 0.13952 | Running loss: 0.36272\n","Epoch: 0 | Iteration: 278 | Classification loss: 0.33711 | Regression loss: 0.22869 | Running loss: 0.36344\n","Epoch: 0 | Iteration: 279 | Classification loss: 0.23483 | Regression loss: 0.09953 | Running loss: 0.36334\n","Epoch: 0 | Iteration: 280 | Classification loss: 0.63520 | Regression loss: 0.33939 | Running loss: 0.36551\n","Epoch: 0 | Iteration: 281 | Classification loss: 0.30806 | Regression loss: 0.20034 | Running loss: 0.36602\n","Epoch: 0 | Iteration: 282 | Classification loss: 0.11263 | Regression loss: 0.04594 | Running loss: 0.36529\n","Epoch: 0 | Iteration: 283 | Classification loss: 0.22833 | Regression loss: 0.09353 | Running loss: 0.36514\n","Epoch: 0 | Iteration: 284 | Classification loss: 0.03393 | Regression loss: 0.00000 | Running loss: 0.36397\n","Epoch: 0 | Iteration: 285 | Classification loss: 0.09573 | Regression loss: 0.05487 | Running loss: 0.36323\n","Epoch: 0 | Iteration: 286 | Classification loss: 0.22452 | Regression loss: 0.15747 | Running loss: 0.36329\n","Epoch: 0 | Iteration: 287 | Classification loss: 0.20969 | Regression loss: 0.28893 | Running loss: 0.36376\n","Epoch: 0 | Iteration: 288 | Classification loss: 0.12352 | Regression loss: 0.30879 | Running loss: 0.36400\n","Epoch: 0 | Iteration: 289 | Classification loss: 0.49742 | Regression loss: 0.45089 | Running loss: 0.36601\n","Epoch: 0 | Iteration: 290 | Classification loss: 0.28431 | Regression loss: 0.36955 | Running loss: 0.36700\n","Epoch: 0 | Iteration: 291 | Classification loss: 0.06480 | Regression loss: 0.00000 | Running loss: 0.36597\n","Epoch: 0 | Iteration: 292 | Classification loss: 0.27602 | Regression loss: 0.06484 | Running loss: 0.36588\n","Epoch: 0 | Iteration: 293 | Classification loss: 0.12032 | Regression loss: 0.27531 | Running loss: 0.36598\n","Epoch: 0 | Iteration: 294 | Classification loss: 0.10251 | Regression loss: 0.09056 | Running loss: 0.36540\n","Epoch: 0 | Iteration: 295 | Classification loss: 0.22518 | Regression loss: 0.30445 | Running loss: 0.36595\n","Epoch: 0 | Iteration: 296 | Classification loss: 0.66095 | Regression loss: 0.53539 | Running loss: 0.36875\n","Epoch: 0 | Iteration: 297 | Classification loss: 0.10451 | Regression loss: 0.09605 | Running loss: 0.36818\n","Epoch: 0 | Iteration: 298 | Classification loss: 0.14373 | Regression loss: 0.27402 | Running loss: 0.36835\n","Epoch: 0 | Iteration: 299 | Classification loss: 0.05322 | Regression loss: 0.04179 | Running loss: 0.36744\n","Epoch: 0 | Iteration: 300 | Classification loss: 0.15119 | Regression loss: 0.08033 | Running loss: 0.36699\n","Epoch: 0 | Iteration: 301 | Classification loss: 0.17509 | Regression loss: 0.05909 | Running loss: 0.36655\n","Epoch: 0 | Iteration: 302 | Classification loss: 0.21182 | Regression loss: 0.24725 | Running loss: 0.36685\n","Epoch: 0 | Iteration: 303 | Classification loss: 0.12081 | Regression loss: 0.08625 | Running loss: 0.36633\n","Epoch: 0 | Iteration: 304 | Classification loss: 0.23654 | Regression loss: 0.43867 | Running loss: 0.36734\n","Epoch: 0 | Iteration: 305 | Classification loss: 0.20668 | Regression loss: 0.23266 | Running loss: 0.36758\n","Epoch: 0 | Iteration: 306 | Classification loss: 0.28062 | Regression loss: 0.23102 | Running loss: 0.36804\n","Epoch: 0 | Iteration: 307 | Classification loss: 0.27108 | Regression loss: 0.28994 | Running loss: 0.36867\n","Epoch: 0 | Iteration: 308 | Classification loss: 0.43313 | Regression loss: 0.15708 | Running loss: 0.36939\n","Epoch: 0 | Iteration: 309 | Classification loss: 0.18669 | Regression loss: 0.11324 | Running loss: 0.36916\n","Epoch: 0 | Iteration: 310 | Classification loss: 0.28653 | Regression loss: 0.19539 | Running loss: 0.36953\n","Epoch: 0 | Iteration: 311 | Classification loss: 0.08772 | Regression loss: 0.13240 | Running loss: 0.36905\n","Epoch: 0 | Iteration: 312 | Classification loss: 0.33843 | Regression loss: 0.14734 | Running loss: 0.36942\n","Epoch: 0 | Iteration: 313 | Classification loss: 0.00001 | Regression loss: 0.00037 | Running loss: 0.36825\n","Epoch: 0 | Iteration: 314 | Classification loss: 0.07011 | Regression loss: 0.07398 | Running loss: 0.36753\n","Epoch: 0 | Iteration: 315 | Classification loss: 0.23693 | Regression loss: 0.30327 | Running loss: 0.36808\n","Epoch: 0 | Iteration: 316 | Classification loss: 0.23691 | Regression loss: 0.16422 | Running loss: 0.36818\n","Epoch: 0 | Iteration: 317 | Classification loss: 0.08701 | Regression loss: 0.12648 | Running loss: 0.36770\n","Epoch: 0 | Iteration: 318 | Classification loss: 0.23435 | Regression loss: 0.19650 | Running loss: 0.36790\n","Epoch: 0 | Iteration: 319 | Classification loss: 0.41282 | Regression loss: 0.27703 | Running loss: 0.36890\n","Epoch: 0 | Iteration: 320 | Classification loss: 0.00000 | Regression loss: 0.00038 | Running loss: 0.36775\n","Epoch: 0 | Iteration: 321 | Classification loss: 0.29081 | Regression loss: 0.22441 | Running loss: 0.36821\n","Epoch: 0 | Iteration: 322 | Classification loss: 0.00003 | Regression loss: 0.00062 | Running loss: 0.36707\n","Epoch: 0 | Iteration: 323 | Classification loss: 0.28849 | Regression loss: 0.20126 | Running loss: 0.36745\n","Epoch: 0 | Iteration: 324 | Classification loss: 0.32119 | Regression loss: 0.21038 | Running loss: 0.36796\n","Epoch: 0 | Iteration: 325 | Classification loss: 0.28322 | Regression loss: 0.08729 | Running loss: 0.36797\n","Epoch: 0 | Iteration: 326 | Classification loss: 0.36863 | Regression loss: 0.23733 | Running loss: 0.36869\n","Epoch: 0 | Iteration: 327 | Classification loss: 0.26608 | Regression loss: 0.17890 | Running loss: 0.36893\n","Epoch: 0 | Iteration: 328 | Classification loss: 0.15564 | Regression loss: 0.11757 | Running loss: 0.36864\n","Epoch: 0 | Iteration: 329 | Classification loss: 0.21247 | Regression loss: 0.22798 | Running loss: 0.36885\n","Epoch: 0 | Iteration: 330 | Classification loss: 0.27209 | Regression loss: 0.05361 | Running loss: 0.36872\n","Epoch: 0 | Iteration: 331 | Classification loss: 0.25280 | Regression loss: 0.10360 | Running loss: 0.36869\n","Epoch: 0 | Iteration: 332 | Classification loss: 0.14583 | Regression loss: 0.14709 | Running loss: 0.36846\n","Epoch: 0 | Iteration: 333 | Classification loss: 0.39384 | Regression loss: 0.17822 | Running loss: 0.36907\n","Epoch: 0 | Iteration: 334 | Classification loss: 0.14450 | Regression loss: 0.14067 | Running loss: 0.36882\n","Epoch: 0 | Iteration: 335 | Classification loss: 0.09998 | Regression loss: 0.10151 | Running loss: 0.36832\n","Epoch: 0 | Iteration: 336 | Classification loss: 0.43031 | Regression loss: 0.32334 | Running loss: 0.36946\n","Epoch: 0 | Iteration: 337 | Classification loss: 0.09680 | Regression loss: 0.10804 | Running loss: 0.36898\n","Epoch: 0 | Iteration: 338 | Classification loss: 0.00001 | Regression loss: 0.00088 | Running loss: 0.36789\n","Epoch: 0 | Iteration: 339 | Classification loss: 0.00010 | Regression loss: 0.00055 | Running loss: 0.36681\n","Epoch: 0 | Iteration: 340 | Classification loss: 0.11170 | Regression loss: 0.05509 | Running loss: 0.36622\n","Epoch: 0 | Iteration: 341 | Classification loss: 0.17080 | Regression loss: 0.16285 | Running loss: 0.36613\n","Epoch: 0 | Iteration: 342 | Classification loss: 0.13833 | Regression loss: 0.02930 | Running loss: 0.36555\n","Epoch: 0 | Iteration: 343 | Classification loss: 0.21545 | Regression loss: 0.16519 | Running loss: 0.36559\n","Epoch: 0 | Iteration: 344 | Classification loss: 0.28965 | Regression loss: 0.00000 | Running loss: 0.36537\n","Epoch: 0 | Iteration: 345 | Classification loss: 0.32333 | Regression loss: 0.28645 | Running loss: 0.36608\n","Epoch: 0 | Iteration: 346 | Classification loss: 0.28653 | Regression loss: 0.24175 | Running loss: 0.36655\n","Epoch: 0 | Iteration: 347 | Classification loss: 0.15506 | Regression loss: 0.11322 | Running loss: 0.36626\n","Epoch: 0 | Iteration: 348 | Classification loss: 0.00000 | Regression loss: 0.00034 | Running loss: 0.36522\n","Epoch: 0 | Iteration: 349 | Classification loss: 0.09061 | Regression loss: 0.11622 | Running loss: 0.36476\n","Epoch: 0 | Iteration: 350 | Classification loss: 0.40326 | Regression loss: 0.45741 | Running loss: 0.36618\n","Epoch: 0 | Iteration: 351 | Classification loss: 0.03052 | Regression loss: 0.00000 | Running loss: 0.36522\n","Epoch: 0 | Iteration: 352 | Classification loss: 0.11840 | Regression loss: 0.03800 | Running loss: 0.36463\n","Epoch: 0 | Iteration: 353 | Classification loss: 0.00002 | Regression loss: 0.00063 | Running loss: 0.36360\n","Epoch: 0 | Iteration: 354 | Classification loss: 0.03841 | Regression loss: 0.01286 | Running loss: 0.36272\n","Epoch: 0 | Iteration: 355 | Classification loss: 0.07051 | Regression loss: 0.04532 | Running loss: 0.36203\n","Epoch: 0 | Iteration: 356 | Classification loss: 0.08135 | Regression loss: 0.22102 | Running loss: 0.36186\n","Epoch: 0 | Iteration: 357 | Classification loss: 0.12382 | Regression loss: 0.14550 | Running loss: 0.36160\n","Epoch: 0 | Iteration: 358 | Classification loss: 0.12932 | Regression loss: 0.11860 | Running loss: 0.36129\n","Epoch: 0 | Iteration: 359 | Classification loss: 0.50081 | Regression loss: 0.44262 | Running loss: 0.36290\n","Epoch: 0 | Iteration: 360 | Classification loss: 0.13592 | Regression loss: 0.06488 | Running loss: 0.36245\n","Epoch: 0 | Iteration: 361 | Classification loss: 0.22906 | Regression loss: 0.15324 | Running loss: 0.36251\n","Epoch: 0 | Iteration: 362 | Classification loss: 0.09400 | Regression loss: 0.05801 | Running loss: 0.36193\n","Epoch: 0 | Iteration: 363 | Classification loss: 0.25272 | Regression loss: 0.16234 | Running loss: 0.36208\n","Epoch: 0 | Iteration: 364 | Classification loss: 0.20303 | Regression loss: 0.13196 | Running loss: 0.36200\n","Epoch: 0 | Iteration: 365 | Classification loss: 0.12622 | Regression loss: 0.16566 | Running loss: 0.36181\n","Epoch: 0 | Iteration: 366 | Classification loss: 0.08512 | Regression loss: 0.09818 | Running loss: 0.36132\n","Epoch: 0 | Iteration: 367 | Classification loss: 0.20160 | Regression loss: 0.21483 | Running loss: 0.36147\n","Epoch: 0 | Iteration: 368 | Classification loss: 0.33297 | Regression loss: 0.19271 | Running loss: 0.36192\n","Epoch: 0 | Iteration: 369 | Classification loss: 0.32932 | Regression loss: 0.30261 | Running loss: 0.36265\n","Epoch: 0 | Iteration: 370 | Classification loss: 0.28324 | Regression loss: 0.12323 | Running loss: 0.36277\n","Epoch: 0 | Iteration: 371 | Classification loss: 0.19915 | Regression loss: 0.15279 | Running loss: 0.36274\n","Epoch: 0 | Iteration: 372 | Classification loss: 0.17883 | Regression loss: 0.11185 | Running loss: 0.36254\n","Epoch: 0 | Iteration: 373 | Classification loss: 0.44163 | Regression loss: 0.42728 | Running loss: 0.36390\n","Epoch: 0 | Iteration: 374 | Classification loss: 0.44530 | Regression loss: 0.48269 | Running loss: 0.36540\n","Epoch: 0 | Iteration: 375 | Classification loss: 0.68458 | Regression loss: 0.34818 | Running loss: 0.36718\n","Epoch: 0 | Iteration: 376 | Classification loss: 0.19582 | Regression loss: 0.20565 | Running loss: 0.36727\n","Epoch: 0 | Iteration: 377 | Classification loss: 0.16946 | Regression loss: 0.04363 | Running loss: 0.36686\n","Epoch: 0 | Iteration: 378 | Classification loss: 0.09029 | Regression loss: 0.12921 | Running loss: 0.36647\n","Epoch: 0 | Iteration: 379 | Classification loss: 0.22770 | Regression loss: 0.16285 | Running loss: 0.36653\n","Epoch: 0 | Iteration: 380 | Classification loss: 0.25903 | Regression loss: 0.11444 | Running loss: 0.36655\n","Epoch: 0 | Iteration: 381 | Classification loss: 0.17250 | Regression loss: 0.07295 | Running loss: 0.36624\n","Epoch: 0 | Iteration: 382 | Classification loss: 0.34227 | Regression loss: 0.27019 | Running loss: 0.36688\n","Epoch: 0 | Iteration: 383 | Classification loss: 0.00013 | Regression loss: 0.00077 | Running loss: 0.36593\n","Epoch: 0 | Iteration: 384 | Classification loss: 0.22184 | Regression loss: 0.12593 | Running loss: 0.36588\n","Epoch: 0 | Iteration: 385 | Classification loss: 0.00003 | Regression loss: 0.00045 | Running loss: 0.36493\n","Epoch: 0 | Iteration: 386 | Classification loss: 0.13230 | Regression loss: 0.09338 | Running loss: 0.36457\n","Epoch: 0 | Iteration: 387 | Classification loss: 0.35429 | Regression loss: 0.14291 | Running loss: 0.36491\n","Epoch: 0 | Iteration: 388 | Classification loss: 0.14733 | Regression loss: 0.11997 | Running loss: 0.36466\n","Epoch: 0 | Iteration: 389 | Classification loss: 0.14644 | Regression loss: 0.18832 | Running loss: 0.36459\n","Epoch: 0 | Iteration: 390 | Classification loss: 0.11455 | Regression loss: 0.08802 | Running loss: 0.36417\n","Epoch: 0 | Iteration: 391 | Classification loss: 0.03212 | Regression loss: 0.00000 | Running loss: 0.36332\n","Epoch: 0 | Iteration: 392 | Classification loss: 0.19518 | Regression loss: 0.16707 | Running loss: 0.36332\n","Epoch: 0 | Iteration: 393 | Classification loss: 0.04181 | Regression loss: 0.02427 | Running loss: 0.36257\n","Epoch: 0 | Iteration: 394 | Classification loss: 0.13081 | Regression loss: 0.16904 | Running loss: 0.36241\n","Epoch: 0 | Iteration: 395 | Classification loss: 0.09044 | Regression loss: 0.11226 | Running loss: 0.36201\n","Epoch: 0 | Iteration: 396 | Classification loss: 1.11182 | Regression loss: 0.46303 | Running loss: 0.36506\n","Epoch: 0 | Iteration: 397 | Classification loss: 0.13138 | Regression loss: 0.15180 | Running loss: 0.36485\n","Epoch: 0 | Iteration: 398 | Classification loss: 0.38688 | Regression loss: 0.19667 | Running loss: 0.36540\n","Epoch: 0 | Iteration: 399 | Classification loss: 0.46188 | Regression loss: 0.43102 | Running loss: 0.36672\n","Epoch: 0 | Iteration: 400 | Classification loss: 0.00010 | Regression loss: 0.00155 | Running loss: 0.36581\n","Epoch: 0 | Iteration: 401 | Classification loss: 0.11451 | Regression loss: 0.16143 | Running loss: 0.36559\n","Epoch: 0 | Iteration: 402 | Classification loss: 0.10854 | Regression loss: 0.28242 | Running loss: 0.36565\n","Epoch: 0 | Iteration: 403 | Classification loss: 0.20354 | Regression loss: 0.40248 | Running loss: 0.36625\n","Epoch: 0 | Iteration: 404 | Classification loss: 0.00000 | Regression loss: 0.00040 | Running loss: 0.36534\n","Epoch: 0 | Iteration: 405 | Classification loss: 0.01443 | Regression loss: 0.00000 | Running loss: 0.36448\n","Epoch: 0 | Iteration: 406 | Classification loss: 0.47671 | Regression loss: 0.12999 | Running loss: 0.36507\n","Epoch: 0 | Iteration: 407 | Classification loss: 0.28708 | Regression loss: 0.14856 | Running loss: 0.36525\n","Epoch: 0 | Iteration: 408 | Classification loss: 0.93606 | Regression loss: 0.51869 | Running loss: 0.36791\n","Epoch: 0 | Iteration: 409 | Classification loss: 0.17114 | Regression loss: 0.17884 | Running loss: 0.36787\n","Epoch: 0 | Iteration: 410 | Classification loss: 0.13543 | Regression loss: 0.08771 | Running loss: 0.36751\n","Epoch: 0 | Iteration: 411 | Classification loss: 0.18090 | Regression loss: 0.23287 | Running loss: 0.36763\n","Epoch: 0 | Iteration: 412 | Classification loss: 0.26028 | Regression loss: 0.12389 | Running loss: 0.36767\n","Epoch: 0 | Iteration: 413 | Classification loss: 0.08432 | Regression loss: 0.11254 | Running loss: 0.36725\n","Epoch: 0 | Iteration: 414 | Classification loss: 0.08304 | Regression loss: 0.08162 | Running loss: 0.36677\n","Epoch: 0 | Iteration: 415 | Classification loss: 0.14760 | Regression loss: 0.12094 | Running loss: 0.36653\n","Epoch: 0 | Iteration: 416 | Classification loss: 0.25192 | Regression loss: 0.14661 | Running loss: 0.36661\n","Epoch: 0 | Iteration: 417 | Classification loss: 0.22354 | Regression loss: 0.18160 | Running loss: 0.36670\n","Epoch: 0 | Iteration: 418 | Classification loss: 0.19347 | Regression loss: 0.16609 | Running loss: 0.36668\n","Epoch: 0 | Iteration: 419 | Classification loss: 0.19056 | Regression loss: 0.47118 | Running loss: 0.36738\n","Epoch: 0 | Iteration: 420 | Classification loss: 0.26939 | Regression loss: 0.14681 | Running loss: 0.36750\n","Epoch: 0 | Iteration: 421 | Classification loss: 0.00000 | Regression loss: 0.00055 | Running loss: 0.36663\n","Epoch: 0 | Iteration: 422 | Classification loss: 0.55887 | Regression loss: 0.41424 | Running loss: 0.36806\n","Epoch: 0 | Iteration: 423 | Classification loss: 0.24144 | Regression loss: 0.15370 | Running loss: 0.36813\n","Epoch: 0 | Iteration: 424 | Classification loss: 0.38869 | Regression loss: 0.46087 | Running loss: 0.36926\n","Epoch: 0 | Iteration: 425 | Classification loss: 0.41552 | Regression loss: 0.39275 | Running loss: 0.37029\n","Epoch: 0 | Iteration: 426 | Classification loss: 0.07811 | Regression loss: 0.07490 | Running loss: 0.36978\n","Epoch: 0 | Iteration: 427 | Classification loss: 0.22616 | Regression loss: 0.14801 | Running loss: 0.36979\n","Epoch: 0 | Iteration: 428 | Classification loss: 0.15306 | Regression loss: 0.22219 | Running loss: 0.36981\n","Epoch: 0 | Iteration: 429 | Classification loss: 0.22039 | Regression loss: 0.52307 | Running loss: 0.37067\n","Epoch: 0 | Iteration: 430 | Classification loss: 0.39578 | Regression loss: 0.37415 | Running loss: 0.37160\n","Epoch: 0 | Iteration: 431 | Classification loss: 0.07244 | Regression loss: 0.06327 | Running loss: 0.37105\n","Epoch: 0 | Iteration: 432 | Classification loss: 0.20229 | Regression loss: 0.11234 | Running loss: 0.37092\n","Epoch: 0 | Iteration: 433 | Classification loss: 0.52053 | Regression loss: 0.27831 | Running loss: 0.37191\n","Epoch: 0 | Iteration: 434 | Classification loss: 0.16654 | Regression loss: 0.05201 | Running loss: 0.37156\n","Epoch: 0 | Iteration: 435 | Classification loss: 0.07387 | Regression loss: 0.10957 | Running loss: 0.37113\n","Epoch: 0 | Iteration: 436 | Classification loss: 0.28402 | Regression loss: 0.37979 | Running loss: 0.37180\n","Epoch: 0 | Iteration: 437 | Classification loss: 0.53656 | Regression loss: 0.46287 | Running loss: 0.37323\n","Epoch: 0 | Iteration: 438 | Classification loss: 0.06133 | Regression loss: 0.00000 | Running loss: 0.37252\n","Epoch: 0 | Iteration: 439 | Classification loss: 0.51053 | Regression loss: 0.36149 | Running loss: 0.37365\n","Epoch: 0 | Iteration: 440 | Classification loss: 0.00463 | Regression loss: 0.00000 | Running loss: 0.37282\n","Epoch: 0 | Iteration: 441 | Classification loss: 0.03835 | Regression loss: 0.05399 | Running loss: 0.37218\n","Epoch: 0 | Iteration: 442 | Classification loss: 0.23726 | Regression loss: 0.20582 | Running loss: 0.37234\n","Epoch: 0 | Iteration: 443 | Classification loss: 0.49348 | Regression loss: 0.11501 | Running loss: 0.37287\n","Epoch: 0 | Iteration: 444 | Classification loss: 0.23530 | Regression loss: 0.23218 | Running loss: 0.37309\n","Epoch: 0 | Iteration: 445 | Classification loss: 0.46205 | Regression loss: 0.77290 | Running loss: 0.37502\n","Epoch: 0 | Iteration: 446 | Classification loss: 0.27298 | Regression loss: 0.16050 | Running loss: 0.37515\n","Epoch: 0 | Iteration: 447 | Classification loss: 0.13941 | Regression loss: 0.16500 | Running loss: 0.37499\n","Epoch: 0 | Iteration: 448 | Classification loss: 0.35630 | Regression loss: 0.11565 | Running loss: 0.37521\n","Epoch: 0 | Iteration: 449 | Classification loss: 0.33312 | Regression loss: 0.37841 | Running loss: 0.37596\n","Epoch: 0 | Iteration: 450 | Classification loss: 0.14616 | Regression loss: 0.17269 | Running loss: 0.37583\n","Epoch: 0 | Iteration: 451 | Classification loss: 0.57459 | Regression loss: 0.24859 | Running loss: 0.37682\n","Epoch: 0 | Iteration: 452 | Classification loss: 0.28708 | Regression loss: 0.23718 | Running loss: 0.37714\n","Epoch: 0 | Iteration: 453 | Classification loss: 0.24817 | Regression loss: 0.12325 | Running loss: 0.37713\n","Epoch: 0 | Iteration: 454 | Classification loss: 0.44406 | Regression loss: 0.50251 | Running loss: 0.37838\n","Epoch: 0 | Iteration: 455 | Classification loss: 0.16922 | Regression loss: 0.30387 | Running loss: 0.37859\n","Epoch: 0 | Iteration: 456 | Classification loss: 0.17912 | Regression loss: 0.06880 | Running loss: 0.37830\n","Epoch: 0 | Iteration: 457 | Classification loss: 0.23184 | Regression loss: 0.16465 | Running loss: 0.37834\n","Epoch: 0 | Iteration: 458 | Classification loss: 0.17251 | Regression loss: 0.04907 | Running loss: 0.37800\n","Epoch: 0 | Iteration: 459 | Classification loss: 0.20955 | Regression loss: 0.19279 | Running loss: 0.37806\n","Epoch: 0 | Iteration: 460 | Classification loss: 0.07282 | Regression loss: 0.06440 | Running loss: 0.37753\n","Epoch: 0 | Iteration: 461 | Classification loss: 0.20900 | Regression loss: 0.15899 | Running loss: 0.37751\n","Epoch: 0 | Iteration: 462 | Classification loss: 0.53826 | Regression loss: 0.38066 | Running loss: 0.37868\n","Epoch: 0 | Iteration: 463 | Classification loss: 0.19269 | Regression loss: 0.22604 | Running loss: 0.37877\n","Epoch: 0 | Iteration: 464 | Classification loss: 0.07478 | Regression loss: 0.08057 | Running loss: 0.37829\n","Epoch: 0 | Iteration: 465 | Classification loss: 0.11826 | Regression loss: 0.06985 | Running loss: 0.37788\n","Epoch: 0 | Iteration: 466 | Classification loss: 0.44941 | Regression loss: 0.10954 | Running loss: 0.37827\n","Epoch: 0 | Iteration: 467 | Classification loss: 0.10845 | Regression loss: 0.04355 | Running loss: 0.37778\n","Epoch: 0 | Iteration: 468 | Classification loss: 0.21146 | Regression loss: 0.27598 | Running loss: 0.37802\n","Epoch: 0 | Iteration: 469 | Classification loss: 0.24835 | Regression loss: 0.27292 | Running loss: 0.37832\n","Epoch: 0 | Iteration: 470 | Classification loss: 0.38063 | Regression loss: 0.39278 | Running loss: 0.37916\n","Epoch: 0 | Iteration: 471 | Classification loss: 0.15087 | Regression loss: 0.14932 | Running loss: 0.37899\n","Epoch: 0 | Iteration: 472 | Classification loss: 0.08910 | Regression loss: 0.07001 | Running loss: 0.37853\n","Epoch: 0 | Iteration: 473 | Classification loss: 0.30360 | Regression loss: 0.20231 | Running loss: 0.37880\n","Epoch: 0 | Iteration: 474 | Classification loss: 0.12649 | Regression loss: 0.05096 | Running loss: 0.37837\n","Epoch: 0 | Iteration: 475 | Classification loss: 0.23754 | Regression loss: 0.34187 | Running loss: 0.37880\n","Epoch: 0 | Iteration: 476 | Classification loss: 0.08808 | Regression loss: 0.06577 | Running loss: 0.37832\n","Epoch: 0 | Iteration: 477 | Classification loss: 0.63055 | Regression loss: 0.18027 | Running loss: 0.37923\n","Epoch: 0 | Iteration: 478 | Classification loss: 0.22032 | Regression loss: 0.13164 | Running loss: 0.37917\n","Epoch: 0 | Iteration: 479 | Classification loss: 0.18549 | Regression loss: 0.36344 | Running loss: 0.37953\n","Epoch: 0 | Iteration: 480 | Classification loss: 0.22645 | Regression loss: 0.03446 | Running loss: 0.37928\n","Epoch: 0 | Iteration: 481 | Classification loss: 0.22632 | Regression loss: 0.18131 | Running loss: 0.37934\n","Epoch: 0 | Iteration: 482 | Classification loss: 0.00021 | Regression loss: 0.00060 | Running loss: 0.37855\n","Epoch: 0 | Iteration: 483 | Classification loss: 0.27311 | Regression loss: 0.33194 | Running loss: 0.37902\n","Epoch: 0 | Iteration: 484 | Classification loss: 0.15780 | Regression loss: 0.26279 | Running loss: 0.37911\n","Epoch: 0 | Iteration: 485 | Classification loss: 0.43834 | Regression loss: 0.22543 | Running loss: 0.37969\n","Epoch: 0 | Iteration: 486 | Classification loss: 0.31189 | Regression loss: 0.30517 | Running loss: 0.38018\n","Epoch: 0 | Iteration: 487 | Classification loss: 0.23375 | Regression loss: 0.33697 | Running loss: 0.38057\n","Epoch: 0 | Iteration: 488 | Classification loss: 0.10135 | Regression loss: 0.07396 | Running loss: 0.38015\n","Epoch: 0 | Iteration: 489 | Classification loss: 0.12890 | Regression loss: 0.37628 | Running loss: 0.38041\n","Epoch: 0 | Iteration: 490 | Classification loss: 0.23922 | Regression loss: 0.28082 | Running loss: 0.38069\n","Epoch: 0 | Iteration: 491 | Classification loss: 0.20655 | Regression loss: 0.19728 | Running loss: 0.38074\n","Epoch: 0 | Iteration: 492 | Classification loss: 0.29182 | Regression loss: 0.23156 | Running loss: 0.38103\n","Epoch: 0 | Iteration: 493 | Classification loss: 0.14210 | Regression loss: 0.09410 | Running loss: 0.38074\n","Epoch: 0 | Iteration: 494 | Classification loss: 0.51156 | Regression loss: 0.39450 | Running loss: 0.38180\n","Epoch: 0 | Iteration: 495 | Classification loss: 0.03310 | Regression loss: 0.03781 | Running loss: 0.38117\n","Epoch: 0 | Iteration: 496 | Classification loss: 0.14759 | Regression loss: 0.15112 | Running loss: 0.38100\n","Epoch: 0 | Iteration: 497 | Classification loss: 0.12862 | Regression loss: 0.05617 | Running loss: 0.38061\n","Epoch: 0 | Iteration: 498 | Classification loss: 0.20774 | Regression loss: 0.35246 | Running loss: 0.38097\n","Epoch: 0 | Iteration: 499 | Classification loss: 0.55771 | Regression loss: 0.62832 | Running loss: 0.38258\n","Epoch: 0 | Iteration: 500 | Classification loss: 0.25352 | Regression loss: 0.37428 | Running loss: 0.38345\n","Epoch: 0 | Iteration: 501 | Classification loss: 0.17245 | Regression loss: 0.41544 | Running loss: 0.38442\n","Epoch: 0 | Iteration: 502 | Classification loss: 0.30553 | Regression loss: 0.34730 | Running loss: 0.38469\n","Epoch: 0 | Iteration: 503 | Classification loss: 0.21763 | Regression loss: 0.07576 | Running loss: 0.38442\n","Epoch: 0 | Iteration: 504 | Classification loss: 0.21858 | Regression loss: 0.09567 | Running loss: 0.38497\n","Epoch: 0 | Iteration: 505 | Classification loss: 0.16843 | Regression loss: 0.26745 | Running loss: 0.38584\n","Epoch: 0 | Iteration: 506 | Classification loss: 0.28148 | Regression loss: 0.25457 | Running loss: 0.38580\n","Epoch: 0 | Iteration: 507 | Classification loss: 0.10808 | Regression loss: 0.07759 | Running loss: 0.38513\n","Epoch: 0 | Iteration: 508 | Classification loss: 0.35840 | Regression loss: 0.47445 | Running loss: 0.38623\n","Epoch: 0 | Iteration: 509 | Classification loss: 0.14251 | Regression loss: 0.08462 | Running loss: 0.38591\n","Epoch: 0 | Iteration: 510 | Classification loss: 0.21578 | Regression loss: 0.28583 | Running loss: 0.38691\n","Epoch: 0 | Iteration: 511 | Classification loss: 0.24970 | Regression loss: 0.45096 | Running loss: 0.38740\n","Epoch: 0 | Iteration: 512 | Classification loss: 0.40707 | Regression loss: 0.41840 | Running loss: 0.38825\n","Epoch: 0 | Iteration: 513 | Classification loss: 0.50295 | Regression loss: 0.42966 | Running loss: 0.38895\n","Epoch: 0 | Iteration: 514 | Classification loss: 0.37136 | Regression loss: 0.30009 | Running loss: 0.39030\n","Epoch: 0 | Iteration: 515 | Classification loss: 0.00000 | Regression loss: 0.00097 | Running loss: 0.38988\n","Epoch: 0 | Iteration: 516 | Classification loss: 0.30454 | Regression loss: 0.18675 | Running loss: 0.38993\n","Epoch: 0 | Iteration: 517 | Classification loss: 0.20327 | Regression loss: 0.32355 | Running loss: 0.39002\n","Epoch: 0 | Iteration: 518 | Classification loss: 0.09224 | Regression loss: 0.19930 | Running loss: 0.39002\n","Epoch: 0 | Iteration: 519 | Classification loss: 0.00000 | Regression loss: 0.00139 | Running loss: 0.38943\n","Epoch: 0 | Iteration: 520 | Classification loss: 0.02190 | Regression loss: 0.00000 | Running loss: 0.38890\n","Epoch: 0 | Iteration: 521 | Classification loss: 0.14920 | Regression loss: 0.00000 | Running loss: 0.38839\n","Epoch: 0 | Iteration: 522 | Classification loss: 0.00000 | Regression loss: 0.00061 | Running loss: 0.38757\n","Epoch: 0 | Iteration: 523 | Classification loss: 0.52226 | Regression loss: 0.38774 | Running loss: 0.38743\n","Epoch: 0 | Iteration: 524 | Classification loss: 0.00001 | Regression loss: 0.00029 | Running loss: 0.38604\n","Epoch: 0 | Iteration: 525 | Classification loss: 0.19935 | Regression loss: 0.09283 | Running loss: 0.38566\n","Epoch: 0 | Iteration: 526 | Classification loss: 0.17540 | Regression loss: 0.13056 | Running loss: 0.38511\n","Epoch: 0 | Iteration: 527 | Classification loss: 0.00008 | Regression loss: 0.00032 | Running loss: 0.38502\n","Epoch: 0 | Iteration: 528 | Classification loss: 0.07389 | Regression loss: 0.00000 | Running loss: 0.38360\n","Epoch: 0 | Iteration: 529 | Classification loss: 0.06732 | Regression loss: 0.04699 | Running loss: 0.38247\n","Epoch: 0 | Iteration: 530 | Classification loss: 0.40719 | Regression loss: 0.30530 | Running loss: 0.38358\n","Epoch: 0 | Iteration: 531 | Classification loss: 0.36571 | Regression loss: 0.37261 | Running loss: 0.38482\n","Epoch: 0 | Iteration: 532 | Classification loss: 0.10356 | Regression loss: 0.02923 | Running loss: 0.38480\n","Epoch: 0 | Iteration: 533 | Classification loss: 0.16175 | Regression loss: 0.14789 | Running loss: 0.38541\n","Epoch: 0 | Iteration: 534 | Classification loss: 0.24363 | Regression loss: 0.15131 | Running loss: 0.38555\n","Epoch: 0 | Iteration: 535 | Classification loss: 0.35551 | Regression loss: 0.23348 | Running loss: 0.38513\n","Epoch: 0 | Iteration: 536 | Classification loss: 0.38681 | Regression loss: 0.15646 | Running loss: 0.38622\n","Epoch: 0 | Iteration: 537 | Classification loss: 0.00001 | Regression loss: 0.00028 | Running loss: 0.38622\n","Epoch: 0 | Iteration: 538 | Classification loss: 0.28181 | Regression loss: 0.17349 | Running loss: 0.38600\n","Epoch: 0 | Iteration: 539 | Classification loss: 0.32953 | Regression loss: 0.12160 | Running loss: 0.38658\n","Epoch: 0 | Iteration: 540 | Classification loss: 0.15170 | Regression loss: 0.24688 | Running loss: 0.38669\n","Epoch: 0 | Iteration: 541 | Classification loss: 0.23029 | Regression loss: 0.12954 | Running loss: 0.38715\n","Epoch: 0 | Iteration: 542 | Classification loss: 0.07232 | Regression loss: 0.11855 | Running loss: 0.38677\n","Epoch: 0 | Iteration: 543 | Classification loss: 0.25028 | Regression loss: 0.32042 | Running loss: 0.38657\n","Epoch: 0 | Iteration: 544 | Classification loss: 0.00006 | Regression loss: 0.00081 | Running loss: 0.38586\n","Epoch: 0 | Iteration: 545 | Classification loss: 0.06795 | Regression loss: 0.12712 | Running loss: 0.38625\n","Epoch: 0 | Iteration: 546 | Classification loss: 0.47062 | Regression loss: 0.49407 | Running loss: 0.38751\n","Epoch: 0 | Iteration: 547 | Classification loss: 0.00001 | Regression loss: 0.00074 | Running loss: 0.38662\n","Epoch: 0 | Iteration: 548 | Classification loss: 0.09576 | Regression loss: 0.06214 | Running loss: 0.38694\n","Epoch: 0 | Iteration: 549 | Classification loss: 0.00000 | Regression loss: 0.00026 | Running loss: 0.38675\n","Epoch: 0 | Iteration: 550 | Classification loss: 0.04178 | Regression loss: 0.00000 | Running loss: 0.38560\n","Epoch: 0 | Iteration: 551 | Classification loss: 0.13950 | Regression loss: 0.31995 | Running loss: 0.38598\n","Epoch: 0 | Iteration: 552 | Classification loss: 0.07019 | Regression loss: 0.11902 | Running loss: 0.38488\n","Epoch: 0 | Iteration: 553 | Classification loss: 0.09168 | Regression loss: 0.04588 | Running loss: 0.38434\n","Epoch: 0 | Iteration: 554 | Classification loss: 0.35599 | Regression loss: 0.20153 | Running loss: 0.38385\n","Epoch: 0 | Iteration: 555 | Classification loss: 0.18595 | Regression loss: 0.23182 | Running loss: 0.38439\n","Epoch: 0 | Iteration: 556 | Classification loss: 0.14160 | Regression loss: 0.12498 | Running loss: 0.38456\n","Epoch: 0 | Iteration: 557 | Classification loss: 0.29289 | Regression loss: 0.16887 | Running loss: 0.38548\n","Epoch: 0 | Iteration: 558 | Classification loss: 0.09825 | Regression loss: 0.11077 | Running loss: 0.38569\n","Epoch: 0 | Iteration: 559 | Classification loss: 0.09254 | Regression loss: 0.03372 | Running loss: 0.38533\n","Epoch: 0 | Iteration: 560 | Classification loss: 0.25106 | Regression loss: 0.35981 | Running loss: 0.38515\n","Epoch: 0 | Iteration: 561 | Classification loss: 0.22311 | Regression loss: 0.13797 | Running loss: 0.38587\n","Epoch: 0 | Iteration: 562 | Classification loss: 0.05055 | Regression loss: 0.03479 | Running loss: 0.38603\n","Epoch: 0 | Iteration: 563 | Classification loss: 0.13265 | Regression loss: 0.13460 | Running loss: 0.38655\n","Epoch: 0 | Iteration: 564 | Classification loss: 0.28249 | Regression loss: 0.25361 | Running loss: 0.38711\n","Epoch: 0 | Iteration: 565 | Classification loss: 0.28091 | Regression loss: 0.07668 | Running loss: 0.38781\n","Epoch: 0 | Iteration: 566 | Classification loss: 0.29100 | Regression loss: 0.35433 | Running loss: 0.38791\n","Epoch: 0 | Iteration: 567 | Classification loss: 0.24448 | Regression loss: 0.20707 | Running loss: 0.38881\n","Epoch: 0 | Iteration: 568 | Classification loss: 0.44060 | Regression loss: 0.42263 | Running loss: 0.38980\n","Epoch: 0 | Iteration: 569 | Classification loss: 0.28956 | Regression loss: 0.15072 | Running loss: 0.39022\n","Epoch: 0 | Iteration: 570 | Classification loss: 0.00000 | Regression loss: 0.00061 | Running loss: 0.38913\n","Epoch: 0 | Iteration: 571 | Classification loss: 0.07039 | Regression loss: 0.11700 | Running loss: 0.38950\n","Epoch: 0 | Iteration: 572 | Classification loss: 0.40603 | Regression loss: 0.20728 | Running loss: 0.38907\n","Epoch: 0 | Iteration: 573 | Classification loss: 0.39301 | Regression loss: 0.28143 | Running loss: 0.38907\n","Epoch: 0 | Iteration: 574 | Classification loss: 0.00007 | Regression loss: 0.00049 | Running loss: 0.38861\n","Epoch: 0 | Iteration: 575 | Classification loss: 0.28185 | Regression loss: 0.48963 | Running loss: 0.39015\n","Epoch: 0 | Iteration: 576 | Classification loss: 0.08474 | Regression loss: 0.10405 | Running loss: 0.38993\n","Epoch: 0 | Iteration: 577 | Classification loss: 0.13857 | Regression loss: 0.10623 | Running loss: 0.38943\n","Epoch: 0 | Iteration: 578 | Classification loss: 0.19864 | Regression loss: 0.26858 | Running loss: 0.38976\n","Epoch: 0 | Iteration: 579 | Classification loss: 0.16973 | Regression loss: 0.13260 | Running loss: 0.38978\n","Epoch: 0 | Iteration: 580 | Classification loss: 0.28905 | Regression loss: 0.18883 | Running loss: 0.38957\n","Epoch: 0 | Iteration: 581 | Classification loss: 0.11829 | Regression loss: 0.15999 | Running loss: 0.39012\n","Epoch: 0 | Iteration: 582 | Classification loss: 0.00000 | Regression loss: 0.00022 | Running loss: 0.38969\n","Epoch: 0 | Iteration: 583 | Classification loss: 0.00000 | Regression loss: 0.00026 | Running loss: 0.38717\n","Epoch: 0 | Iteration: 584 | Classification loss: 0.00000 | Regression loss: 0.00030 | Running loss: 0.38669\n","Epoch: 0 | Iteration: 585 | Classification loss: 0.18252 | Regression loss: 0.07748 | Running loss: 0.38680\n","Epoch: 0 | Iteration: 586 | Classification loss: 0.17795 | Regression loss: 0.05336 | Running loss: 0.38727\n","Epoch: 0 | Iteration: 587 | Classification loss: 0.32424 | Regression loss: 0.23159 | Running loss: 0.38793\n","Epoch: 0 | Iteration: 588 | Classification loss: 0.32687 | Regression loss: 0.20176 | Running loss: 0.38869\n","Epoch: 0 | Iteration: 589 | Classification loss: 0.30210 | Regression loss: 0.39368 | Running loss: 0.38922\n","Epoch: 0 | Iteration: 590 | Classification loss: 0.14874 | Regression loss: 0.19983 | Running loss: 0.38991\n","Epoch: 0 | Iteration: 591 | Classification loss: 0.28632 | Regression loss: 0.45186 | Running loss: 0.39090\n","Epoch: 0 | Iteration: 592 | Classification loss: 0.16310 | Regression loss: 0.12821 | Running loss: 0.38965\n","Epoch: 0 | Iteration: 593 | Classification loss: 0.07149 | Regression loss: 0.12438 | Running loss: 0.38947\n","Epoch: 0 | Iteration: 594 | Classification loss: 0.33595 | Regression loss: 0.35371 | Running loss: 0.39014\n","Epoch: 0 | Iteration: 595 | Classification loss: 0.06111 | Regression loss: 0.05873 | Running loss: 0.39038\n","Epoch: 0 | Iteration: 596 | Classification loss: 0.27400 | Regression loss: 0.15712 | Running loss: 0.38996\n","Epoch: 0 | Iteration: 597 | Classification loss: 0.17232 | Regression loss: 0.36921 | Running loss: 0.39047\n","Epoch: 0 | Iteration: 598 | Classification loss: 0.16022 | Regression loss: 0.12537 | Running loss: 0.39048\n","Epoch: 0 | Iteration: 599 | Classification loss: 0.10064 | Regression loss: 0.18417 | Running loss: 0.38944\n","Epoch: 0 | Iteration: 600 | Classification loss: 0.14318 | Regression loss: 0.12760 | Running loss: 0.38856\n","Epoch: 0 | Iteration: 601 | Classification loss: 0.35746 | Regression loss: 0.23035 | Running loss: 0.38858\n","Epoch: 0 | Iteration: 602 | Classification loss: 0.00001 | Regression loss: 0.00065 | Running loss: 0.38763\n","Epoch: 0 | Iteration: 603 | Classification loss: 0.43120 | Regression loss: 0.15326 | Running loss: 0.38879\n","Epoch: 0 | Iteration: 604 | Classification loss: 0.24030 | Regression loss: 0.24761 | Running loss: 0.38957\n","Epoch: 0 | Iteration: 605 | Classification loss: 0.02807 | Regression loss: 0.00000 | Running loss: 0.38842\n","Epoch: 0 | Iteration: 606 | Classification loss: 0.04349 | Regression loss: 0.10105 | Running loss: 0.38871\n","Epoch: 0 | Iteration: 607 | Classification loss: 0.14684 | Regression loss: 0.09796 | Running loss: 0.38915\n","Epoch: 0 | Iteration: 608 | Classification loss: 0.00001 | Regression loss: 0.00075 | Running loss: 0.38879\n","Epoch: 0 | Iteration: 609 | Classification loss: 0.12969 | Regression loss: 0.16182 | Running loss: 0.38906\n","Epoch: 0 | Iteration: 610 | Classification loss: 0.25477 | Regression loss: 0.22777 | Running loss: 0.38927\n","Epoch: 0 | Iteration: 611 | Classification loss: 0.20389 | Regression loss: 0.08827 | Running loss: 0.38985\n","Epoch: 0 | Iteration: 612 | Classification loss: 0.05187 | Regression loss: 0.00000 | Running loss: 0.38873\n","Epoch: 0 | Iteration: 613 | Classification loss: 0.09374 | Regression loss: 0.03163 | Running loss: 0.38811\n","Epoch: 0 | Iteration: 614 | Classification loss: 0.13616 | Regression loss: 0.12072 | Running loss: 0.38748\n","Epoch: 0 | Iteration: 615 | Classification loss: 0.00000 | Regression loss: 0.00025 | Running loss: 0.38640\n","Epoch: 0 | Iteration: 616 | Classification loss: 0.00000 | Regression loss: 0.00060 | Running loss: 0.38478\n","Epoch: 0 | Iteration: 617 | Classification loss: 0.31157 | Regression loss: 0.15210 | Running loss: 0.38570\n","Epoch: 0 | Iteration: 618 | Classification loss: 0.15140 | Regression loss: 0.08333 | Running loss: 0.38617\n","Epoch: 0 | Iteration: 619 | Classification loss: 0.12874 | Regression loss: 0.09736 | Running loss: 0.38542\n","Epoch: 0 | Iteration: 620 | Classification loss: 0.16115 | Regression loss: 0.03978 | Running loss: 0.38465\n","Epoch: 0 | Iteration: 621 | Classification loss: 0.21879 | Regression loss: 0.09811 | Running loss: 0.38498\n","Epoch: 0 | Iteration: 622 | Classification loss: 0.41195 | Regression loss: 0.35610 | Running loss: 0.38610\n","Epoch: 0 | Iteration: 623 | Classification loss: 0.14557 | Regression loss: 0.21923 | Running loss: 0.38500\n","Epoch: 0 | Iteration: 624 | Classification loss: 0.00002 | Regression loss: 0.00018 | Running loss: 0.38372\n","Epoch: 0 | Iteration: 625 | Classification loss: 0.17315 | Regression loss: 0.20764 | Running loss: 0.38374\n","Epoch: 0 | Iteration: 626 | Classification loss: 0.37575 | Regression loss: 0.36897 | Running loss: 0.38458\n","Epoch: 0 | Iteration: 627 | Classification loss: 0.01238 | Regression loss: 0.02496 | Running loss: 0.38364\n","Epoch: 0 | Iteration: 628 | Classification loss: 0.18158 | Regression loss: 0.25717 | Running loss: 0.38413\n","Epoch: 0 | Iteration: 629 | Classification loss: 0.05100 | Regression loss: 0.00000 | Running loss: 0.38383\n","Epoch: 0 | Iteration: 630 | Classification loss: 0.45449 | Regression loss: 0.18784 | Running loss: 0.38511\n","Epoch: 0 | Iteration: 631 | Classification loss: 0.35919 | Regression loss: 0.48394 | Running loss: 0.38533\n","Epoch: 0 | Iteration: 632 | Classification loss: 0.49154 | Regression loss: 0.58006 | Running loss: 0.38655\n","Epoch: 0 | Iteration: 633 | Classification loss: 0.78652 | Regression loss: 0.57673 | Running loss: 0.38737\n","Epoch: 0 | Iteration: 634 | Classification loss: 0.09608 | Regression loss: 0.08680 | Running loss: 0.38721\n","Epoch: 0 | Iteration: 635 | Classification loss: 0.28718 | Regression loss: 0.31226 | Running loss: 0.38736\n","Epoch: 0 | Iteration: 636 | Classification loss: 0.28739 | Regression loss: 0.22041 | Running loss: 0.38751\n","Epoch: 0 | Iteration: 637 | Classification loss: 0.20802 | Regression loss: 0.14978 | Running loss: 0.38772\n","Epoch: 0 | Iteration: 638 | Classification loss: 0.06524 | Regression loss: 0.07083 | Running loss: 0.38684\n","Epoch: 0 | Iteration: 639 | Classification loss: 0.38154 | Regression loss: 0.12810 | Running loss: 0.38696\n","Epoch: 0 | Iteration: 640 | Classification loss: 0.16403 | Regression loss: 0.09124 | Running loss: 0.38688\n","Epoch: 0 | Iteration: 641 | Classification loss: 0.12434 | Regression loss: 0.08032 | Running loss: 0.38729\n","Epoch: 0 | Iteration: 642 | Classification loss: 0.16310 | Regression loss: 0.07681 | Running loss: 0.38706\n","Epoch: 0 | Iteration: 643 | Classification loss: 0.18429 | Regression loss: 0.27175 | Running loss: 0.38665\n","Epoch: 0 | Iteration: 644 | Classification loss: 0.00177 | Regression loss: 0.00000 | Running loss: 0.38505\n","Epoch: 0 | Iteration: 645 | Classification loss: 0.24076 | Regression loss: 0.09130 | Running loss: 0.38517\n","Epoch: 0 | Iteration: 646 | Classification loss: 0.15384 | Regression loss: 0.07958 | Running loss: 0.38564\n","Epoch: 0 | Iteration: 647 | Classification loss: 0.00000 | Regression loss: 0.00043 | Running loss: 0.38479\n","Epoch: 0 | Iteration: 648 | Classification loss: 0.07006 | Regression loss: 0.16488 | Running loss: 0.38438\n","Epoch: 0 | Iteration: 649 | Classification loss: 0.07482 | Regression loss: 0.00000 | Running loss: 0.38338\n","Epoch: 0 | Iteration: 650 | Classification loss: 0.54483 | Regression loss: 0.30876 | Running loss: 0.38454\n","Epoch: 0 | Iteration: 651 | Classification loss: 0.21207 | Regression loss: 0.07280 | Running loss: 0.38433\n","Epoch: 0 | Iteration: 652 | Classification loss: 0.17958 | Regression loss: 0.14767 | Running loss: 0.38491\n","Epoch: 0 | Iteration: 653 | Classification loss: 0.20671 | Regression loss: 0.19075 | Running loss: 0.38403\n","Epoch: 0 | Iteration: 654 | Classification loss: 0.20004 | Regression loss: 0.16532 | Running loss: 0.38338\n","Epoch: 0 | Iteration: 655 | Classification loss: 0.04443 | Regression loss: 0.19392 | Running loss: 0.38177\n","Epoch: 0 | Iteration: 656 | Classification loss: 0.36331 | Regression loss: 0.22419 | Running loss: 0.38294\n","Epoch: 0 | Iteration: 657 | Classification loss: 0.59528 | Regression loss: 0.45333 | Running loss: 0.38363\n","Epoch: 0 | Iteration: 658 | Classification loss: 0.09470 | Regression loss: 0.11116 | Running loss: 0.38317\n","Epoch: 0 | Iteration: 659 | Classification loss: 0.25794 | Regression loss: 0.10849 | Running loss: 0.38282\n","Epoch: 0 | Iteration: 660 | Classification loss: 0.25131 | Regression loss: 0.17557 | Running loss: 0.38247\n","Epoch: 0 | Iteration: 661 | Classification loss: 0.03455 | Regression loss: 0.08800 | Running loss: 0.38199\n","Epoch: 0 | Iteration: 662 | Classification loss: 0.00002 | Regression loss: 0.00034 | Running loss: 0.38199\n","Epoch: 0 | Iteration: 663 | Classification loss: 0.09770 | Regression loss: 0.12612 | Running loss: 0.38129\n","Epoch: 0 | Iteration: 664 | Classification loss: 0.07883 | Regression loss: 0.10717 | Running loss: 0.38049\n","Epoch: 0 | Iteration: 665 | Classification loss: 0.56150 | Regression loss: 0.44661 | Running loss: 0.38129\n","Epoch: 0 | Iteration: 666 | Classification loss: 0.18458 | Regression loss: 0.05476 | Running loss: 0.38084\n","Epoch: 0 | Iteration: 667 | Classification loss: 0.28984 | Regression loss: 0.22280 | Running loss: 0.38117\n","Epoch: 0 | Iteration: 668 | Classification loss: 0.12854 | Regression loss: 0.05259 | Running loss: 0.38072\n","Epoch: 0 | Iteration: 669 | Classification loss: 0.20482 | Regression loss: 0.20716 | Running loss: 0.38112\n","Epoch: 0 | Iteration: 670 | Classification loss: 0.40947 | Regression loss: 0.25111 | Running loss: 0.38170\n","Epoch: 0 | Iteration: 671 | Classification loss: 0.31047 | Regression loss: 0.00000 | Running loss: 0.38164\n","Epoch: 0 | Iteration: 672 | Classification loss: 0.00001 | Regression loss: 0.00039 | Running loss: 0.38026\n","Epoch: 0 | Iteration: 673 | Classification loss: 0.16503 | Regression loss: 0.12825 | Running loss: 0.37980\n","Epoch: 0 | Iteration: 674 | Classification loss: 0.21395 | Regression loss: 0.13644 | Running loss: 0.38009\n","Epoch: 0 | Iteration: 675 | Classification loss: 0.14082 | Regression loss: 0.11773 | Running loss: 0.38061\n","Epoch: 0 | Iteration: 676 | Classification loss: 0.06283 | Regression loss: 0.13664 | Running loss: 0.38042\n","Epoch: 0 | Iteration: 677 | Classification loss: 0.76127 | Regression loss: 0.44332 | Running loss: 0.38234\n","Epoch: 0 | Iteration: 678 | Classification loss: 0.34164 | Regression loss: 0.23763 | Running loss: 0.38214\n","Epoch: 0 | Iteration: 679 | Classification loss: 0.79994 | Regression loss: 0.34108 | Running loss: 0.38359\n","Epoch: 0 | Iteration: 680 | Classification loss: 0.28065 | Regression loss: 0.23806 | Running loss: 0.38377\n","Epoch: 0 | Iteration: 681 | Classification loss: 0.90098 | Regression loss: 0.20477 | Running loss: 0.38534\n","Epoch: 0 | Iteration: 682 | Classification loss: 0.01932 | Regression loss: 0.03723 | Running loss: 0.38500\n","Epoch: 0 | Iteration: 683 | Classification loss: 0.12389 | Regression loss: 0.06125 | Running loss: 0.38458\n","Epoch: 0 | Iteration: 684 | Classification loss: 0.65778 | Regression loss: 0.37665 | Running loss: 0.38530\n","Epoch: 0 | Iteration: 685 | Classification loss: 0.19011 | Regression loss: 0.06275 | Running loss: 0.38494\n","Epoch: 0 | Iteration: 686 | Classification loss: 0.00000 | Regression loss: 0.00012 | Running loss: 0.38344\n","Epoch: 0 | Iteration: 687 | Classification loss: 0.51783 | Regression loss: 0.29268 | Running loss: 0.38474\n","Epoch: 0 | Iteration: 688 | Classification loss: 0.00000 | Regression loss: 0.00034 | Running loss: 0.38364\n","Epoch: 0 | Iteration: 689 | Classification loss: 0.00019 | Regression loss: 0.00021 | Running loss: 0.38364\n","Epoch: 0 | Iteration: 690 | Classification loss: 0.17196 | Regression loss: 0.05127 | Running loss: 0.38356\n","Epoch: 0 | Iteration: 691 | Classification loss: 0.13256 | Regression loss: 0.16333 | Running loss: 0.38360\n","Epoch: 0 | Iteration: 692 | Classification loss: 0.09162 | Regression loss: 0.11813 | Running loss: 0.38402\n","Epoch: 0 | Iteration: 693 | Classification loss: 0.25669 | Regression loss: 0.19217 | Running loss: 0.38429\n","Epoch: 0 | Iteration: 694 | Classification loss: 0.16991 | Regression loss: 0.36940 | Running loss: 0.38482\n","Epoch: 0 | Iteration: 695 | Classification loss: 0.16797 | Regression loss: 0.21474 | Running loss: 0.38460\n","Epoch: 0 | Iteration: 696 | Classification loss: 0.00000 | Regression loss: 0.00014 | Running loss: 0.38460\n","Epoch: 0 | Iteration: 697 | Classification loss: 0.49969 | Regression loss: 0.50758 | Running loss: 0.38434\n","Epoch: 0 | Iteration: 698 | Classification loss: 0.53218 | Regression loss: 0.56069 | Running loss: 0.38610\n","Epoch: 0 | Iteration: 699 | Classification loss: 0.72517 | Regression loss: 0.53413 | Running loss: 0.38834\n","Epoch: 0 | Iteration: 700 | Classification loss: 0.24714 | Regression loss: 0.10762 | Running loss: 0.38857\n","Epoch: 0 | Iteration: 701 | Classification loss: 0.07569 | Regression loss: 0.07281 | Running loss: 0.38844\n","Epoch: 0 | Iteration: 702 | Classification loss: 0.34046 | Regression loss: 0.20904 | Running loss: 0.38895\n","Epoch: 0 | Iteration: 703 | Classification loss: 0.18314 | Regression loss: 0.36221 | Running loss: 0.38895\n","Epoch: 0 | Iteration: 704 | Classification loss: 0.00018 | Regression loss: 0.00053 | Running loss: 0.38868\n","Epoch: 0 | Iteration: 705 | Classification loss: 0.22170 | Regression loss: 0.14188 | Running loss: 0.38905\n","Epoch: 0 | Iteration: 706 | Classification loss: 0.19994 | Regression loss: 0.36255 | Running loss: 0.38872\n","Epoch: 0 | Iteration: 707 | Classification loss: 0.22142 | Regression loss: 0.15078 | Running loss: 0.38793\n","Epoch: 0 | Iteration: 708 | Classification loss: 0.42417 | Regression loss: 0.12342 | Running loss: 0.38902\n","Epoch: 0 | Iteration: 709 | Classification loss: 0.10655 | Regression loss: 0.08009 | Running loss: 0.38865\n","Epoch: 0 | Iteration: 710 | Classification loss: 0.10849 | Regression loss: 0.00000 | Running loss: 0.38845\n","Epoch: 0 | Iteration: 711 | Classification loss: 0.00064 | Regression loss: 0.00039 | Running loss: 0.38738\n","Epoch: 0 | Iteration: 712 | Classification loss: 0.12236 | Regression loss: 0.11840 | Running loss: 0.38749\n","Epoch: 0 | Iteration: 713 | Classification loss: 0.06590 | Regression loss: 0.02477 | Running loss: 0.38734\n","Epoch: 0 | Iteration: 714 | Classification loss: 0.24693 | Regression loss: 0.28841 | Running loss: 0.38769\n","Epoch: 0 | Iteration: 715 | Classification loss: 0.07434 | Regression loss: 0.20088 | Running loss: 0.38824\n","Epoch: 0 | Iteration: 716 | Classification loss: 0.29118 | Regression loss: 0.37683 | Running loss: 0.38829\n","Epoch: 0 | Iteration: 717 | Classification loss: 0.17150 | Regression loss: 0.20174 | Running loss: 0.38842\n","Epoch: 0 | Iteration: 718 | Classification loss: 0.17304 | Regression loss: 0.12147 | Running loss: 0.38787\n","Epoch: 0 | Iteration: 719 | Classification loss: 0.24854 | Regression loss: 0.17206 | Running loss: 0.38871\n","Epoch: 0 | Iteration: 720 | Classification loss: 0.11193 | Regression loss: 0.19193 | Running loss: 0.38860\n","Epoch: 0 | Iteration: 721 | Classification loss: 0.14641 | Regression loss: 0.05510 | Running loss: 0.38900\n","Epoch: 0 | Iteration: 722 | Classification loss: 0.00016 | Regression loss: 0.00042 | Running loss: 0.38839\n","Epoch: 0 | Iteration: 723 | Classification loss: 0.22934 | Regression loss: 0.15007 | Running loss: 0.38814\n","Epoch: 0 | Iteration: 724 | Classification loss: 0.18817 | Regression loss: 0.16824 | Running loss: 0.38885\n","Epoch: 0 | Iteration: 725 | Classification loss: 0.18340 | Regression loss: 0.09537 | Running loss: 0.38845\n","Epoch: 0 | Iteration: 726 | Classification loss: 0.19587 | Regression loss: 0.21239 | Running loss: 0.38894\n","Epoch: 0 | Iteration: 727 | Classification loss: 0.17467 | Regression loss: 0.13049 | Running loss: 0.38814\n","Epoch: 0 | Iteration: 728 | Classification loss: 0.25551 | Regression loss: 0.09266 | Running loss: 0.38807\n","Epoch: 0 | Iteration: 729 | Classification loss: 0.34936 | Regression loss: 0.45211 | Running loss: 0.38930\n","Epoch: 0 | Iteration: 730 | Classification loss: 0.37921 | Regression loss: 0.21557 | Running loss: 0.38984\n","Epoch: 0 | Iteration: 731 | Classification loss: 0.10617 | Regression loss: 0.13097 | Running loss: 0.38995\n","Epoch: 0 | Iteration: 732 | Classification loss: 0.00000 | Regression loss: 0.00036 | Running loss: 0.38962\n","Epoch: 0 | Iteration: 733 | Classification loss: 0.10224 | Regression loss: 0.11376 | Running loss: 0.38964\n","Epoch: 0 | Iteration: 734 | Classification loss: 0.17121 | Regression loss: 0.20768 | Running loss: 0.39004\n","Epoch: 0 | Iteration: 735 | Classification loss: 0.38401 | Regression loss: 0.29533 | Running loss: 0.39108\n","Epoch: 0 | Iteration: 736 | Classification loss: 0.14714 | Regression loss: 0.18267 | Running loss: 0.39094\n","Epoch: 0 | Iteration: 737 | Classification loss: 0.29445 | Regression loss: 0.42782 | Running loss: 0.39186\n","Epoch: 0 | Iteration: 738 | Classification loss: 0.14984 | Regression loss: 0.15828 | Running loss: 0.39248\n","Epoch: 0 | Iteration: 739 | Classification loss: 0.10409 | Regression loss: 0.06518 | Running loss: 0.39095\n","Epoch: 0 | Iteration: 740 | Classification loss: 0.15988 | Regression loss: 0.13941 | Running loss: 0.38946\n","Epoch: 0 | Iteration: 741 | Classification loss: 0.41260 | Regression loss: 0.21780 | Running loss: 0.38871\n","Epoch: 0 | Iteration: 742 | Classification loss: 0.14114 | Regression loss: 0.12671 | Running loss: 0.38810\n","Epoch: 0 | Iteration: 743 | Classification loss: 0.15651 | Regression loss: 0.10752 | Running loss: 0.38736\n","Epoch: 0 | Iteration: 744 | Classification loss: 0.18621 | Regression loss: 0.18528 | Running loss: 0.38768\n","Epoch: 0 | Iteration: 745 | Classification loss: 0.15861 | Regression loss: 0.27960 | Running loss: 0.38762\n","Epoch: 0 | Iteration: 746 | Classification loss: 0.23615 | Regression loss: 0.11578 | Running loss: 0.38646\n","Epoch: 0 | Iteration: 747 | Classification loss: 0.16492 | Regression loss: 0.18343 | Running loss: 0.38533\n","Epoch: 0 | Iteration: 748 | Classification loss: 0.09869 | Regression loss: 0.03354 | Running loss: 0.38488\n","Epoch: 0 | Iteration: 749 | Classification loss: 0.32315 | Regression loss: 0.11536 | Running loss: 0.38545\n","Epoch: 0 | Iteration: 750 | Classification loss: 0.08404 | Regression loss: 0.07163 | Running loss: 0.38440\n","Epoch: 0 | Iteration: 751 | Classification loss: 0.02480 | Regression loss: 0.00000 | Running loss: 0.38314\n","Epoch: 0 | Iteration: 752 | Classification loss: 0.15556 | Regression loss: 0.15581 | Running loss: 0.38332\n","Epoch: 0 | Iteration: 753 | Classification loss: 0.19026 | Regression loss: 0.18971 | Running loss: 0.38340\n","Epoch: 0 | Iteration: 754 | Classification loss: 0.00000 | Regression loss: 0.00014 | Running loss: 0.38233\n","Epoch: 0 | Iteration: 755 | Classification loss: 0.01989 | Regression loss: 0.04246 | Running loss: 0.38124\n","Epoch: 0 | Iteration: 756 | Classification loss: 0.33083 | Regression loss: 0.27590 | Running loss: 0.38159\n","Epoch: 0 | Iteration: 757 | Classification loss: 0.50533 | Regression loss: 0.37498 | Running loss: 0.38249\n","Epoch: 0 | Iteration: 758 | Classification loss: 0.13975 | Regression loss: 0.15491 | Running loss: 0.38308\n","Epoch: 0 | Iteration: 759 | Classification loss: 0.00001 | Regression loss: 0.00030 | Running loss: 0.38308\n","Epoch: 0 | Iteration: 760 | Classification loss: 0.20180 | Regression loss: 0.17434 | Running loss: 0.38322\n","Epoch: 0 | Iteration: 761 | Classification loss: 0.42520 | Regression loss: 0.17575 | Running loss: 0.38336\n","Epoch: 0 | Iteration: 762 | Classification loss: 0.09650 | Regression loss: 0.03746 | Running loss: 0.38362\n","Epoch: 0 | Iteration: 763 | Classification loss: 0.22517 | Regression loss: 0.21731 | Running loss: 0.38406\n","Epoch: 0 | Iteration: 764 | Classification loss: 0.34315 | Regression loss: 0.36175 | Running loss: 0.38406\n","Epoch: 0 | Iteration: 765 | Classification loss: 0.28196 | Regression loss: 0.30457 | Running loss: 0.38477\n","Epoch: 0 | Iteration: 766 | Classification loss: 0.27109 | Regression loss: 0.09533 | Running loss: 0.38497\n","Epoch: 0 | Iteration: 767 | Classification loss: 0.23738 | Regression loss: 0.22875 | Running loss: 0.38589\n","Epoch: 0 | Iteration: 768 | Classification loss: 0.24801 | Regression loss: 0.14814 | Running loss: 0.38668\n","Epoch: 0 | Iteration: 769 | Classification loss: 0.17966 | Regression loss: 0.21514 | Running loss: 0.38614\n","Epoch: 0 | Iteration: 770 | Classification loss: 0.32856 | Regression loss: 0.30542 | Running loss: 0.38679\n","Epoch: 0 | Iteration: 771 | Classification loss: 0.53659 | Regression loss: 0.09697 | Running loss: 0.38703\n","Epoch: 0 | Iteration: 772 | Classification loss: 0.25451 | Regression loss: 0.10486 | Running loss: 0.38775\n","Epoch: 0 | Iteration: 773 | Classification loss: 0.14177 | Regression loss: 0.10365 | Running loss: 0.38731\n","Epoch: 0 | Iteration: 774 | Classification loss: 0.10352 | Regression loss: 0.10461 | Running loss: 0.38642\n","Epoch: 0 | Iteration: 775 | Classification loss: 0.18190 | Regression loss: 0.16421 | Running loss: 0.38711\n","Epoch: 0 | Iteration: 776 | Classification loss: 0.00000 | Regression loss: 0.00025 | Running loss: 0.38581\n","Epoch: 0 | Iteration: 777 | Classification loss: 0.12246 | Regression loss: 0.23277 | Running loss: 0.38585\n","Epoch: 0 | Iteration: 778 | Classification loss: 0.09102 | Regression loss: 0.15864 | Running loss: 0.38522\n","Epoch: 0 | Iteration: 779 | Classification loss: 0.59226 | Regression loss: 0.17818 | Running loss: 0.38609\n","Epoch: 0 | Iteration: 780 | Classification loss: 0.14650 | Regression loss: 0.27678 | Running loss: 0.38498\n","0\n","Evaluating dataset\n","\n","mAP:\n","bird: 0.12678435800755566\n","bobcat: 0.042414529914529916\n","car: 1.0\n","cat: 0.015676169894439367\n","raccoon: 0.011896629093511722\n","rabbit: 0.04746317512274959\n","coyote: 0.027961253707991258\n","squirrel: 0.3273254128421485\n","0.3779794983180862\n","---------------------------------------\n","Epoch: 1 | Iteration: 0 | Classification loss: 0.38038 | Regression loss: 0.18761 | Running loss: 0.38510\n","Epoch: 1 | Iteration: 1 | Classification loss: 0.22814 | Regression loss: 0.16194 | Running loss: 0.38557\n","Epoch: 1 | Iteration: 2 | Classification loss: 0.15721 | Regression loss: 0.13441 | Running loss: 0.38551\n","Epoch: 1 | Iteration: 3 | Classification loss: 0.12136 | Regression loss: 0.24156 | Running loss: 0.38616\n","Epoch: 1 | Iteration: 4 | Classification loss: 0.61475 | Regression loss: 0.27214 | Running loss: 0.38764\n","Epoch: 1 | Iteration: 5 | Classification loss: 0.20793 | Regression loss: 0.43855 | Running loss: 0.38817\n","Epoch: 1 | Iteration: 6 | Classification loss: 0.00000 | Regression loss: 0.00017 | Running loss: 0.38717\n","Epoch: 1 | Iteration: 7 | Classification loss: 0.25345 | Regression loss: 0.28164 | Running loss: 0.38737\n","Epoch: 1 | Iteration: 8 | Classification loss: 0.17600 | Regression loss: 0.38452 | Running loss: 0.38660\n","Epoch: 1 | Iteration: 9 | Classification loss: 0.26301 | Regression loss: 0.23123 | Running loss: 0.38628\n","Epoch: 1 | Iteration: 10 | Classification loss: 0.25518 | Regression loss: 0.29004 | Running loss: 0.38724\n","Epoch: 1 | Iteration: 11 | Classification loss: 0.18805 | Regression loss: 0.24842 | Running loss: 0.38743\n","Epoch: 1 | Iteration: 12 | Classification loss: 0.27671 | Regression loss: 0.13560 | Running loss: 0.38747\n","Epoch: 1 | Iteration: 13 | Classification loss: 0.06277 | Regression loss: 0.06406 | Running loss: 0.38733\n","Epoch: 1 | Iteration: 14 | Classification loss: 0.19336 | Regression loss: 0.22864 | Running loss: 0.38712\n","Epoch: 1 | Iteration: 15 | Classification loss: 0.01174 | Regression loss: 0.00000 | Running loss: 0.38475\n","Epoch: 1 | Iteration: 16 | Classification loss: 0.14313 | Regression loss: 0.28993 | Running loss: 0.38521\n","Epoch: 1 | Iteration: 17 | Classification loss: 0.08371 | Regression loss: 0.14082 | Running loss: 0.38483\n","Epoch: 1 | Iteration: 18 | Classification loss: 0.12264 | Regression loss: 0.17730 | Running loss: 0.38524\n","Epoch: 1 | Iteration: 19 | Classification loss: 0.42608 | Regression loss: 0.38740 | Running loss: 0.38640\n","Epoch: 1 | Iteration: 20 | Classification loss: 0.38561 | Regression loss: 0.28560 | Running loss: 0.38727\n","Epoch: 1 | Iteration: 21 | Classification loss: 0.26921 | Regression loss: 0.14819 | Running loss: 0.38719\n","Epoch: 1 | Iteration: 22 | Classification loss: 0.15614 | Regression loss: 0.20196 | Running loss: 0.38749\n","Epoch: 1 | Iteration: 23 | Classification loss: 0.09709 | Regression loss: 0.05501 | Running loss: 0.38645\n","Epoch: 1 | Iteration: 24 | Classification loss: 0.29034 | Regression loss: 0.16495 | Running loss: 0.38648\n","Epoch: 1 | Iteration: 25 | Classification loss: 0.28490 | Regression loss: 0.08425 | Running loss: 0.38619\n","Epoch: 1 | Iteration: 26 | Classification loss: 0.63604 | Regression loss: 0.15926 | Running loss: 0.38666\n","Epoch: 1 | Iteration: 27 | Classification loss: 0.00001 | Regression loss: 0.00017 | Running loss: 0.38548\n","Epoch: 1 | Iteration: 28 | Classification loss: 0.14640 | Regression loss: 0.14205 | Running loss: 0.38546\n","Epoch: 1 | Iteration: 29 | Classification loss: 0.10173 | Regression loss: 0.17842 | Running loss: 0.38506\n","Epoch: 1 | Iteration: 30 | Classification loss: 0.17497 | Regression loss: 0.16536 | Running loss: 0.38530\n","Epoch: 1 | Iteration: 31 | Classification loss: 0.11453 | Regression loss: 0.13588 | Running loss: 0.38483\n","Epoch: 1 | Iteration: 32 | Classification loss: 0.15615 | Regression loss: 0.08064 | Running loss: 0.38530\n","Epoch: 1 | Iteration: 33 | Classification loss: 0.28126 | Regression loss: 0.27870 | Running loss: 0.38613\n","Epoch: 1 | Iteration: 34 | Classification loss: 0.43326 | Regression loss: 0.09579 | Running loss: 0.38611\n","Epoch: 1 | Iteration: 35 | Classification loss: 0.45147 | Regression loss: 0.11905 | Running loss: 0.38645\n","Epoch: 1 | Iteration: 36 | Classification loss: 0.35393 | Regression loss: 0.44764 | Running loss: 0.38762\n","Epoch: 1 | Iteration: 37 | Classification loss: 0.00006 | Regression loss: 0.00061 | Running loss: 0.38676\n","Epoch: 1 | Iteration: 38 | Classification loss: 0.05133 | Regression loss: 0.04156 | Running loss: 0.38557\n","Epoch: 1 | Iteration: 39 | Classification loss: 0.00000 | Regression loss: 0.00018 | Running loss: 0.38557\n","Epoch: 1 | Iteration: 40 | Classification loss: 0.58393 | Regression loss: 0.60551 | Running loss: 0.38692\n","Epoch: 1 | Iteration: 41 | Classification loss: 0.17331 | Regression loss: 0.38263 | Running loss: 0.38803\n","Epoch: 1 | Iteration: 42 | Classification loss: 0.32825 | Regression loss: 0.25298 | Running loss: 0.38821\n","Epoch: 1 | Iteration: 43 | Classification loss: 0.41602 | Regression loss: 0.26488 | Running loss: 0.38851\n","Epoch: 1 | Iteration: 44 | Classification loss: 0.39812 | Regression loss: 0.43317 | Running loss: 0.38943\n","Epoch: 1 | Iteration: 45 | Classification loss: 0.12499 | Regression loss: 0.06405 | Running loss: 0.38860\n","Epoch: 1 | Iteration: 46 | Classification loss: 0.19410 | Regression loss: 0.12796 | Running loss: 0.38835\n","Epoch: 1 | Iteration: 47 | Classification loss: 0.22261 | Regression loss: 0.11495 | Running loss: 0.38848\n","Epoch: 1 | Iteration: 48 | Classification loss: 0.18392 | Regression loss: 0.18807 | Running loss: 0.38834\n","Epoch: 1 | Iteration: 49 | Classification loss: 0.37824 | Regression loss: 0.58514 | Running loss: 0.38962\n","Epoch: 1 | Iteration: 50 | Classification loss: 0.14600 | Regression loss: 0.09200 | Running loss: 0.38938\n","Epoch: 1 | Iteration: 51 | Classification loss: 0.20096 | Regression loss: 0.09901 | Running loss: 0.38940\n","Epoch: 1 | Iteration: 52 | Classification loss: 0.18259 | Regression loss: 0.13002 | Running loss: 0.38888\n","Epoch: 1 | Iteration: 53 | Classification loss: 0.30663 | Regression loss: 0.18881 | Running loss: 0.38930\n","Epoch: 1 | Iteration: 54 | Classification loss: 0.12770 | Regression loss: 0.12448 | Running loss: 0.38940\n","Epoch: 1 | Iteration: 55 | Classification loss: 0.00957 | Regression loss: 0.00000 | Running loss: 0.38791\n","Epoch: 1 | Iteration: 56 | Classification loss: 0.23488 | Regression loss: 0.27055 | Running loss: 0.38851\n","Epoch: 1 | Iteration: 57 | Classification loss: 0.10157 | Regression loss: 0.13725 | Running loss: 0.38899\n","Epoch: 1 | Iteration: 58 | Classification loss: 0.17399 | Regression loss: 0.18417 | Running loss: 0.38970\n","Epoch: 1 | Iteration: 59 | Classification loss: 0.18796 | Regression loss: 0.18408 | Running loss: 0.39011\n","Epoch: 1 | Iteration: 60 | Classification loss: 0.20058 | Regression loss: 0.10535 | Running loss: 0.39006\n","Epoch: 1 | Iteration: 61 | Classification loss: 0.00005 | Regression loss: 0.00106 | Running loss: 0.38972\n","Epoch: 1 | Iteration: 62 | Classification loss: 0.30488 | Regression loss: 0.20514 | Running loss: 0.38998\n","Epoch: 1 | Iteration: 63 | Classification loss: 0.17648 | Regression loss: 0.16315 | Running loss: 0.39008\n","Epoch: 1 | Iteration: 64 | Classification loss: 0.10153 | Regression loss: 0.08181 | Running loss: 0.38923\n","Epoch: 1 | Iteration: 65 | Classification loss: 0.08740 | Regression loss: 0.16678 | Running loss: 0.38868\n","Epoch: 1 | Iteration: 66 | Classification loss: 0.13949 | Regression loss: 0.16359 | Running loss: 0.38875\n","Epoch: 1 | Iteration: 67 | Classification loss: 0.13845 | Regression loss: 0.20343 | Running loss: 0.38943\n","Epoch: 1 | Iteration: 68 | Classification loss: 0.23856 | Regression loss: 0.24382 | Running loss: 0.38999\n","Epoch: 1 | Iteration: 69 | Classification loss: 0.00000 | Regression loss: 0.00052 | Running loss: 0.38827\n","Epoch: 1 | Iteration: 70 | Classification loss: 0.19040 | Regression loss: 0.10182 | Running loss: 0.38879\n","Epoch: 1 | Iteration: 71 | Classification loss: 0.25673 | Regression loss: 0.17832 | Running loss: 0.38935\n","Epoch: 1 | Iteration: 72 | Classification loss: 0.30041 | Regression loss: 0.20108 | Running loss: 0.39035\n","Epoch: 1 | Iteration: 73 | Classification loss: 0.51431 | Regression loss: 0.39331 | Running loss: 0.39206\n","Epoch: 1 | Iteration: 74 | Classification loss: 0.67674 | Regression loss: 0.57204 | Running loss: 0.39433\n","Epoch: 1 | Iteration: 75 | Classification loss: 0.51690 | Regression loss: 0.34347 | Running loss: 0.39544\n","Epoch: 1 | Iteration: 76 | Classification loss: 0.07538 | Regression loss: 0.03493 | Running loss: 0.39512\n","Epoch: 1 | Iteration: 77 | Classification loss: 0.45615 | Regression loss: 0.56751 | Running loss: 0.39668\n","Epoch: 1 | Iteration: 78 | Classification loss: 0.26513 | Regression loss: 0.11602 | Running loss: 0.39555\n","Epoch: 1 | Iteration: 79 | Classification loss: 0.12397 | Regression loss: 0.31978 | Running loss: 0.39604\n","Epoch: 1 | Iteration: 80 | Classification loss: 0.27676 | Regression loss: 0.13973 | Running loss: 0.39611\n","Epoch: 1 | Iteration: 81 | Classification loss: 0.27578 | Regression loss: 0.27178 | Running loss: 0.39690\n","Epoch: 1 | Iteration: 82 | Classification loss: 0.39085 | Regression loss: 0.31495 | Running loss: 0.39748\n","Epoch: 1 | Iteration: 83 | Classification loss: 0.16322 | Regression loss: 0.10487 | Running loss: 0.39734\n","Epoch: 1 | Iteration: 84 | Classification loss: 0.03237 | Regression loss: 0.04155 | Running loss: 0.39691\n","Epoch: 1 | Iteration: 85 | Classification loss: 0.30065 | Regression loss: 0.40580 | Running loss: 0.39795\n","Epoch: 1 | Iteration: 86 | Classification loss: 0.00000 | Regression loss: 0.00050 | Running loss: 0.39712\n","Epoch: 1 | Iteration: 87 | Classification loss: 0.12015 | Regression loss: 0.09014 | Running loss: 0.39649\n","Epoch: 1 | Iteration: 88 | Classification loss: 0.06850 | Regression loss: 0.04147 | Running loss: 0.39545\n","Epoch: 1 | Iteration: 89 | Classification loss: 0.09621 | Regression loss: 0.01801 | Running loss: 0.39486\n","Epoch: 1 | Iteration: 90 | Classification loss: 0.42690 | Regression loss: 0.35569 | Running loss: 0.39572\n","Epoch: 1 | Iteration: 91 | Classification loss: 0.13693 | Regression loss: 0.36384 | Running loss: 0.39615\n","Epoch: 1 | Iteration: 92 | Classification loss: 0.22561 | Regression loss: 0.11806 | Running loss: 0.39509\n","Epoch: 1 | Iteration: 93 | Classification loss: 0.31905 | Regression loss: 0.09276 | Running loss: 0.39406\n","Epoch: 1 | Iteration: 94 | Classification loss: 0.04954 | Regression loss: 0.02023 | Running loss: 0.39214\n","Epoch: 1 | Iteration: 95 | Classification loss: 0.51936 | Regression loss: 0.44588 | Running loss: 0.39326\n","Epoch: 1 | Iteration: 96 | Classification loss: 0.22876 | Regression loss: 0.17815 | Running loss: 0.39365\n","Epoch: 1 | Iteration: 97 | Classification loss: 0.14990 | Regression loss: 0.16019 | Running loss: 0.39383\n","Epoch: 1 | Iteration: 98 | Classification loss: 0.24592 | Regression loss: 0.18075 | Running loss: 0.39390\n","Epoch: 1 | Iteration: 99 | Classification loss: 0.46773 | Regression loss: 0.26962 | Running loss: 0.39463\n","Epoch: 1 | Iteration: 100 | Classification loss: 0.00001 | Regression loss: 0.00023 | Running loss: 0.39414\n","Epoch: 1 | Iteration: 101 | Classification loss: 0.08614 | Regression loss: 0.00000 | Running loss: 0.39309\n","Epoch: 1 | Iteration: 102 | Classification loss: 0.09385 | Regression loss: 0.07940 | Running loss: 0.39343\n","Epoch: 1 | Iteration: 103 | Classification loss: 0.13294 | Regression loss: 0.10656 | Running loss: 0.39322\n","Epoch: 1 | Iteration: 104 | Classification loss: 0.16454 | Regression loss: 0.28053 | Running loss: 0.39411\n","Epoch: 1 | Iteration: 105 | Classification loss: 0.08426 | Regression loss: 0.03343 | Running loss: 0.39389\n","Epoch: 1 | Iteration: 106 | Classification loss: 0.06091 | Regression loss: 0.10253 | Running loss: 0.39322\n","Epoch: 1 | Iteration: 107 | Classification loss: 0.17872 | Regression loss: 0.31619 | Running loss: 0.39368\n","Epoch: 1 | Iteration: 108 | Classification loss: 0.21932 | Regression loss: 0.23115 | Running loss: 0.39391\n","Epoch: 1 | Iteration: 109 | Classification loss: 0.12358 | Regression loss: 0.27245 | Running loss: 0.39430\n","Epoch: 1 | Iteration: 110 | Classification loss: 0.25899 | Regression loss: 0.52826 | Running loss: 0.39581\n","Epoch: 1 | Iteration: 111 | Classification loss: 0.09729 | Regression loss: 0.04225 | Running loss: 0.39536\n","Epoch: 1 | Iteration: 112 | Classification loss: 0.44142 | Regression loss: 0.71343 | Running loss: 0.39754\n","Epoch: 1 | Iteration: 113 | Classification loss: 0.08899 | Regression loss: 0.10691 | Running loss: 0.39733\n","Epoch: 1 | Iteration: 114 | Classification loss: 0.20390 | Regression loss: 0.15001 | Running loss: 0.39763\n","Epoch: 1 | Iteration: 115 | Classification loss: 0.23052 | Regression loss: 0.09663 | Running loss: 0.39514\n","Epoch: 1 | Iteration: 116 | Classification loss: 0.00016 | Regression loss: 0.00057 | Running loss: 0.39457\n","Epoch: 1 | Iteration: 117 | Classification loss: 0.15320 | Regression loss: 0.16924 | Running loss: 0.39405\n","Epoch: 1 | Iteration: 118 | Classification loss: 0.20009 | Regression loss: 0.15590 | Running loss: 0.39298\n","Epoch: 1 | Iteration: 119 | Classification loss: 0.16286 | Regression loss: 0.19294 | Running loss: 0.39369\n","Epoch: 1 | Iteration: 120 | Classification loss: 0.26319 | Regression loss: 0.08816 | Running loss: 0.39384\n","Epoch: 1 | Iteration: 121 | Classification loss: 0.16236 | Regression loss: 0.11813 | Running loss: 0.39362\n","Epoch: 1 | Iteration: 122 | Classification loss: 0.02742 | Regression loss: 0.00877 | Running loss: 0.39248\n","Epoch: 1 | Iteration: 123 | Classification loss: 0.34800 | Regression loss: 0.19942 | Running loss: 0.39357\n","Epoch: 1 | Iteration: 124 | Classification loss: 0.16288 | Regression loss: 0.16400 | Running loss: 0.39419\n","Epoch: 1 | Iteration: 125 | Classification loss: 0.20732 | Regression loss: 0.11746 | Running loss: 0.39363\n","Epoch: 1 | Iteration: 126 | Classification loss: 0.06999 | Regression loss: 0.06935 | Running loss: 0.39304\n","Epoch: 1 | Iteration: 127 | Classification loss: 0.25660 | Regression loss: 0.11712 | Running loss: 0.39088\n","Epoch: 1 | Iteration: 128 | Classification loss: 0.11775 | Regression loss: 0.04195 | Running loss: 0.39050\n","Epoch: 1 | Iteration: 129 | Classification loss: 0.00009 | Regression loss: 0.00088 | Running loss: 0.39005\n","Epoch: 1 | Iteration: 130 | Classification loss: 0.42026 | Regression loss: 0.42289 | Running loss: 0.39091\n","Epoch: 1 | Iteration: 131 | Classification loss: 0.37312 | Regression loss: 0.35489 | Running loss: 0.39160\n","Epoch: 1 | Iteration: 132 | Classification loss: 0.20163 | Regression loss: 0.17959 | Running loss: 0.39197\n","Epoch: 1 | Iteration: 133 | Classification loss: 0.50562 | Regression loss: 0.33418 | Running loss: 0.39332\n","Epoch: 1 | Iteration: 134 | Classification loss: 0.23784 | Regression loss: 0.17129 | Running loss: 0.39360\n","Epoch: 1 | Iteration: 135 | Classification loss: 0.39133 | Regression loss: 0.14650 | Running loss: 0.39388\n","Epoch: 1 | Iteration: 136 | Classification loss: 0.14600 | Regression loss: 0.15670 | Running loss: 0.39367\n","Epoch: 1 | Iteration: 137 | Classification loss: 0.65621 | Regression loss: 0.31609 | Running loss: 0.39490\n","Epoch: 1 | Iteration: 138 | Classification loss: 0.29644 | Regression loss: 0.15047 | Running loss: 0.39447\n","Epoch: 1 | Iteration: 139 | Classification loss: 0.37450 | Regression loss: 0.22326 | Running loss: 0.39483\n","Epoch: 1 | Iteration: 140 | Classification loss: 0.00001 | Regression loss: 0.00074 | Running loss: 0.39483\n","Epoch: 1 | Iteration: 141 | Classification loss: 0.02774 | Regression loss: 0.00000 | Running loss: 0.39294\n","Epoch: 1 | Iteration: 142 | Classification loss: 0.06420 | Regression loss: 0.02388 | Running loss: 0.39233\n","Epoch: 1 | Iteration: 143 | Classification loss: 0.14872 | Regression loss: 0.02753 | Running loss: 0.39098\n","Epoch: 1 | Iteration: 144 | Classification loss: 0.21640 | Regression loss: 0.17547 | Running loss: 0.39015\n","Epoch: 1 | Iteration: 145 | Classification loss: 0.00538 | Regression loss: 0.00000 | Running loss: 0.38985\n","Epoch: 1 | Iteration: 146 | Classification loss: 0.03598 | Regression loss: 0.00000 | Running loss: 0.38918\n","Epoch: 1 | Iteration: 147 | Classification loss: 0.37896 | Regression loss: 0.21442 | Running loss: 0.38961\n","Epoch: 1 | Iteration: 148 | Classification loss: 0.00303 | Regression loss: 0.00000 | Running loss: 0.38813\n","Epoch: 1 | Iteration: 149 | Classification loss: 0.24698 | Regression loss: 0.06483 | Running loss: 0.38721\n","Epoch: 1 | Iteration: 150 | Classification loss: 0.15803 | Regression loss: 0.20215 | Running loss: 0.38766\n","Epoch: 1 | Iteration: 151 | Classification loss: 0.14189 | Regression loss: 0.16269 | Running loss: 0.38764\n","Epoch: 1 | Iteration: 152 | Classification loss: 0.06700 | Regression loss: 0.08471 | Running loss: 0.38635\n","Epoch: 1 | Iteration: 153 | Classification loss: 0.18591 | Regression loss: 0.11134 | Running loss: 0.38651\n","Epoch: 1 | Iteration: 154 | Classification loss: 0.23167 | Regression loss: 0.14506 | Running loss: 0.38689\n","Epoch: 1 | Iteration: 155 | Classification loss: 0.14367 | Regression loss: 0.06174 | Running loss: 0.38598\n","Epoch: 1 | Iteration: 156 | Classification loss: 0.19522 | Regression loss: 0.17340 | Running loss: 0.38471\n","Epoch: 1 | Iteration: 157 | Classification loss: 0.00000 | Regression loss: 0.00038 | Running loss: 0.38459\n","Epoch: 1 | Iteration: 158 | Classification loss: 0.31288 | Regression loss: 0.19048 | Running loss: 0.38386\n","Epoch: 1 | Iteration: 159 | Classification loss: 0.14283 | Regression loss: 0.04914 | Running loss: 0.38423\n","Epoch: 1 | Iteration: 160 | Classification loss: 0.16159 | Regression loss: 0.11562 | Running loss: 0.38460\n","Epoch: 1 | Iteration: 161 | Classification loss: 0.00003 | Regression loss: 0.00035 | Running loss: 0.38371\n","Epoch: 1 | Iteration: 162 | Classification loss: 0.10249 | Regression loss: 0.06860 | Running loss: 0.38284\n","Epoch: 1 | Iteration: 163 | Classification loss: 0.32282 | Regression loss: 0.33888 | Running loss: 0.38323\n","Epoch: 1 | Iteration: 164 | Classification loss: 0.26152 | Regression loss: 0.22510 | Running loss: 0.38173\n","Epoch: 1 | Iteration: 165 | Classification loss: 0.24625 | Regression loss: 0.07911 | Running loss: 0.38152\n","Epoch: 1 | Iteration: 166 | Classification loss: 0.07201 | Regression loss: 0.06781 | Running loss: 0.38119\n","Epoch: 1 | Iteration: 167 | Classification loss: 0.25508 | Regression loss: 0.19878 | Running loss: 0.38115\n","Epoch: 1 | Iteration: 168 | Classification loss: 0.31249 | Regression loss: 0.11847 | Running loss: 0.38059\n","Epoch: 1 | Iteration: 169 | Classification loss: 0.13340 | Regression loss: 0.15043 | Running loss: 0.38052\n","Epoch: 1 | Iteration: 170 | Classification loss: 0.33998 | Regression loss: 0.18314 | Running loss: 0.37992\n","Epoch: 1 | Iteration: 171 | Classification loss: 0.28432 | Regression loss: 0.44983 | Running loss: 0.38034\n","Epoch: 1 | Iteration: 172 | Classification loss: 0.31522 | Regression loss: 0.24811 | Running loss: 0.38072\n","Epoch: 1 | Iteration: 173 | Classification loss: 0.10482 | Regression loss: 0.24379 | Running loss: 0.37953\n","Epoch: 1 | Iteration: 174 | Classification loss: 0.20381 | Regression loss: 0.47110 | Running loss: 0.37993\n","Epoch: 1 | Iteration: 175 | Classification loss: 0.32802 | Regression loss: 0.47955 | Running loss: 0.38105\n","Epoch: 1 | Iteration: 176 | Classification loss: 0.23524 | Regression loss: 0.15733 | Running loss: 0.38104\n","Epoch: 1 | Iteration: 177 | Classification loss: 0.14750 | Regression loss: 0.07802 | Running loss: 0.38105\n","Epoch: 1 | Iteration: 178 | Classification loss: 0.06164 | Regression loss: 0.11837 | Running loss: 0.38060\n","Epoch: 1 | Iteration: 179 | Classification loss: 0.07688 | Regression loss: 0.06391 | Running loss: 0.38061\n","Epoch: 1 | Iteration: 180 | Classification loss: 0.06359 | Regression loss: 0.00000 | Running loss: 0.38000\n","Epoch: 1 | Iteration: 181 | Classification loss: 0.28339 | Regression loss: 0.59214 | Running loss: 0.37992\n","Epoch: 1 | Iteration: 182 | Classification loss: 0.47863 | Regression loss: 0.39055 | Running loss: 0.38082\n","Epoch: 1 | Iteration: 183 | Classification loss: 0.17232 | Regression loss: 0.09861 | Running loss: 0.38105\n","Epoch: 1 | Iteration: 184 | Classification loss: 0.00605 | Regression loss: 0.00000 | Running loss: 0.38068\n","Epoch: 1 | Iteration: 185 | Classification loss: 0.00000 | Regression loss: 0.00032 | Running loss: 0.37957\n","Epoch: 1 | Iteration: 186 | Classification loss: 0.01849 | Regression loss: 0.03835 | Running loss: 0.37938\n","Epoch: 1 | Iteration: 187 | Classification loss: 0.13831 | Regression loss: 0.20176 | Running loss: 0.37908\n","Epoch: 1 | Iteration: 188 | Classification loss: 0.34943 | Regression loss: 0.22564 | Running loss: 0.37919\n","Epoch: 1 | Iteration: 189 | Classification loss: 0.11426 | Regression loss: 0.28707 | Running loss: 0.37845\n","Epoch: 1 | Iteration: 190 | Classification loss: 0.01296 | Regression loss: 0.00000 | Running loss: 0.37787\n","Epoch: 1 | Iteration: 191 | Classification loss: 0.15028 | Regression loss: 0.10837 | Running loss: 0.37807\n","Epoch: 1 | Iteration: 192 | Classification loss: 0.20916 | Regression loss: 0.20605 | Running loss: 0.37789\n","Epoch: 1 | Iteration: 193 | Classification loss: 0.08937 | Regression loss: 0.11776 | Running loss: 0.37795\n","Epoch: 1 | Iteration: 194 | Classification loss: 0.10203 | Regression loss: 0.15232 | Running loss: 0.37730\n","Epoch: 1 | Iteration: 195 | Classification loss: 0.38863 | Regression loss: 0.34730 | Running loss: 0.37846\n","Epoch: 1 | Iteration: 196 | Classification loss: 0.33604 | Regression loss: 0.20768 | Running loss: 0.37793\n","Epoch: 1 | Iteration: 197 | Classification loss: 0.03149 | Regression loss: 0.02487 | Running loss: 0.37734\n","Epoch: 1 | Iteration: 198 | Classification loss: 0.19884 | Regression loss: 0.29088 | Running loss: 0.37722\n","Epoch: 1 | Iteration: 199 | Classification loss: 0.14246 | Regression loss: 0.16325 | Running loss: 0.37731\n","Epoch: 1 | Iteration: 200 | Classification loss: 0.07368 | Regression loss: 0.00000 | Running loss: 0.37664\n","Epoch: 1 | Iteration: 201 | Classification loss: 0.20826 | Regression loss: 0.09422 | Running loss: 0.37724\n","Epoch: 1 | Iteration: 202 | Classification loss: 0.00000 | Regression loss: 0.00031 | Running loss: 0.37603\n","Epoch: 1 | Iteration: 203 | Classification loss: 0.17618 | Regression loss: 0.19218 | Running loss: 0.37593\n","Epoch: 1 | Iteration: 204 | Classification loss: 0.14478 | Regression loss: 0.07687 | Running loss: 0.37504\n","Epoch: 1 | Iteration: 205 | Classification loss: 0.04403 | Regression loss: 0.08505 | Running loss: 0.37407\n","Epoch: 1 | Iteration: 206 | Classification loss: 0.13752 | Regression loss: 0.10691 | Running loss: 0.37342\n","Epoch: 1 | Iteration: 207 | Classification loss: 0.45348 | Regression loss: 0.47176 | Running loss: 0.37492\n","Epoch: 1 | Iteration: 208 | Classification loss: 0.19160 | Regression loss: 0.34143 | Running loss: 0.37497\n","Epoch: 1 | Iteration: 209 | Classification loss: 0.26915 | Regression loss: 0.34265 | Running loss: 0.37516\n","Epoch: 1 | Iteration: 210 | Classification loss: 0.13916 | Regression loss: 0.07238 | Running loss: 0.37477\n","Epoch: 1 | Iteration: 211 | Classification loss: 0.00010 | Regression loss: 0.00020 | Running loss: 0.37372\n","Epoch: 1 | Iteration: 212 | Classification loss: 0.19718 | Regression loss: 0.26106 | Running loss: 0.37417\n","Epoch: 1 | Iteration: 213 | Classification loss: 0.15920 | Regression loss: 0.35198 | Running loss: 0.37338\n","Epoch: 1 | Iteration: 214 | Classification loss: 0.15652 | Regression loss: 0.15215 | Running loss: 0.37385\n","Epoch: 1 | Iteration: 215 | Classification loss: 0.22221 | Regression loss: 0.03322 | Running loss: 0.37377\n","Epoch: 1 | Iteration: 216 | Classification loss: 0.07316 | Regression loss: 0.10332 | Running loss: 0.37375\n","Epoch: 1 | Iteration: 217 | Classification loss: 0.15374 | Regression loss: 0.09182 | Running loss: 0.37312\n","Epoch: 1 | Iteration: 218 | Classification loss: 0.07560 | Regression loss: 0.13752 | Running loss: 0.37118\n","Epoch: 1 | Iteration: 219 | Classification loss: 0.36736 | Regression loss: 0.30002 | Running loss: 0.37126\n","Epoch: 1 | Iteration: 220 | Classification loss: 0.24036 | Regression loss: 0.22574 | Running loss: 0.37101\n","Epoch: 1 | Iteration: 221 | Classification loss: 0.40793 | Regression loss: 0.11730 | Running loss: 0.37076\n","Epoch: 1 | Iteration: 222 | Classification loss: 0.00002 | Regression loss: 0.00112 | Running loss: 0.37017\n","Epoch: 1 | Iteration: 223 | Classification loss: 0.32618 | Regression loss: 0.19648 | Running loss: 0.37059\n","Epoch: 1 | Iteration: 224 | Classification loss: 0.40264 | Regression loss: 0.12835 | Running loss: 0.37078\n","Epoch: 1 | Iteration: 225 | Classification loss: 0.24032 | Regression loss: 0.28784 | Running loss: 0.37076\n","Epoch: 1 | Iteration: 226 | Classification loss: 0.19105 | Regression loss: 0.32209 | Running loss: 0.37142\n","Epoch: 1 | Iteration: 227 | Classification loss: 0.02800 | Regression loss: 0.00000 | Running loss: 0.36981\n","Epoch: 1 | Iteration: 228 | Classification loss: 0.22461 | Regression loss: 0.17695 | Running loss: 0.37016\n","Epoch: 1 | Iteration: 229 | Classification loss: 0.55138 | Regression loss: 0.09528 | Running loss: 0.37045\n","Epoch: 1 | Iteration: 230 | Classification loss: 0.08350 | Regression loss: 0.05966 | Running loss: 0.36933\n","Epoch: 1 | Iteration: 231 | Classification loss: 0.35789 | Regression loss: 0.00000 | Running loss: 0.36840\n","Epoch: 1 | Iteration: 232 | Classification loss: 0.26656 | Regression loss: 0.15181 | Running loss: 0.36737\n","Epoch: 1 | Iteration: 233 | Classification loss: 0.19609 | Regression loss: 0.11246 | Running loss: 0.36664\n","Epoch: 1 | Iteration: 234 | Classification loss: 0.15031 | Regression loss: 0.05758 | Running loss: 0.36706\n","Epoch: 1 | Iteration: 235 | Classification loss: 0.02654 | Regression loss: 0.02074 | Running loss: 0.36617\n","Epoch: 1 | Iteration: 236 | Classification loss: 0.29394 | Regression loss: 0.20847 | Running loss: 0.36612\n","Epoch: 1 | Iteration: 237 | Classification loss: 0.64473 | Regression loss: 0.54645 | Running loss: 0.36792\n","Epoch: 1 | Iteration: 238 | Classification loss: 0.17646 | Regression loss: 0.11211 | Running loss: 0.36849\n","Epoch: 1 | Iteration: 239 | Classification loss: 0.30280 | Regression loss: 0.17300 | Running loss: 0.36940\n","Epoch: 1 | Iteration: 240 | Classification loss: 0.28600 | Regression loss: 0.17411 | Running loss: 0.37002\n","Epoch: 1 | Iteration: 241 | Classification loss: 0.37333 | Regression loss: 0.19838 | Running loss: 0.37117\n","Epoch: 1 | Iteration: 242 | Classification loss: 0.46738 | Regression loss: 0.24328 | Running loss: 0.37077\n","Epoch: 1 | Iteration: 243 | Classification loss: 0.28028 | Regression loss: 0.23090 | Running loss: 0.37179\n","Epoch: 1 | Iteration: 244 | Classification loss: 0.05008 | Regression loss: 0.00000 | Running loss: 0.37130\n","Epoch: 1 | Iteration: 245 | Classification loss: 0.54435 | Regression loss: 0.33415 | Running loss: 0.37245\n","Epoch: 1 | Iteration: 246 | Classification loss: 0.16778 | Regression loss: 0.23029 | Running loss: 0.37324\n","Epoch: 1 | Iteration: 247 | Classification loss: 0.14316 | Regression loss: 0.18239 | Running loss: 0.37375\n","Epoch: 1 | Iteration: 248 | Classification loss: 0.15585 | Regression loss: 0.17561 | Running loss: 0.37418\n","Epoch: 1 | Iteration: 249 | Classification loss: 0.21572 | Regression loss: 0.21398 | Running loss: 0.37362\n","Epoch: 1 | Iteration: 250 | Classification loss: 0.00007 | Regression loss: 0.00031 | Running loss: 0.37214\n","Epoch: 1 | Iteration: 251 | Classification loss: 0.08054 | Regression loss: 0.05738 | Running loss: 0.37215\n","Epoch: 1 | Iteration: 252 | Classification loss: 0.20720 | Regression loss: 0.31345 | Running loss: 0.37257\n","Epoch: 1 | Iteration: 253 | Classification loss: 0.25824 | Regression loss: 0.15538 | Running loss: 0.37261\n","Epoch: 1 | Iteration: 254 | Classification loss: 0.12606 | Regression loss: 0.07742 | Running loss: 0.37184\n","Epoch: 1 | Iteration: 255 | Classification loss: 0.13927 | Regression loss: 0.23391 | Running loss: 0.37150\n","Epoch: 1 | Iteration: 256 | Classification loss: 0.23630 | Regression loss: 0.25272 | Running loss: 0.37248\n","Epoch: 1 | Iteration: 257 | Classification loss: 0.01750 | Regression loss: 0.00000 | Running loss: 0.37160\n","Epoch: 1 | Iteration: 258 | Classification loss: 0.22152 | Regression loss: 0.29535 | Running loss: 0.37173\n","Epoch: 1 | Iteration: 259 | Classification loss: 0.39183 | Regression loss: 0.27719 | Running loss: 0.37227\n","Epoch: 1 | Iteration: 260 | Classification loss: 0.19815 | Regression loss: 0.06130 | Running loss: 0.37207\n","Epoch: 1 | Iteration: 261 | Classification loss: 0.00000 | Regression loss: 0.00031 | Running loss: 0.37169\n","Epoch: 1 | Iteration: 262 | Classification loss: 0.12348 | Regression loss: 0.09577 | Running loss: 0.37099\n","Epoch: 1 | Iteration: 263 | Classification loss: 0.00000 | Regression loss: 0.00030 | Running loss: 0.37099\n","Epoch: 1 | Iteration: 264 | Classification loss: 0.46054 | Regression loss: 0.14977 | Running loss: 0.37182\n","Epoch: 1 | Iteration: 265 | Classification loss: 0.18546 | Regression loss: 0.36911 | Running loss: 0.37100\n","Epoch: 1 | Iteration: 266 | Classification loss: 0.37867 | Regression loss: 0.46867 | Running loss: 0.37269\n","Epoch: 1 | Iteration: 267 | Classification loss: 0.19783 | Regression loss: 0.13344 | Running loss: 0.37304\n","Epoch: 1 | Iteration: 268 | Classification loss: 0.00001 | Regression loss: 0.00053 | Running loss: 0.37304\n","Epoch: 1 | Iteration: 269 | Classification loss: 0.24990 | Regression loss: 0.33788 | Running loss: 0.37413\n","Epoch: 1 | Iteration: 270 | Classification loss: 0.24353 | Regression loss: 0.21744 | Running loss: 0.37413\n","Epoch: 1 | Iteration: 271 | Classification loss: 0.00000 | Regression loss: 0.00038 | Running loss: 0.37376\n","Epoch: 1 | Iteration: 272 | Classification loss: 0.21741 | Regression loss: 0.00000 | Running loss: 0.37392\n","Epoch: 1 | Iteration: 273 | Classification loss: 0.31900 | Regression loss: 0.21882 | Running loss: 0.37388\n","Epoch: 1 | Iteration: 274 | Classification loss: 0.24290 | Regression loss: 0.22134 | Running loss: 0.37397\n","Epoch: 1 | Iteration: 275 | Classification loss: 0.09970 | Regression loss: 0.04559 | Running loss: 0.37373\n","Epoch: 1 | Iteration: 276 | Classification loss: 0.16304 | Regression loss: 0.13511 | Running loss: 0.37340\n","Epoch: 1 | Iteration: 277 | Classification loss: 0.39741 | Regression loss: 0.36617 | Running loss: 0.37451\n","Epoch: 1 | Iteration: 278 | Classification loss: 0.07771 | Regression loss: 0.22237 | Running loss: 0.37486\n","Epoch: 1 | Iteration: 279 | Classification loss: 0.16308 | Regression loss: 0.07079 | Running loss: 0.37410\n","Epoch: 1 | Iteration: 280 | Classification loss: 0.15630 | Regression loss: 0.37308 | Running loss: 0.37444\n","Epoch: 1 | Iteration: 281 | Classification loss: 0.13496 | Regression loss: 0.11004 | Running loss: 0.37476\n","Epoch: 1 | Iteration: 282 | Classification loss: 0.21763 | Regression loss: 0.21436 | Running loss: 0.37509\n","Epoch: 1 | Iteration: 283 | Classification loss: 0.22579 | Regression loss: 0.15473 | Running loss: 0.37478\n","Epoch: 1 | Iteration: 284 | Classification loss: 0.10709 | Regression loss: 0.19144 | Running loss: 0.37466\n","Epoch: 1 | Iteration: 285 | Classification loss: 0.00000 | Regression loss: 0.00019 | Running loss: 0.37337\n","Epoch: 1 | Iteration: 286 | Classification loss: 0.54782 | Regression loss: 0.32020 | Running loss: 0.37420\n","Epoch: 1 | Iteration: 287 | Classification loss: 0.35567 | Regression loss: 0.30584 | Running loss: 0.37380\n","Epoch: 1 | Iteration: 288 | Classification loss: 0.09444 | Regression loss: 0.07122 | Running loss: 0.37325\n","Epoch: 1 | Iteration: 289 | Classification loss: 0.19136 | Regression loss: 0.07807 | Running loss: 0.37379\n","Epoch: 1 | Iteration: 290 | Classification loss: 0.11816 | Regression loss: 0.11372 | Running loss: 0.37387\n","Epoch: 1 | Iteration: 291 | Classification loss: 0.08780 | Regression loss: 0.10526 | Running loss: 0.37303\n","Epoch: 1 | Iteration: 292 | Classification loss: 0.38352 | Regression loss: 0.38209 | Running loss: 0.37322\n","Epoch: 1 | Iteration: 293 | Classification loss: 0.17783 | Regression loss: 0.43156 | Running loss: 0.37443\n","Epoch: 1 | Iteration: 294 | Classification loss: 0.45329 | Regression loss: 0.32381 | Running loss: 0.37445\n","Epoch: 1 | Iteration: 295 | Classification loss: 0.28320 | Regression loss: 0.16916 | Running loss: 0.37497\n","Epoch: 1 | Iteration: 296 | Classification loss: 0.19456 | Regression loss: 0.10518 | Running loss: 0.37508\n","Epoch: 1 | Iteration: 297 | Classification loss: 0.13999 | Regression loss: 0.11273 | Running loss: 0.37465\n","Epoch: 1 | Iteration: 298 | Classification loss: 0.18311 | Regression loss: 0.17452 | Running loss: 0.37476\n","Epoch: 1 | Iteration: 299 | Classification loss: 0.18230 | Regression loss: 0.21855 | Running loss: 0.37461\n","Epoch: 1 | Iteration: 300 | Classification loss: 0.08143 | Regression loss: 0.03242 | Running loss: 0.37428\n","Epoch: 1 | Iteration: 301 | Classification loss: 0.39631 | Regression loss: 0.38582 | Running loss: 0.37585\n","Epoch: 1 | Iteration: 302 | Classification loss: 0.05950 | Regression loss: 0.09668 | Running loss: 0.37616\n","Epoch: 1 | Iteration: 303 | Classification loss: 0.35899 | Regression loss: 0.38678 | Running loss: 0.37765\n","Epoch: 1 | Iteration: 304 | Classification loss: 0.19617 | Regression loss: 0.23026 | Running loss: 0.37798\n","Epoch: 1 | Iteration: 305 | Classification loss: 0.21905 | Regression loss: 0.27697 | Running loss: 0.37851\n","Epoch: 1 | Iteration: 306 | Classification loss: 0.34448 | Regression loss: 0.39954 | Running loss: 0.37889\n","Epoch: 1 | Iteration: 307 | Classification loss: 0.12472 | Regression loss: 0.14053 | Running loss: 0.37836\n","Epoch: 1 | Iteration: 308 | Classification loss: 0.32619 | Regression loss: 0.23744 | Running loss: 0.37810\n","Epoch: 1 | Iteration: 309 | Classification loss: 0.24393 | Regression loss: 0.26091 | Running loss: 0.37841\n","Epoch: 1 | Iteration: 310 | Classification loss: 0.39155 | Regression loss: 0.32522 | Running loss: 0.37837\n","Epoch: 1 | Iteration: 311 | Classification loss: 0.27903 | Regression loss: 0.41492 | Running loss: 0.37917\n","Epoch: 1 | Iteration: 312 | Classification loss: 0.30294 | Regression loss: 0.12329 | Running loss: 0.37963\n","Epoch: 1 | Iteration: 313 | Classification loss: 0.49099 | Regression loss: 0.15766 | Running loss: 0.37955\n","Epoch: 1 | Iteration: 314 | Classification loss: 0.20834 | Regression loss: 0.12103 | Running loss: 0.37997\n","Epoch: 1 | Iteration: 315 | Classification loss: 0.21432 | Regression loss: 0.15903 | Running loss: 0.37985\n","Epoch: 1 | Iteration: 316 | Classification loss: 0.14437 | Regression loss: 0.17474 | Running loss: 0.37941\n","Epoch: 1 | Iteration: 317 | Classification loss: 0.86862 | Regression loss: 0.11472 | Running loss: 0.38080\n","Epoch: 1 | Iteration: 318 | Classification loss: 0.35809 | Regression loss: 0.41628 | Running loss: 0.38178\n","Epoch: 1 | Iteration: 319 | Classification loss: 0.18854 | Regression loss: 0.11949 | Running loss: 0.38186\n","Epoch: 1 | Iteration: 320 | Classification loss: 0.18184 | Regression loss: 0.15385 | Running loss: 0.38135\n","Epoch: 1 | Iteration: 321 | Classification loss: 0.21656 | Regression loss: 0.14513 | Running loss: 0.38207\n","Epoch: 1 | Iteration: 322 | Classification loss: 0.30310 | Regression loss: 0.29792 | Running loss: 0.38211\n","Epoch: 1 | Iteration: 323 | Classification loss: 0.28723 | Regression loss: 0.28294 | Running loss: 0.38227\n","Epoch: 1 | Iteration: 324 | Classification loss: 0.22196 | Regression loss: 0.18640 | Running loss: 0.38303\n","Epoch: 1 | Iteration: 325 | Classification loss: 0.41804 | Regression loss: 0.17695 | Running loss: 0.38393\n","Epoch: 1 | Iteration: 326 | Classification loss: 0.13753 | Regression loss: 0.13732 | Running loss: 0.38399\n","Epoch: 1 | Iteration: 327 | Classification loss: 0.43457 | Regression loss: 0.31184 | Running loss: 0.38549\n","Epoch: 1 | Iteration: 328 | Classification loss: 0.14755 | Regression loss: 0.12497 | Running loss: 0.38545\n","Epoch: 1 | Iteration: 329 | Classification loss: 0.66658 | Regression loss: 0.36943 | Running loss: 0.38655\n","Epoch: 1 | Iteration: 330 | Classification loss: 0.21141 | Regression loss: 0.13495 | Running loss: 0.38666\n","Epoch: 1 | Iteration: 331 | Classification loss: 0.00000 | Regression loss: 0.00019 | Running loss: 0.38656\n","Epoch: 1 | Iteration: 332 | Classification loss: 0.17635 | Regression loss: 0.09778 | Running loss: 0.38686\n","Epoch: 1 | Iteration: 333 | Classification loss: 0.14787 | Regression loss: 0.12594 | Running loss: 0.38689\n","Epoch: 1 | Iteration: 334 | Classification loss: 0.37308 | Regression loss: 0.31472 | Running loss: 0.38827\n","Epoch: 1 | Iteration: 335 | Classification loss: 0.13086 | Regression loss: 0.19677 | Running loss: 0.38892\n","Epoch: 1 | Iteration: 336 | Classification loss: 0.31925 | Regression loss: 0.19810 | Running loss: 0.38903\n","Epoch: 1 | Iteration: 337 | Classification loss: 0.00000 | Regression loss: 0.00043 | Running loss: 0.38856\n","Epoch: 1 | Iteration: 338 | Classification loss: 0.18997 | Regression loss: 0.14223 | Running loss: 0.38877\n","Epoch: 1 | Iteration: 339 | Classification loss: 0.21638 | Regression loss: 0.12165 | Running loss: 0.38904\n","Epoch: 1 | Iteration: 340 | Classification loss: 0.29343 | Regression loss: 0.10046 | Running loss: 0.38920\n","Epoch: 1 | Iteration: 341 | Classification loss: 0.20068 | Regression loss: 0.27139 | Running loss: 0.38861\n","Epoch: 1 | Iteration: 342 | Classification loss: 0.39231 | Regression loss: 0.20598 | Running loss: 0.38907\n","Epoch: 1 | Iteration: 343 | Classification loss: 0.09211 | Regression loss: 0.13961 | Running loss: 0.38954\n","Epoch: 1 | Iteration: 344 | Classification loss: 0.12484 | Regression loss: 0.30246 | Running loss: 0.38963\n","Epoch: 1 | Iteration: 345 | Classification loss: 0.06613 | Regression loss: 0.11011 | Running loss: 0.38849\n","Epoch: 1 | Iteration: 346 | Classification loss: 0.09335 | Regression loss: 0.06858 | Running loss: 0.38874\n","Epoch: 1 | Iteration: 347 | Classification loss: 0.30117 | Regression loss: 0.20174 | Running loss: 0.38887\n","Epoch: 1 | Iteration: 348 | Classification loss: 0.54255 | Regression loss: 0.08446 | Running loss: 0.39002\n","Epoch: 1 | Iteration: 349 | Classification loss: 0.00002 | Regression loss: 0.00038 | Running loss: 0.38874\n","Epoch: 1 | Iteration: 350 | Classification loss: 0.24026 | Regression loss: 0.09745 | Running loss: 0.38773\n","Epoch: 1 | Iteration: 351 | Classification loss: 0.09215 | Regression loss: 0.06101 | Running loss: 0.38589\n","Epoch: 1 | Iteration: 352 | Classification loss: 0.00004 | Regression loss: 0.00028 | Running loss: 0.38317\n","Epoch: 1 | Iteration: 353 | Classification loss: 0.17627 | Regression loss: 0.27073 | Running loss: 0.38369\n","Epoch: 1 | Iteration: 354 | Classification loss: 0.28785 | Regression loss: 0.28887 | Running loss: 0.38365\n","Epoch: 1 | Iteration: 355 | Classification loss: 0.30751 | Regression loss: 0.12440 | Running loss: 0.38350\n","Epoch: 1 | Iteration: 356 | Classification loss: 0.19919 | Regression loss: 0.20326 | Running loss: 0.38359\n","Epoch: 1 | Iteration: 357 | Classification loss: 0.15262 | Regression loss: 0.19426 | Running loss: 0.38401\n","Epoch: 1 | Iteration: 358 | Classification loss: 0.00000 | Regression loss: 0.00070 | Running loss: 0.38299\n","Epoch: 1 | Iteration: 359 | Classification loss: 0.31188 | Regression loss: 0.12669 | Running loss: 0.38336\n","Epoch: 1 | Iteration: 360 | Classification loss: 0.16168 | Regression loss: 0.27151 | Running loss: 0.38381\n","Epoch: 1 | Iteration: 361 | Classification loss: 0.09169 | Regression loss: 0.05867 | Running loss: 0.38363\n","Epoch: 1 | Iteration: 362 | Classification loss: 0.00001 | Regression loss: 0.00051 | Running loss: 0.38272\n","Epoch: 1 | Iteration: 363 | Classification loss: 0.12610 | Regression loss: 0.05282 | Running loss: 0.38308\n","Epoch: 1 | Iteration: 364 | Classification loss: 0.00000 | Regression loss: 0.00037 | Running loss: 0.38241\n","Epoch: 1 | Iteration: 365 | Classification loss: 0.00000 | Regression loss: 0.00026 | Running loss: 0.38195\n","Epoch: 1 | Iteration: 366 | Classification loss: 0.32367 | Regression loss: 0.14279 | Running loss: 0.38288\n","Epoch: 1 | Iteration: 367 | Classification loss: 0.49292 | Regression loss: 0.35340 | Running loss: 0.38410\n","Epoch: 1 | Iteration: 368 | Classification loss: 0.29534 | Regression loss: 0.27833 | Running loss: 0.38510\n","Epoch: 1 | Iteration: 369 | Classification loss: 0.09708 | Regression loss: 0.04454 | Running loss: 0.38368\n","Epoch: 1 | Iteration: 370 | Classification loss: 0.09610 | Regression loss: 0.07356 | Running loss: 0.38345\n","Epoch: 1 | Iteration: 371 | Classification loss: 0.11348 | Regression loss: 0.02903 | Running loss: 0.38308\n","Epoch: 1 | Iteration: 372 | Classification loss: 0.26095 | Regression loss: 0.38779 | Running loss: 0.38358\n","Epoch: 1 | Iteration: 373 | Classification loss: 0.16684 | Regression loss: 0.11164 | Running loss: 0.38340\n","Epoch: 1 | Iteration: 374 | Classification loss: 0.46059 | Regression loss: 0.28117 | Running loss: 0.38441\n","Epoch: 1 | Iteration: 375 | Classification loss: 0.14220 | Regression loss: 0.22498 | Running loss: 0.38397\n","Epoch: 1 | Iteration: 376 | Classification loss: 0.00000 | Regression loss: 0.00103 | Running loss: 0.38188\n","Epoch: 1 | Iteration: 377 | Classification loss: 0.00000 | Regression loss: 0.00086 | Running loss: 0.38147\n","Epoch: 1 | Iteration: 378 | Classification loss: 0.20252 | Regression loss: 0.21663 | Running loss: 0.38157\n","Epoch: 1 | Iteration: 379 | Classification loss: 0.00000 | Regression loss: 0.00028 | Running loss: 0.38072\n","Epoch: 1 | Iteration: 380 | Classification loss: 0.14642 | Regression loss: 0.30698 | Running loss: 0.38138\n","Epoch: 1 | Iteration: 381 | Classification loss: 0.37520 | Regression loss: 0.38386 | Running loss: 0.38290\n","Epoch: 1 | Iteration: 382 | Classification loss: 0.33343 | Regression loss: 0.02313 | Running loss: 0.38316\n","Epoch: 1 | Iteration: 383 | Classification loss: 0.11022 | Regression loss: 0.06273 | Running loss: 0.38314\n","Epoch: 1 | Iteration: 384 | Classification loss: 0.05171 | Regression loss: 0.00000 | Running loss: 0.38122\n","Epoch: 1 | Iteration: 385 | Classification loss: 0.22227 | Regression loss: 0.11989 | Running loss: 0.38143\n","Epoch: 1 | Iteration: 386 | Classification loss: 0.19360 | Regression loss: 0.28254 | Running loss: 0.38136\n","Epoch: 1 | Iteration: 387 | Classification loss: 0.10557 | Regression loss: 0.11917 | Running loss: 0.38144\n","Epoch: 1 | Iteration: 388 | Classification loss: 0.36940 | Regression loss: 0.12647 | Running loss: 0.38161\n","Epoch: 1 | Iteration: 389 | Classification loss: 0.00019 | Regression loss: 0.00034 | Running loss: 0.38029\n","Epoch: 1 | Iteration: 390 | Classification loss: 0.05793 | Regression loss: 0.13847 | Running loss: 0.38006\n","Epoch: 1 | Iteration: 391 | Classification loss: 0.28815 | Regression loss: 0.13276 | Running loss: 0.38090\n","Epoch: 1 | Iteration: 392 | Classification loss: 0.00000 | Regression loss: 0.00042 | Running loss: 0.38032\n","Epoch: 1 | Iteration: 393 | Classification loss: 0.12417 | Regression loss: 0.07389 | Running loss: 0.38001\n","Epoch: 1 | Iteration: 394 | Classification loss: 0.14633 | Regression loss: 0.42755 | Running loss: 0.38064\n","Epoch: 1 | Iteration: 395 | Classification loss: 0.07652 | Regression loss: 0.21119 | Running loss: 0.38082\n","Epoch: 1 | Iteration: 396 | Classification loss: 0.27799 | Regression loss: 0.28859 | Running loss: 0.37954\n","Epoch: 1 | Iteration: 397 | Classification loss: 0.00013 | Regression loss: 0.00024 | Running loss: 0.37839\n","Epoch: 1 | Iteration: 398 | Classification loss: 0.12178 | Regression loss: 0.15868 | Running loss: 0.37667\n","Epoch: 1 | Iteration: 399 | Classification loss: 0.12602 | Regression loss: 0.13468 | Running loss: 0.37615\n","Epoch: 1 | Iteration: 400 | Classification loss: 0.20295 | Regression loss: 0.20162 | Running loss: 0.37475\n","Epoch: 1 | Iteration: 401 | Classification loss: 0.08975 | Regression loss: 0.09341 | Running loss: 0.37500\n","Epoch: 1 | Iteration: 402 | Classification loss: 0.18278 | Regression loss: 0.22173 | Running loss: 0.37544\n","Epoch: 1 | Iteration: 403 | Classification loss: 0.20025 | Regression loss: 0.12857 | Running loss: 0.37403\n","Epoch: 1 | Iteration: 404 | Classification loss: 0.35225 | Regression loss: 0.22088 | Running loss: 0.37467\n","Epoch: 1 | Iteration: 405 | Classification loss: 0.03580 | Regression loss: 0.00000 | Running loss: 0.37474\n","Epoch: 1 | Iteration: 406 | Classification loss: 0.05329 | Regression loss: 0.04855 | Running loss: 0.37332\n","Epoch: 1 | Iteration: 407 | Classification loss: 0.30306 | Regression loss: 0.34709 | Running loss: 0.37462\n","Epoch: 1 | Iteration: 408 | Classification loss: 0.37763 | Regression loss: 0.34014 | Running loss: 0.37606\n","Epoch: 1 | Iteration: 409 | Classification loss: 0.11609 | Regression loss: 0.27828 | Running loss: 0.37640\n","Epoch: 1 | Iteration: 410 | Classification loss: 0.37926 | Regression loss: 0.24800 | Running loss: 0.37706\n","Epoch: 1 | Iteration: 411 | Classification loss: 0.14630 | Regression loss: 0.15384 | Running loss: 0.37724\n","Epoch: 1 | Iteration: 412 | Classification loss: 0.07080 | Regression loss: 0.07679 | Running loss: 0.37664\n","Epoch: 1 | Iteration: 413 | Classification loss: 0.20481 | Regression loss: 0.19347 | Running loss: 0.37636\n","Epoch: 1 | Iteration: 414 | Classification loss: 0.19904 | Regression loss: 0.33288 | Running loss: 0.37666\n","Epoch: 1 | Iteration: 415 | Classification loss: 0.25260 | Regression loss: 0.20188 | Running loss: 0.37757\n","Epoch: 1 | Iteration: 416 | Classification loss: 0.07807 | Regression loss: 0.08868 | Running loss: 0.37588\n","Epoch: 1 | Iteration: 417 | Classification loss: 0.11133 | Regression loss: 0.06473 | Running loss: 0.37405\n","Epoch: 1 | Iteration: 418 | Classification loss: 0.17491 | Regression loss: 0.35330 | Running loss: 0.37259\n","Epoch: 1 | Iteration: 419 | Classification loss: 0.01421 | Regression loss: 0.00000 | Running loss: 0.37191\n","Epoch: 1 | Iteration: 420 | Classification loss: 0.24782 | Regression loss: 0.11137 | Running loss: 0.37233\n","Epoch: 1 | Iteration: 421 | Classification loss: 0.12652 | Regression loss: 0.04292 | Running loss: 0.37157\n","Epoch: 1 | Iteration: 422 | Classification loss: 0.14602 | Regression loss: 0.03944 | Running loss: 0.37085\n","Epoch: 1 | Iteration: 423 | Classification loss: 0.00001 | Regression loss: 0.00126 | Running loss: 0.37085\n","Epoch: 1 | Iteration: 424 | Classification loss: 0.35145 | Regression loss: 0.34184 | Running loss: 0.37151\n","Epoch: 1 | Iteration: 425 | Classification loss: 0.21183 | Regression loss: 0.19537 | Running loss: 0.37120\n","Epoch: 1 | Iteration: 426 | Classification loss: 0.39814 | Regression loss: 0.40486 | Running loss: 0.37206\n","Epoch: 1 | Iteration: 427 | Classification loss: 0.12431 | Regression loss: 0.08879 | Running loss: 0.37139\n","Epoch: 1 | Iteration: 428 | Classification loss: 0.03682 | Regression loss: 0.06242 | Running loss: 0.37122\n","Epoch: 1 | Iteration: 429 | Classification loss: 0.09355 | Regression loss: 0.03810 | Running loss: 0.37126\n","Epoch: 1 | Iteration: 430 | Classification loss: 0.39145 | Regression loss: 0.16777 | Running loss: 0.37238\n","Epoch: 1 | Iteration: 431 | Classification loss: 0.15831 | Regression loss: 0.13191 | Running loss: 0.37248\n","Epoch: 1 | Iteration: 432 | Classification loss: 0.00000 | Regression loss: 0.00044 | Running loss: 0.37230\n","Epoch: 1 | Iteration: 433 | Classification loss: 0.00000 | Regression loss: 0.00062 | Running loss: 0.37123\n","Epoch: 1 | Iteration: 434 | Classification loss: 0.02822 | Regression loss: 0.03626 | Running loss: 0.37081\n","Epoch: 1 | Iteration: 435 | Classification loss: 0.00157 | Regression loss: 0.00000 | Running loss: 0.36947\n","Epoch: 1 | Iteration: 436 | Classification loss: 0.27614 | Regression loss: 0.14926 | Running loss: 0.36958\n","Epoch: 1 | Iteration: 437 | Classification loss: 0.15422 | Regression loss: 0.03968 | Running loss: 0.36938\n","Epoch: 1 | Iteration: 438 | Classification loss: 0.28053 | Regression loss: 0.09489 | Running loss: 0.36929\n","Epoch: 1 | Iteration: 439 | Classification loss: 0.00000 | Regression loss: 0.00018 | Running loss: 0.36868\n","Epoch: 1 | Iteration: 440 | Classification loss: 0.00011 | Regression loss: 0.00060 | Running loss: 0.36828\n","Epoch: 1 | Iteration: 441 | Classification loss: 0.45396 | Regression loss: 0.41911 | Running loss: 0.37002\n","Epoch: 1 | Iteration: 442 | Classification loss: 0.23913 | Regression loss: 0.13826 | Running loss: 0.37002\n","Epoch: 1 | Iteration: 443 | Classification loss: 0.25086 | Regression loss: 0.10741 | Running loss: 0.37002\n","Epoch: 1 | Iteration: 444 | Classification loss: 0.00001 | Regression loss: 0.00237 | Running loss: 0.36947\n","Epoch: 1 | Iteration: 445 | Classification loss: 0.23263 | Regression loss: 0.13920 | Running loss: 0.36940\n","Epoch: 1 | Iteration: 446 | Classification loss: 0.20393 | Regression loss: 0.33168 | Running loss: 0.36986\n","Epoch: 1 | Iteration: 447 | Classification loss: 0.29956 | Regression loss: 0.35224 | Running loss: 0.37047\n","Epoch: 1 | Iteration: 448 | Classification loss: 0.00000 | Regression loss: 0.00247 | Running loss: 0.36887\n","Epoch: 1 | Iteration: 449 | Classification loss: 0.24074 | Regression loss: 0.32968 | Running loss: 0.36882\n","Epoch: 1 | Iteration: 450 | Classification loss: 0.39620 | Regression loss: 0.28464 | Running loss: 0.36971\n","Epoch: 1 | Iteration: 451 | Classification loss: 0.33791 | Regression loss: 0.63115 | Running loss: 0.37164\n","Epoch: 1 | Iteration: 452 | Classification loss: 0.08167 | Regression loss: 0.15346 | Running loss: 0.37168\n","Epoch: 1 | Iteration: 453 | Classification loss: 0.42877 | Regression loss: 0.44237 | Running loss: 0.37267\n","Epoch: 1 | Iteration: 454 | Classification loss: 0.09604 | Regression loss: 0.09050 | Running loss: 0.37168\n","Epoch: 1 | Iteration: 455 | Classification loss: 0.08343 | Regression loss: 0.11717 | Running loss: 0.37142\n","Epoch: 1 | Iteration: 456 | Classification loss: 0.38208 | Regression loss: 0.41404 | Running loss: 0.37157\n","Epoch: 1 | Iteration: 457 | Classification loss: 0.51568 | Regression loss: 0.19602 | Running loss: 0.37238\n","Epoch: 1 | Iteration: 458 | Classification loss: 0.00019 | Regression loss: 0.00052 | Running loss: 0.37204\n","Epoch: 1 | Iteration: 459 | Classification loss: 0.00020 | Regression loss: 0.00045 | Running loss: 0.37144\n","Epoch: 1 | Iteration: 460 | Classification loss: 0.39077 | Regression loss: 0.30420 | Running loss: 0.37157\n","Epoch: 1 | Iteration: 461 | Classification loss: 0.45801 | Regression loss: 0.45763 | Running loss: 0.37287\n","Epoch: 1 | Iteration: 462 | Classification loss: 0.31710 | Regression loss: 0.32987 | Running loss: 0.37363\n","Epoch: 1 | Iteration: 463 | Classification loss: 0.00000 | Regression loss: 0.00031 | Running loss: 0.37289\n","Epoch: 1 | Iteration: 464 | Classification loss: 0.99250 | Regression loss: 0.00000 | Running loss: 0.37400\n","Epoch: 1 | Iteration: 465 | Classification loss: 0.00004 | Regression loss: 0.00033 | Running loss: 0.37330\n","Epoch: 1 | Iteration: 466 | Classification loss: 0.15164 | Regression loss: 0.09727 | Running loss: 0.37310\n","Epoch: 1 | Iteration: 467 | Classification loss: 0.15455 | Regression loss: 0.07324 | Running loss: 0.37329\n","Epoch: 1 | Iteration: 468 | Classification loss: 0.24097 | Regression loss: 0.19347 | Running loss: 0.37328\n","Epoch: 1 | Iteration: 469 | Classification loss: 0.42584 | Regression loss: 0.35162 | Running loss: 0.37452\n","Epoch: 1 | Iteration: 470 | Classification loss: 0.08833 | Regression loss: 0.21678 | Running loss: 0.37508\n","Epoch: 1 | Iteration: 471 | Classification loss: 0.09206 | Regression loss: 0.06552 | Running loss: 0.37478\n","Epoch: 1 | Iteration: 472 | Classification loss: 0.44308 | Regression loss: 0.32633 | Running loss: 0.37556\n","Epoch: 1 | Iteration: 473 | Classification loss: 0.43289 | Regression loss: 0.16614 | Running loss: 0.37675\n","Epoch: 1 | Iteration: 474 | Classification loss: 0.08807 | Regression loss: 0.05780 | Running loss: 0.37692\n","Epoch: 1 | Iteration: 475 | Classification loss: 0.17586 | Regression loss: 0.07829 | Running loss: 0.37622\n","Epoch: 1 | Iteration: 476 | Classification loss: 0.26691 | Regression loss: 0.24144 | Running loss: 0.37547\n","Epoch: 1 | Iteration: 477 | Classification loss: 0.02084 | Regression loss: 0.00000 | Running loss: 0.37492\n","Epoch: 1 | Iteration: 478 | Classification loss: 0.07967 | Regression loss: 0.03525 | Running loss: 0.37515\n","Epoch: 1 | Iteration: 479 | Classification loss: 0.42848 | Regression loss: 0.12379 | Running loss: 0.37551\n","Epoch: 1 | Iteration: 480 | Classification loss: 0.19750 | Regression loss: 0.18855 | Running loss: 0.37508\n","Epoch: 1 | Iteration: 481 | Classification loss: 0.00000 | Regression loss: 0.00349 | Running loss: 0.37481\n","Epoch: 1 | Iteration: 482 | Classification loss: 0.26719 | Regression loss: 0.22155 | Running loss: 0.37491\n","Epoch: 1 | Iteration: 483 | Classification loss: 0.47643 | Regression loss: 0.49604 | Running loss: 0.37544\n","Epoch: 1 | Iteration: 484 | Classification loss: 0.10596 | Regression loss: 0.02445 | Running loss: 0.37453\n","Epoch: 1 | Iteration: 485 | Classification loss: 0.20719 | Regression loss: 0.13330 | Running loss: 0.37448\n","Epoch: 1 | Iteration: 486 | Classification loss: 0.22018 | Regression loss: 0.46902 | Running loss: 0.37492\n","Epoch: 1 | Iteration: 487 | Classification loss: 0.25393 | Regression loss: 0.18238 | Running loss: 0.37500\n","Epoch: 1 | Iteration: 488 | Classification loss: 0.00000 | Regression loss: 0.00284 | Running loss: 0.37422\n","Epoch: 1 | Iteration: 489 | Classification loss: 0.08606 | Regression loss: 0.18941 | Running loss: 0.37350\n","Epoch: 1 | Iteration: 490 | Classification loss: 0.21178 | Regression loss: 0.09505 | Running loss: 0.37285\n","Epoch: 1 | Iteration: 491 | Classification loss: 0.00000 | Regression loss: 0.00146 | Running loss: 0.37213\n","Epoch: 1 | Iteration: 492 | Classification loss: 0.33188 | Regression loss: 0.42641 | Running loss: 0.37316\n","Epoch: 1 | Iteration: 493 | Classification loss: 0.14015 | Regression loss: 0.17139 | Running loss: 0.37337\n","Epoch: 1 | Iteration: 494 | Classification loss: 0.20478 | Regression loss: 0.26177 | Running loss: 0.37361\n","Epoch: 1 | Iteration: 495 | Classification loss: 0.37136 | Regression loss: 0.20428 | Running loss: 0.37476\n","Epoch: 1 | Iteration: 496 | Classification loss: 1.05166 | Regression loss: 0.44294 | Running loss: 0.37704\n","Epoch: 1 | Iteration: 497 | Classification loss: 0.26871 | Regression loss: 0.17495 | Running loss: 0.37743\n","Epoch: 1 | Iteration: 498 | Classification loss: 0.26225 | Regression loss: 0.25842 | Running loss: 0.37693\n","Epoch: 1 | Iteration: 499 | Classification loss: 0.08044 | Regression loss: 0.09105 | Running loss: 0.37642\n","Epoch: 1 | Iteration: 500 | Classification loss: 0.20245 | Regression loss: 0.00000 | Running loss: 0.37569\n","Epoch: 1 | Iteration: 501 | Classification loss: 0.00002 | Regression loss: 0.00029 | Running loss: 0.37491\n","Epoch: 1 | Iteration: 502 | Classification loss: 0.00001 | Regression loss: 0.00025 | Running loss: 0.37433\n","Epoch: 1 | Iteration: 503 | Classification loss: 0.00004 | Regression loss: 0.00075 | Running loss: 0.37360\n","Epoch: 1 | Iteration: 504 | Classification loss: 0.27360 | Regression loss: 0.36252 | Running loss: 0.37310\n","Epoch: 1 | Iteration: 505 | Classification loss: 0.13872 | Regression loss: 0.24613 | Running loss: 0.37258\n","Epoch: 1 | Iteration: 506 | Classification loss: 0.50337 | Regression loss: 0.47149 | Running loss: 0.37453\n","Epoch: 1 | Iteration: 507 | Classification loss: 0.13468 | Regression loss: 0.00000 | Running loss: 0.37373\n","Epoch: 1 | Iteration: 508 | Classification loss: 0.16596 | Regression loss: 0.11818 | Running loss: 0.37318\n","Epoch: 1 | Iteration: 509 | Classification loss: 0.30616 | Regression loss: 0.40303 | Running loss: 0.37361\n","Epoch: 1 | Iteration: 510 | Classification loss: 0.36729 | Regression loss: 0.26646 | Running loss: 0.37378\n","Epoch: 1 | Iteration: 511 | Classification loss: 0.22467 | Regression loss: 0.07645 | Running loss: 0.37351\n","Epoch: 1 | Iteration: 512 | Classification loss: 0.37338 | Regression loss: 0.31007 | Running loss: 0.37405\n","Epoch: 1 | Iteration: 513 | Classification loss: 0.24711 | Regression loss: 0.12519 | Running loss: 0.37455\n","Epoch: 1 | Iteration: 514 | Classification loss: 0.15592 | Regression loss: 0.15490 | Running loss: 0.37432\n","Epoch: 1 | Iteration: 515 | Classification loss: 0.09978 | Regression loss: 0.12391 | Running loss: 0.37475\n","Epoch: 1 | Iteration: 516 | Classification loss: 0.53123 | Regression loss: 0.23531 | Running loss: 0.37541\n","Epoch: 1 | Iteration: 517 | Classification loss: 0.25591 | Regression loss: 0.22481 | Running loss: 0.37593\n","Epoch: 1 | Iteration: 518 | Classification loss: 0.00000 | Regression loss: 0.00022 | Running loss: 0.37533\n","Epoch: 1 | Iteration: 519 | Classification loss: 0.17148 | Regression loss: 0.19659 | Running loss: 0.37444\n","Epoch: 1 | Iteration: 520 | Classification loss: 0.12190 | Regression loss: 0.09421 | Running loss: 0.37353\n","Epoch: 1 | Iteration: 521 | Classification loss: 0.07263 | Regression loss: 0.14844 | Running loss: 0.37313\n","Epoch: 1 | Iteration: 522 | Classification loss: 0.57289 | Regression loss: 0.42335 | Running loss: 0.37441\n","Epoch: 1 | Iteration: 523 | Classification loss: 0.27153 | Regression loss: 0.11054 | Running loss: 0.37487\n","Epoch: 1 | Iteration: 524 | Classification loss: 0.06557 | Regression loss: 0.15297 | Running loss: 0.37440\n","Epoch: 1 | Iteration: 525 | Classification loss: 0.66781 | Regression loss: 0.52000 | Running loss: 0.37603\n","Epoch: 1 | Iteration: 526 | Classification loss: 0.10062 | Regression loss: 0.03166 | Running loss: 0.37471\n","Epoch: 1 | Iteration: 527 | Classification loss: 0.32295 | Regression loss: 0.22336 | Running loss: 0.37580\n","Epoch: 1 | Iteration: 528 | Classification loss: 0.11605 | Regression loss: 0.22675 | Running loss: 0.37591\n","Epoch: 1 | Iteration: 529 | Classification loss: 0.09277 | Regression loss: 0.10089 | Running loss: 0.37573\n","Epoch: 1 | Iteration: 530 | Classification loss: 0.20407 | Regression loss: 0.25846 | Running loss: 0.37598\n","Epoch: 1 | Iteration: 531 | Classification loss: 0.36825 | Regression loss: 0.31492 | Running loss: 0.37684\n","Epoch: 1 | Iteration: 532 | Classification loss: 0.16556 | Regression loss: 0.11614 | Running loss: 0.37693\n","Epoch: 1 | Iteration: 533 | Classification loss: 0.08903 | Regression loss: 0.05447 | Running loss: 0.37610\n","Epoch: 1 | Iteration: 534 | Classification loss: 0.00283 | Regression loss: 0.00000 | Running loss: 0.37505\n","Epoch: 1 | Iteration: 535 | Classification loss: 0.33092 | Regression loss: 0.18794 | Running loss: 0.37495\n","Epoch: 1 | Iteration: 536 | Classification loss: 0.36483 | Regression loss: 0.15982 | Running loss: 0.37439\n","Epoch: 1 | Iteration: 537 | Classification loss: 0.07191 | Regression loss: 0.07248 | Running loss: 0.37468\n","Epoch: 1 | Iteration: 538 | Classification loss: 0.82984 | Regression loss: 0.58181 | Running loss: 0.37732\n","Epoch: 1 | Iteration: 539 | Classification loss: 0.25344 | Regression loss: 0.09749 | Running loss: 0.37802\n","Epoch: 1 | Iteration: 540 | Classification loss: 0.56461 | Regression loss: 0.50841 | Running loss: 0.37779\n","Epoch: 1 | Iteration: 541 | Classification loss: 0.52796 | Regression loss: 0.32430 | Running loss: 0.37838\n","Epoch: 1 | Iteration: 542 | Classification loss: 0.41156 | Regression loss: 0.33355 | Running loss: 0.37871\n","Epoch: 1 | Iteration: 543 | Classification loss: 0.46579 | Regression loss: 0.53566 | Running loss: 0.37935\n","Epoch: 1 | Iteration: 544 | Classification loss: 0.25483 | Regression loss: 0.28473 | Running loss: 0.37876\n","Epoch: 1 | Iteration: 545 | Classification loss: 0.10452 | Regression loss: 0.05626 | Running loss: 0.37871\n","Epoch: 1 | Iteration: 546 | Classification loss: 0.13520 | Regression loss: 0.07585 | Running loss: 0.37849\n","Epoch: 1 | Iteration: 547 | Classification loss: 0.19826 | Regression loss: 0.16024 | Running loss: 0.37853\n","Epoch: 1 | Iteration: 548 | Classification loss: 0.53197 | Regression loss: 0.30343 | Running loss: 0.37945\n","Epoch: 1 | Iteration: 549 | Classification loss: 0.15594 | Regression loss: 0.19562 | Running loss: 0.37823\n","Epoch: 1 | Iteration: 550 | Classification loss: 0.19338 | Regression loss: 0.08594 | Running loss: 0.37831\n","Epoch: 1 | Iteration: 551 | Classification loss: 0.11263 | Regression loss: 0.10589 | Running loss: 0.37815\n","Epoch: 1 | Iteration: 552 | Classification loss: 0.08373 | Regression loss: 0.03988 | Running loss: 0.37777\n","Epoch: 1 | Iteration: 553 | Classification loss: 0.10589 | Regression loss: 0.05916 | Running loss: 0.37711\n","Epoch: 1 | Iteration: 554 | Classification loss: 0.28755 | Regression loss: 0.08417 | Running loss: 0.37735\n","Epoch: 1 | Iteration: 555 | Classification loss: 0.08966 | Regression loss: 0.08933 | Running loss: 0.37769\n","Epoch: 1 | Iteration: 556 | Classification loss: 0.21509 | Regression loss: 0.09716 | Running loss: 0.37730\n","Epoch: 1 | Iteration: 557 | Classification loss: 0.07206 | Regression loss: 0.07176 | Running loss: 0.37711\n","Epoch: 1 | Iteration: 558 | Classification loss: 0.00529 | Regression loss: 0.00000 | Running loss: 0.37641\n","Epoch: 1 | Iteration: 559 | Classification loss: 0.29645 | Regression loss: 0.09874 | Running loss: 0.37645\n","Epoch: 1 | Iteration: 560 | Classification loss: 0.13830 | Regression loss: 0.09317 | Running loss: 0.37630\n","Epoch: 1 | Iteration: 561 | Classification loss: 0.00307 | Regression loss: 0.00000 | Running loss: 0.37631\n","Epoch: 1 | Iteration: 562 | Classification loss: 0.26693 | Regression loss: 0.15758 | Running loss: 0.37614\n","Epoch: 1 | Iteration: 563 | Classification loss: 0.22349 | Regression loss: 0.39542 | Running loss: 0.37670\n","Epoch: 1 | Iteration: 564 | Classification loss: 0.20520 | Regression loss: 0.07987 | Running loss: 0.37690\n","Epoch: 1 | Iteration: 565 | Classification loss: 0.21360 | Regression loss: 0.09170 | Running loss: 0.37700\n","Epoch: 1 | Iteration: 566 | Classification loss: 0.00006 | Regression loss: 0.00041 | Running loss: 0.37640\n","Epoch: 1 | Iteration: 567 | Classification loss: 0.00000 | Regression loss: 0.00020 | Running loss: 0.37571\n","Epoch: 1 | Iteration: 568 | Classification loss: 0.49734 | Regression loss: 0.30844 | Running loss: 0.37636\n","Epoch: 1 | Iteration: 569 | Classification loss: 0.24487 | Regression loss: 0.28780 | Running loss: 0.37742\n","Epoch: 1 | Iteration: 570 | Classification loss: 0.24998 | Regression loss: 0.14865 | Running loss: 0.37764\n","Epoch: 1 | Iteration: 571 | Classification loss: 0.16458 | Regression loss: 0.09920 | Running loss: 0.37729\n","Epoch: 1 | Iteration: 572 | Classification loss: 0.00000 | Regression loss: 0.00021 | Running loss: 0.37629\n","Epoch: 1 | Iteration: 573 | Classification loss: 0.57327 | Regression loss: 0.15465 | Running loss: 0.37593\n","Epoch: 1 | Iteration: 574 | Classification loss: 0.14582 | Regression loss: 0.16830 | Running loss: 0.37406\n","Epoch: 1 | Iteration: 575 | Classification loss: 0.32368 | Regression loss: 0.30457 | Running loss: 0.37360\n","Epoch: 1 | Iteration: 576 | Classification loss: 0.32679 | Regression loss: 0.16987 | Running loss: 0.37437\n","Epoch: 1 | Iteration: 577 | Classification loss: 0.02996 | Regression loss: 0.02808 | Running loss: 0.37244\n","Epoch: 1 | Iteration: 578 | Classification loss: 0.07727 | Regression loss: 0.13466 | Running loss: 0.37210\n","Epoch: 1 | Iteration: 579 | Classification loss: 0.25739 | Regression loss: 0.11612 | Running loss: 0.37196\n","Epoch: 1 | Iteration: 580 | Classification loss: 0.00000 | Regression loss: 0.00021 | Running loss: 0.37113\n","Epoch: 1 | Iteration: 581 | Classification loss: 0.21023 | Regression loss: 0.18519 | Running loss: 0.37082\n","Epoch: 1 | Iteration: 582 | Classification loss: 0.21087 | Regression loss: 0.19218 | Running loss: 0.37022\n","Epoch: 1 | Iteration: 583 | Classification loss: 0.28864 | Regression loss: 0.19012 | Running loss: 0.37064\n","Epoch: 1 | Iteration: 584 | Classification loss: 0.30253 | Regression loss: 0.11832 | Running loss: 0.37133\n","Epoch: 1 | Iteration: 585 | Classification loss: 0.11593 | Regression loss: 0.08248 | Running loss: 0.37032\n","Epoch: 1 | Iteration: 586 | Classification loss: 0.00001 | Regression loss: 0.00067 | Running loss: 0.37032\n","Epoch: 1 | Iteration: 587 | Classification loss: 0.51301 | Regression loss: 0.53222 | Running loss: 0.37199\n","Epoch: 1 | Iteration: 588 | Classification loss: 0.27036 | Regression loss: 0.20704 | Running loss: 0.37272\n","Epoch: 1 | Iteration: 589 | Classification loss: 0.25852 | Regression loss: 0.24989 | Running loss: 0.37351\n","Epoch: 1 | Iteration: 590 | Classification loss: 0.16345 | Regression loss: 0.29002 | Running loss: 0.37285\n","Epoch: 1 | Iteration: 591 | Classification loss: 0.34729 | Regression loss: 0.35312 | Running loss: 0.37325\n","Epoch: 1 | Iteration: 592 | Classification loss: 0.13251 | Regression loss: 0.08312 | Running loss: 0.37300\n","Epoch: 1 | Iteration: 593 | Classification loss: 0.17630 | Regression loss: 0.20424 | Running loss: 0.37293\n","Epoch: 1 | Iteration: 594 | Classification loss: 0.28369 | Regression loss: 0.12883 | Running loss: 0.37362\n","Epoch: 1 | Iteration: 595 | Classification loss: 0.09167 | Regression loss: 0.10974 | Running loss: 0.37209\n","Epoch: 1 | Iteration: 596 | Classification loss: 0.11710 | Regression loss: 0.04585 | Running loss: 0.37160\n","Epoch: 1 | Iteration: 597 | Classification loss: 0.00000 | Regression loss: 0.00019 | Running loss: 0.37098\n","Epoch: 1 | Iteration: 598 | Classification loss: 0.18670 | Regression loss: 0.21415 | Running loss: 0.37093\n","Epoch: 1 | Iteration: 599 | Classification loss: 0.17768 | Regression loss: 0.00000 | Running loss: 0.36981\n","Epoch: 1 | Iteration: 600 | Classification loss: 0.16969 | Regression loss: 0.12023 | Running loss: 0.37039\n","Epoch: 1 | Iteration: 601 | Classification loss: 0.22318 | Regression loss: 0.07783 | Running loss: 0.37082\n","Epoch: 1 | Iteration: 602 | Classification loss: 0.16436 | Regression loss: 0.24160 | Running loss: 0.37129\n","Epoch: 1 | Iteration: 603 | Classification loss: 0.16308 | Regression loss: 0.08541 | Running loss: 0.37131\n","Epoch: 1 | Iteration: 604 | Classification loss: 0.05817 | Regression loss: 0.00000 | Running loss: 0.37053\n","Epoch: 1 | Iteration: 605 | Classification loss: 0.00011 | Regression loss: 0.00034 | Running loss: 0.37030\n","Epoch: 1 | Iteration: 606 | Classification loss: 0.36661 | Regression loss: 0.44622 | Running loss: 0.37160\n","Epoch: 1 | Iteration: 607 | Classification loss: 0.06411 | Regression loss: 0.10009 | Running loss: 0.37093\n","Epoch: 1 | Iteration: 608 | Classification loss: 0.29778 | Regression loss: 0.13374 | Running loss: 0.37090\n","Epoch: 1 | Iteration: 609 | Classification loss: 0.08957 | Regression loss: 0.06724 | Running loss: 0.37042\n","Epoch: 1 | Iteration: 610 | Classification loss: 0.13013 | Regression loss: 0.04163 | Running loss: 0.36919\n","Epoch: 1 | Iteration: 611 | Classification loss: 0.29217 | Regression loss: 0.36725 | Running loss: 0.37023\n","Epoch: 1 | Iteration: 612 | Classification loss: 0.32946 | Regression loss: 0.28314 | Running loss: 0.36914\n","Epoch: 1 | Iteration: 613 | Classification loss: 0.25888 | Regression loss: 0.05069 | Running loss: 0.36937\n","Epoch: 1 | Iteration: 614 | Classification loss: 0.19089 | Regression loss: 0.07298 | Running loss: 0.36919\n","Epoch: 1 | Iteration: 615 | Classification loss: 0.25660 | Regression loss: 0.19414 | Running loss: 0.36944\n","Epoch: 1 | Iteration: 616 | Classification loss: 0.15725 | Regression loss: 0.07732 | Running loss: 0.36990\n","Epoch: 1 | Iteration: 617 | Classification loss: 0.13466 | Regression loss: 0.13498 | Running loss: 0.36980\n","Epoch: 1 | Iteration: 618 | Classification loss: 0.17015 | Regression loss: 0.23830 | Running loss: 0.36990\n","Epoch: 1 | Iteration: 619 | Classification loss: 0.20425 | Regression loss: 0.27401 | Running loss: 0.37015\n","Epoch: 1 | Iteration: 620 | Classification loss: 0.17910 | Regression loss: 0.09571 | Running loss: 0.37000\n","Epoch: 1 | Iteration: 621 | Classification loss: 0.18471 | Regression loss: 0.05135 | Running loss: 0.36991\n","Epoch: 1 | Iteration: 622 | Classification loss: 0.00001 | Regression loss: 0.00022 | Running loss: 0.36984\n","Epoch: 1 | Iteration: 623 | Classification loss: 0.17053 | Regression loss: 0.11029 | Running loss: 0.36930\n","Epoch: 1 | Iteration: 624 | Classification loss: 0.28063 | Regression loss: 0.33151 | Running loss: 0.36987\n","Epoch: 1 | Iteration: 625 | Classification loss: 0.66645 | Regression loss: 0.31778 | Running loss: 0.37119\n","Epoch: 1 | Iteration: 626 | Classification loss: 0.21184 | Regression loss: 0.19270 | Running loss: 0.37172\n","Epoch: 1 | Iteration: 627 | Classification loss: 0.00014 | Regression loss: 0.00040 | Running loss: 0.37098\n","Epoch: 1 | Iteration: 628 | Classification loss: 0.00011 | Regression loss: 0.00031 | Running loss: 0.37066\n","Epoch: 1 | Iteration: 629 | Classification loss: 0.00000 | Regression loss: 0.00046 | Running loss: 0.37066\n","Epoch: 1 | Iteration: 630 | Classification loss: 0.23475 | Regression loss: 0.13480 | Running loss: 0.36971\n","Epoch: 1 | Iteration: 631 | Classification loss: 0.73171 | Regression loss: 0.00000 | Running loss: 0.36972\n","Epoch: 1 | Iteration: 632 | Classification loss: 0.27234 | Regression loss: 0.12349 | Running loss: 0.36975\n","Epoch: 1 | Iteration: 633 | Classification loss: 0.00001 | Regression loss: 0.00046 | Running loss: 0.36807\n","Epoch: 1 | Iteration: 634 | Classification loss: 0.39586 | Regression loss: 0.24253 | Running loss: 0.36853\n","Epoch: 1 | Iteration: 635 | Classification loss: 0.41437 | Regression loss: 0.57828 | Running loss: 0.36943\n","Epoch: 1 | Iteration: 636 | Classification loss: 0.12435 | Regression loss: 0.10202 | Running loss: 0.36928\n","Epoch: 1 | Iteration: 637 | Classification loss: 0.15636 | Regression loss: 0.10318 | Running loss: 0.36786\n","Epoch: 1 | Iteration: 638 | Classification loss: 0.09084 | Regression loss: 0.21862 | Running loss: 0.36758\n","Epoch: 1 | Iteration: 639 | Classification loss: 0.15888 | Regression loss: 0.15901 | Running loss: 0.36702\n","Epoch: 1 | Iteration: 640 | Classification loss: 0.14823 | Regression loss: 0.06910 | Running loss: 0.36746\n","Epoch: 1 | Iteration: 641 | Classification loss: 0.13062 | Regression loss: 0.08215 | Running loss: 0.36783\n","Epoch: 1 | Iteration: 642 | Classification loss: 0.18063 | Regression loss: 0.19590 | Running loss: 0.36840\n","Epoch: 1 | Iteration: 643 | Classification loss: 0.00000 | Regression loss: 0.00031 | Running loss: 0.36805\n","Epoch: 1 | Iteration: 644 | Classification loss: 0.11078 | Regression loss: 0.04002 | Running loss: 0.36757\n","Epoch: 1 | Iteration: 645 | Classification loss: 0.06422 | Regression loss: 0.07208 | Running loss: 0.36783\n","Epoch: 1 | Iteration: 646 | Classification loss: 0.00012 | Regression loss: 0.00041 | Running loss: 0.36776\n","Epoch: 1 | Iteration: 647 | Classification loss: 0.00000 | Regression loss: 0.00047 | Running loss: 0.36657\n","Epoch: 1 | Iteration: 648 | Classification loss: 0.15210 | Regression loss: 0.00000 | Running loss: 0.36687\n","Epoch: 1 | Iteration: 649 | Classification loss: 0.07913 | Regression loss: 0.05290 | Running loss: 0.36651\n","Epoch: 1 | Iteration: 650 | Classification loss: 0.00000 | Regression loss: 0.00025 | Running loss: 0.36579\n","Epoch: 1 | Iteration: 651 | Classification loss: 0.44979 | Regression loss: 0.11738 | Running loss: 0.36632\n","Epoch: 1 | Iteration: 652 | Classification loss: 0.09193 | Regression loss: 0.23539 | Running loss: 0.36667\n","Epoch: 1 | Iteration: 653 | Classification loss: 0.13769 | Regression loss: 0.17266 | Running loss: 0.36669\n","Epoch: 1 | Iteration: 654 | Classification loss: 0.22877 | Regression loss: 0.03472 | Running loss: 0.36647\n","Epoch: 1 | Iteration: 655 | Classification loss: 0.57591 | Regression loss: 0.40385 | Running loss: 0.36802\n","Epoch: 1 | Iteration: 656 | Classification loss: 0.20539 | Regression loss: 0.22188 | Running loss: 0.36813\n","Epoch: 1 | Iteration: 657 | Classification loss: 0.00000 | Regression loss: 0.00034 | Running loss: 0.36813\n","Epoch: 1 | Iteration: 658 | Classification loss: 0.00000 | Regression loss: 0.00069 | Running loss: 0.36713\n","Epoch: 1 | Iteration: 659 | Classification loss: 0.25577 | Regression loss: 0.23003 | Running loss: 0.36772\n","Epoch: 1 | Iteration: 660 | Classification loss: 0.19223 | Regression loss: 0.12187 | Running loss: 0.36779\n","Epoch: 1 | Iteration: 661 | Classification loss: 0.29571 | Regression loss: 0.10946 | Running loss: 0.36860\n","Epoch: 1 | Iteration: 662 | Classification loss: 0.11010 | Regression loss: 0.11933 | Running loss: 0.36872\n","Epoch: 1 | Iteration: 663 | Classification loss: 0.55111 | Regression loss: 0.28111 | Running loss: 0.36906\n","Epoch: 1 | Iteration: 664 | Classification loss: 0.06646 | Regression loss: 0.11020 | Running loss: 0.36844\n","Epoch: 1 | Iteration: 665 | Classification loss: 0.04927 | Regression loss: 0.03175 | Running loss: 0.36795\n","Epoch: 1 | Iteration: 666 | Classification loss: 0.28110 | Regression loss: 0.23047 | Running loss: 0.36869\n","Epoch: 1 | Iteration: 667 | Classification loss: 0.26305 | Regression loss: 0.36206 | Running loss: 0.36903\n","Epoch: 1 | Iteration: 668 | Classification loss: 0.30004 | Regression loss: 0.21713 | Running loss: 0.36921\n","Epoch: 1 | Iteration: 669 | Classification loss: 0.22980 | Regression loss: 0.31327 | Running loss: 0.36973\n","Epoch: 1 | Iteration: 670 | Classification loss: 0.14254 | Regression loss: 0.23670 | Running loss: 0.36944\n","Epoch: 1 | Iteration: 671 | Classification loss: 0.20326 | Regression loss: 0.35403 | Running loss: 0.36908\n","Epoch: 1 | Iteration: 672 | Classification loss: 0.24314 | Regression loss: 0.09032 | Running loss: 0.36862\n","Epoch: 1 | Iteration: 673 | Classification loss: 0.79347 | Regression loss: 0.34794 | Running loss: 0.37021\n","Epoch: 1 | Iteration: 674 | Classification loss: 0.18703 | Regression loss: 0.07694 | Running loss: 0.36939\n","Epoch: 1 | Iteration: 675 | Classification loss: 0.09076 | Regression loss: 0.03653 | Running loss: 0.36803\n","Epoch: 1 | Iteration: 676 | Classification loss: 0.11882 | Regression loss: 0.00000 | Running loss: 0.36748\n","Epoch: 1 | Iteration: 677 | Classification loss: 0.88543 | Regression loss: 0.22683 | Running loss: 0.36925\n","Epoch: 1 | Iteration: 678 | Classification loss: 0.20209 | Regression loss: 0.28673 | Running loss: 0.36987\n","Epoch: 1 | Iteration: 679 | Classification loss: 0.00001 | Regression loss: 0.00037 | Running loss: 0.36959\n","Epoch: 1 | Iteration: 680 | Classification loss: 0.33280 | Regression loss: 0.54337 | Running loss: 0.37122\n","Epoch: 1 | Iteration: 681 | Classification loss: 0.11040 | Regression loss: 0.06815 | Running loss: 0.36982\n","Epoch: 1 | Iteration: 682 | Classification loss: 0.12988 | Regression loss: 0.00000 | Running loss: 0.36834\n","Epoch: 1 | Iteration: 683 | Classification loss: 0.20481 | Regression loss: 0.11983 | Running loss: 0.36845\n","Epoch: 1 | Iteration: 684 | Classification loss: 0.00004 | Regression loss: 0.00042 | Running loss: 0.36844\n","Epoch: 1 | Iteration: 685 | Classification loss: 0.36202 | Regression loss: 0.39514 | Running loss: 0.36995\n","Epoch: 1 | Iteration: 686 | Classification loss: 0.07763 | Regression loss: 0.06958 | Running loss: 0.37013\n","Epoch: 1 | Iteration: 687 | Classification loss: 0.00076 | Regression loss: 0.00079 | Running loss: 0.36946\n","Epoch: 1 | Iteration: 688 | Classification loss: 0.17237 | Regression loss: 0.12303 | Running loss: 0.36890\n","Epoch: 1 | Iteration: 689 | Classification loss: 0.38683 | Regression loss: 0.37586 | Running loss: 0.36962\n","Epoch: 1 | Iteration: 690 | Classification loss: 0.07433 | Regression loss: 0.07487 | Running loss: 0.36989\n","Epoch: 1 | Iteration: 691 | Classification loss: 0.00002 | Regression loss: 0.00020 | Running loss: 0.36938\n","Epoch: 1 | Iteration: 692 | Classification loss: 0.15117 | Regression loss: 0.19109 | Running loss: 0.36923\n","Epoch: 1 | Iteration: 693 | Classification loss: 0.12335 | Regression loss: 0.13486 | Running loss: 0.36933\n","Epoch: 1 | Iteration: 694 | Classification loss: 0.33456 | Regression loss: 0.12278 | Running loss: 0.36974\n","Epoch: 1 | Iteration: 695 | Classification loss: 0.11027 | Regression loss: 0.20531 | Running loss: 0.36890\n","Epoch: 1 | Iteration: 696 | Classification loss: 0.00000 | Regression loss: 0.00040 | Running loss: 0.36781\n","Epoch: 1 | Iteration: 697 | Classification loss: 0.06397 | Regression loss: 0.12207 | Running loss: 0.36807\n","Epoch: 1 | Iteration: 698 | Classification loss: 0.41151 | Regression loss: 0.48466 | Running loss: 0.36888\n","Epoch: 1 | Iteration: 699 | Classification loss: 0.22246 | Regression loss: 0.32562 | Running loss: 0.36937\n","Epoch: 1 | Iteration: 700 | Classification loss: 0.03951 | Regression loss: 0.11908 | Running loss: 0.36954\n","Epoch: 1 | Iteration: 701 | Classification loss: 0.11309 | Regression loss: 0.04126 | Running loss: 0.36924\n","Epoch: 1 | Iteration: 702 | Classification loss: 0.65642 | Regression loss: 0.45843 | Running loss: 0.37147\n","Epoch: 1 | Iteration: 703 | Classification loss: 0.24218 | Regression loss: 0.08992 | Running loss: 0.37140\n","Epoch: 1 | Iteration: 704 | Classification loss: 0.15910 | Regression loss: 0.05195 | Running loss: 0.37138\n","Epoch: 1 | Iteration: 705 | Classification loss: 0.08048 | Regression loss: 0.15395 | Running loss: 0.37159\n","Epoch: 1 | Iteration: 706 | Classification loss: 0.28834 | Regression loss: 0.17677 | Running loss: 0.37203\n","Epoch: 1 | Iteration: 707 | Classification loss: 0.13803 | Regression loss: 0.08616 | Running loss: 0.37063\n","Epoch: 1 | Iteration: 708 | Classification loss: 0.63157 | Regression loss: 0.33532 | Running loss: 0.37149\n","Epoch: 1 | Iteration: 709 | Classification loss: 0.09381 | Regression loss: 0.06935 | Running loss: 0.37060\n","Epoch: 1 | Iteration: 710 | Classification loss: 0.13479 | Regression loss: 0.12542 | Running loss: 0.37069\n","Epoch: 1 | Iteration: 711 | Classification loss: 0.31221 | Regression loss: 0.19504 | Running loss: 0.37171\n","Epoch: 1 | Iteration: 712 | Classification loss: 0.13117 | Regression loss: 0.13120 | Running loss: 0.37132\n","Epoch: 1 | Iteration: 713 | Classification loss: 0.16294 | Regression loss: 0.03851 | Running loss: 0.37070\n","Epoch: 1 | Iteration: 714 | Classification loss: 0.07709 | Regression loss: 0.01482 | Running loss: 0.37026\n","Epoch: 1 | Iteration: 715 | Classification loss: 0.32643 | Regression loss: 0.30589 | Running loss: 0.37102\n","Epoch: 1 | Iteration: 716 | Classification loss: 0.22297 | Regression loss: 0.07233 | Running loss: 0.37125\n","Epoch: 1 | Iteration: 717 | Classification loss: 0.19811 | Regression loss: 0.07038 | Running loss: 0.37130\n","Epoch: 1 | Iteration: 718 | Classification loss: 0.02828 | Regression loss: 0.01310 | Running loss: 0.37096\n","Epoch: 1 | Iteration: 719 | Classification loss: 0.27284 | Regression loss: 0.11903 | Running loss: 0.37041\n","Epoch: 1 | Iteration: 720 | Classification loss: 0.20703 | Regression loss: 0.07227 | Running loss: 0.37003\n","Epoch: 1 | Iteration: 721 | Classification loss: 0.00000 | Regression loss: 0.00126 | Running loss: 0.36898\n","Epoch: 1 | Iteration: 722 | Classification loss: 0.17057 | Regression loss: 0.03580 | Running loss: 0.36940\n","Epoch: 1 | Iteration: 723 | Classification loss: 0.23512 | Regression loss: 0.21765 | Running loss: 0.36926\n","Epoch: 1 | Iteration: 724 | Classification loss: 0.12686 | Regression loss: 0.08891 | Running loss: 0.36862\n","Epoch: 1 | Iteration: 725 | Classification loss: 0.13560 | Regression loss: 0.05297 | Running loss: 0.36795\n","Epoch: 1 | Iteration: 726 | Classification loss: 0.00001 | Regression loss: 0.00029 | Running loss: 0.36692\n","Epoch: 1 | Iteration: 727 | Classification loss: 0.30392 | Regression loss: 0.23718 | Running loss: 0.36795\n","Epoch: 1 | Iteration: 728 | Classification loss: 0.19087 | Regression loss: 0.09143 | Running loss: 0.36771\n","Epoch: 1 | Iteration: 729 | Classification loss: 0.17754 | Regression loss: 0.11711 | Running loss: 0.36700\n","Epoch: 1 | Iteration: 730 | Classification loss: 0.23956 | Regression loss: 0.12630 | Running loss: 0.36745\n","Epoch: 1 | Iteration: 731 | Classification loss: 0.27746 | Regression loss: 0.35980 | Running loss: 0.36801\n","Epoch: 1 | Iteration: 732 | Classification loss: 0.11887 | Regression loss: 0.14576 | Running loss: 0.36770\n","Epoch: 1 | Iteration: 733 | Classification loss: 0.10732 | Regression loss: 0.12478 | Running loss: 0.36755\n","Epoch: 1 | Iteration: 734 | Classification loss: 0.30540 | Regression loss: 0.13432 | Running loss: 0.36801\n","Epoch: 1 | Iteration: 735 | Classification loss: 0.01548 | Regression loss: 0.02125 | Running loss: 0.36799\n","Epoch: 1 | Iteration: 736 | Classification loss: 0.19449 | Regression loss: 0.25018 | Running loss: 0.36787\n","Epoch: 1 | Iteration: 737 | Classification loss: 0.35104 | Regression loss: 0.35112 | Running loss: 0.36690\n","Epoch: 1 | Iteration: 738 | Classification loss: 0.08761 | Regression loss: 0.15172 | Running loss: 0.36680\n","Epoch: 1 | Iteration: 739 | Classification loss: 0.12581 | Regression loss: 0.06825 | Running loss: 0.36623\n","Epoch: 1 | Iteration: 740 | Classification loss: 0.44224 | Regression loss: 0.36395 | Running loss: 0.36693\n","Epoch: 1 | Iteration: 741 | Classification loss: 0.09279 | Regression loss: 0.06509 | Running loss: 0.36610\n","Epoch: 1 | Iteration: 742 | Classification loss: 0.09109 | Regression loss: 0.12844 | Running loss: 0.36512\n","Epoch: 1 | Iteration: 743 | Classification loss: 0.25132 | Regression loss: 0.43786 | Running loss: 0.36547\n","Epoch: 1 | Iteration: 744 | Classification loss: 0.00000 | Regression loss: 0.00069 | Running loss: 0.36537\n","Epoch: 1 | Iteration: 745 | Classification loss: 0.25402 | Regression loss: 0.44131 | Running loss: 0.36501\n","Epoch: 1 | Iteration: 746 | Classification loss: 0.23443 | Regression loss: 0.15065 | Running loss: 0.36498\n","Epoch: 1 | Iteration: 747 | Classification loss: 0.09088 | Regression loss: 0.15632 | Running loss: 0.36483\n","Epoch: 1 | Iteration: 748 | Classification loss: 0.30628 | Regression loss: 0.21646 | Running loss: 0.36521\n","Epoch: 1 | Iteration: 749 | Classification loss: 0.00001 | Regression loss: 0.00048 | Running loss: 0.36435\n","Epoch: 1 | Iteration: 750 | Classification loss: 0.27188 | Regression loss: 0.40412 | Running loss: 0.36570\n","Epoch: 1 | Iteration: 751 | Classification loss: 0.08792 | Regression loss: 0.31905 | Running loss: 0.36624\n","Epoch: 1 | Iteration: 752 | Classification loss: 0.13029 | Regression loss: 0.34096 | Running loss: 0.36614\n","Epoch: 1 | Iteration: 753 | Classification loss: 0.20351 | Regression loss: 0.08319 | Running loss: 0.36589\n","Epoch: 1 | Iteration: 754 | Classification loss: 0.05414 | Regression loss: 0.03459 | Running loss: 0.36566\n","Epoch: 1 | Iteration: 755 | Classification loss: 0.13445 | Regression loss: 0.08350 | Running loss: 0.36535\n","Epoch: 1 | Iteration: 756 | Classification loss: 0.10900 | Regression loss: 0.07012 | Running loss: 0.36473\n","Epoch: 1 | Iteration: 757 | Classification loss: 0.13514 | Regression loss: 0.02647 | Running loss: 0.36501\n","Epoch: 1 | Iteration: 758 | Classification loss: 0.00001 | Regression loss: 0.00080 | Running loss: 0.36398\n","Epoch: 1 | Iteration: 759 | Classification loss: 0.11143 | Regression loss: 0.09045 | Running loss: 0.36305\n","Epoch: 1 | Iteration: 760 | Classification loss: 0.07725 | Regression loss: 0.18700 | Running loss: 0.36306\n","Epoch: 1 | Iteration: 761 | Classification loss: 0.16047 | Regression loss: 0.08040 | Running loss: 0.36354\n","Epoch: 1 | Iteration: 762 | Classification loss: 0.16129 | Regression loss: 0.00000 | Running loss: 0.36342\n","Epoch: 1 | Iteration: 763 | Classification loss: 0.13286 | Regression loss: 0.08048 | Running loss: 0.36385\n","Epoch: 1 | Iteration: 764 | Classification loss: 0.42160 | Regression loss: 0.26329 | Running loss: 0.36400\n","Epoch: 1 | Iteration: 765 | Classification loss: 0.26002 | Regression loss: 0.32728 | Running loss: 0.36406\n","Epoch: 1 | Iteration: 766 | Classification loss: 0.33285 | Regression loss: 0.30739 | Running loss: 0.36365\n","Epoch: 1 | Iteration: 767 | Classification loss: 0.16624 | Regression loss: 0.10222 | Running loss: 0.36352\n","Epoch: 1 | Iteration: 768 | Classification loss: 0.15545 | Regression loss: 0.14248 | Running loss: 0.36412\n","Epoch: 1 | Iteration: 769 | Classification loss: 0.00001 | Regression loss: 0.00029 | Running loss: 0.36294\n","Epoch: 1 | Iteration: 770 | Classification loss: 0.03374 | Regression loss: 0.03233 | Running loss: 0.36215\n","Epoch: 1 | Iteration: 771 | Classification loss: 0.00015 | Regression loss: 0.00077 | Running loss: 0.36215\n","Epoch: 1 | Iteration: 772 | Classification loss: 0.00000 | Regression loss: 0.00064 | Running loss: 0.36172\n","Epoch: 1 | Iteration: 773 | Classification loss: 0.00000 | Regression loss: 0.00016 | Running loss: 0.36065\n","Epoch: 1 | Iteration: 774 | Classification loss: 0.10412 | Regression loss: 0.06925 | Running loss: 0.36006\n","Epoch: 1 | Iteration: 775 | Classification loss: 0.11165 | Regression loss: 0.10605 | Running loss: 0.36021\n","Epoch: 1 | Iteration: 776 | Classification loss: 0.10007 | Regression loss: 0.18588 | Running loss: 0.36018\n","Epoch: 1 | Iteration: 777 | Classification loss: 0.04884 | Regression loss: 0.10618 | Running loss: 0.35897\n","Epoch: 1 | Iteration: 778 | Classification loss: 0.39679 | Regression loss: 0.40025 | Running loss: 0.35996\n","Epoch: 1 | Iteration: 779 | Classification loss: 0.25686 | Regression loss: 0.15888 | Running loss: 0.36033\n","Epoch: 1 | Iteration: 780 | Classification loss: 0.18530 | Regression loss: 0.12514 | Running loss: 0.35989\n","1\n","Evaluating dataset\n","\n","mAP:\n","bird: 0.20412379315950752\n","bobcat: 0.007906362803728247\n","car: 1.0\n","cat: 0.02120653262659221\n","raccoon: 0.050562955923221846\n","rabbit: 0.05390070921985815\n","coyote: 0.06908997414082178\n","squirrel: 0.24925322693179836\n","0.36589328402718324\n","---------------------------------------\n","Epoch: 2 | Iteration: 0 | Classification loss: 0.30083 | Regression loss: 0.61468 | Running loss: 0.36123\n","Epoch: 2 | Iteration: 1 | Classification loss: 0.31509 | Regression loss: 0.14018 | Running loss: 0.36127\n","Epoch: 2 | Iteration: 2 | Classification loss: 0.15910 | Regression loss: 0.21749 | Running loss: 0.36127\n","Epoch: 2 | Iteration: 3 | Classification loss: 0.14822 | Regression loss: 0.13402 | Running loss: 0.36123\n","Epoch: 2 | Iteration: 4 | Classification loss: 0.13957 | Regression loss: 0.04295 | Running loss: 0.36160\n","Epoch: 2 | Iteration: 5 | Classification loss: 0.22335 | Regression loss: 0.14244 | Running loss: 0.36059\n","Epoch: 2 | Iteration: 6 | Classification loss: 0.00010 | Regression loss: 0.00041 | Running loss: 0.35927\n","Epoch: 2 | Iteration: 7 | Classification loss: 0.15577 | Regression loss: 0.09770 | Running loss: 0.35945\n","Epoch: 2 | Iteration: 8 | Classification loss: 0.31042 | Regression loss: 0.31163 | Running loss: 0.36015\n","Epoch: 2 | Iteration: 9 | Classification loss: 0.00000 | Regression loss: 0.00045 | Running loss: 0.35969\n","Epoch: 2 | Iteration: 10 | Classification loss: 0.39150 | Regression loss: 0.40595 | Running loss: 0.36090\n","Epoch: 2 | Iteration: 11 | Classification loss: 0.47355 | Regression loss: 0.35997 | Running loss: 0.36104\n","Epoch: 2 | Iteration: 12 | Classification loss: 0.00002 | Regression loss: 0.00023 | Running loss: 0.35982\n","Epoch: 2 | Iteration: 13 | Classification loss: 0.11693 | Regression loss: 0.04119 | Running loss: 0.35858\n","Epoch: 2 | Iteration: 14 | Classification loss: 0.18286 | Regression loss: 0.10874 | Running loss: 0.35826\n","Epoch: 2 | Iteration: 15 | Classification loss: 0.00009 | Regression loss: 0.00053 | Running loss: 0.35766\n","Epoch: 2 | Iteration: 16 | Classification loss: 0.04355 | Regression loss: 0.02325 | Running loss: 0.35729\n","Epoch: 2 | Iteration: 17 | Classification loss: 0.00004 | Regression loss: 0.00118 | Running loss: 0.35657\n","Epoch: 2 | Iteration: 18 | Classification loss: 0.33405 | Regression loss: 0.14110 | Running loss: 0.35672\n","Epoch: 2 | Iteration: 19 | Classification loss: 0.33573 | Regression loss: 0.42851 | Running loss: 0.35802\n","Epoch: 2 | Iteration: 20 | Classification loss: 0.24252 | Regression loss: 0.25323 | Running loss: 0.35745\n","Epoch: 2 | Iteration: 21 | Classification loss: 0.21380 | Regression loss: 0.21389 | Running loss: 0.35799\n","Epoch: 2 | Iteration: 22 | Classification loss: 0.08283 | Regression loss: 0.06035 | Running loss: 0.35679\n","Epoch: 2 | Iteration: 23 | Classification loss: 0.00000 | Regression loss: 0.00011 | Running loss: 0.35594\n","Epoch: 2 | Iteration: 24 | Classification loss: 0.61865 | Regression loss: 0.56290 | Running loss: 0.35731\n","Epoch: 2 | Iteration: 25 | Classification loss: 0.20464 | Regression loss: 0.08999 | Running loss: 0.35641\n","Epoch: 2 | Iteration: 26 | Classification loss: 0.26377 | Regression loss: 0.14370 | Running loss: 0.35669\n","Epoch: 2 | Iteration: 27 | Classification loss: 0.10677 | Regression loss: 0.11728 | Running loss: 0.35601\n","Epoch: 2 | Iteration: 28 | Classification loss: 0.00028 | Regression loss: 0.00099 | Running loss: 0.35501\n","Epoch: 2 | Iteration: 29 | Classification loss: 0.19967 | Regression loss: 0.02910 | Running loss: 0.35403\n","Epoch: 2 | Iteration: 30 | Classification loss: 0.13350 | Regression loss: 0.08325 | Running loss: 0.35308\n","Epoch: 2 | Iteration: 31 | Classification loss: 0.11006 | Regression loss: 0.22184 | Running loss: 0.35289\n","Epoch: 2 | Iteration: 32 | Classification loss: 0.09409 | Regression loss: 0.00000 | Running loss: 0.35178\n","Epoch: 2 | Iteration: 33 | Classification loss: 0.17868 | Regression loss: 0.14946 | Running loss: 0.35178\n","Epoch: 2 | Iteration: 34 | Classification loss: 0.16185 | Regression loss: 0.11224 | Running loss: 0.35158\n","Epoch: 2 | Iteration: 35 | Classification loss: 0.25033 | Regression loss: 0.23933 | Running loss: 0.35192\n","Epoch: 2 | Iteration: 36 | Classification loss: 0.15648 | Regression loss: 0.07406 | Running loss: 0.35041\n","Epoch: 2 | Iteration: 37 | Classification loss: 0.02380 | Regression loss: 0.01537 | Running loss: 0.34894\n","Epoch: 2 | Iteration: 38 | Classification loss: 0.07837 | Regression loss: 0.11967 | Running loss: 0.34872\n","Epoch: 2 | Iteration: 39 | Classification loss: 0.42053 | Regression loss: 0.21352 | Running loss: 0.34932\n","Epoch: 2 | Iteration: 40 | Classification loss: 0.07886 | Regression loss: 0.18431 | Running loss: 0.34912\n","Epoch: 2 | Iteration: 41 | Classification loss: 0.39018 | Regression loss: 0.25998 | Running loss: 0.34922\n","Epoch: 2 | Iteration: 42 | Classification loss: 0.06861 | Regression loss: 0.08885 | Running loss: 0.34840\n","Epoch: 2 | Iteration: 43 | Classification loss: 0.24659 | Regression loss: 0.18003 | Running loss: 0.34843\n","Epoch: 2 | Iteration: 44 | Classification loss: 0.07097 | Regression loss: 0.01270 | Running loss: 0.34741\n","Epoch: 2 | Iteration: 45 | Classification loss: 0.32506 | Regression loss: 0.25969 | Running loss: 0.34803\n","Epoch: 2 | Iteration: 46 | Classification loss: 0.27957 | Regression loss: 0.23951 | Running loss: 0.34757\n","Epoch: 2 | Iteration: 47 | Classification loss: 0.09640 | Regression loss: 0.07315 | Running loss: 0.34737\n","Epoch: 2 | Iteration: 48 | Classification loss: 0.50548 | Regression loss: 0.25365 | Running loss: 0.34681\n","Epoch: 2 | Iteration: 49 | Classification loss: 0.26591 | Regression loss: 0.43553 | Running loss: 0.34752\n","Epoch: 2 | Iteration: 50 | Classification loss: 0.15942 | Regression loss: 0.11794 | Running loss: 0.34808\n","Epoch: 2 | Iteration: 51 | Classification loss: 0.27531 | Regression loss: 0.24346 | Running loss: 0.34857\n","Epoch: 2 | Iteration: 52 | Classification loss: 0.00001 | Regression loss: 0.00020 | Running loss: 0.34802\n","Epoch: 2 | Iteration: 53 | Classification loss: 0.15328 | Regression loss: 0.15461 | Running loss: 0.34726\n","Epoch: 2 | Iteration: 54 | Classification loss: 0.29908 | Regression loss: 0.69383 | Running loss: 0.34859\n","Epoch: 2 | Iteration: 55 | Classification loss: 0.15130 | Regression loss: 0.13116 | Running loss: 0.34812\n","Epoch: 2 | Iteration: 56 | Classification loss: 0.16395 | Regression loss: 0.30623 | Running loss: 0.34906\n","Epoch: 2 | Iteration: 57 | Classification loss: 0.46421 | Regression loss: 0.28304 | Running loss: 0.34989\n","Epoch: 2 | Iteration: 58 | Classification loss: 0.20577 | Regression loss: 0.15683 | Running loss: 0.34994\n","Epoch: 2 | Iteration: 59 | Classification loss: 0.70261 | Regression loss: 0.37039 | Running loss: 0.35130\n","Epoch: 2 | Iteration: 60 | Classification loss: 0.90347 | Regression loss: 0.18779 | Running loss: 0.35254\n","Epoch: 2 | Iteration: 61 | Classification loss: 0.08264 | Regression loss: 0.02509 | Running loss: 0.35156\n","Epoch: 2 | Iteration: 62 | Classification loss: 0.13357 | Regression loss: 0.05656 | Running loss: 0.35147\n","Epoch: 2 | Iteration: 63 | Classification loss: 0.07476 | Regression loss: 0.05648 | Running loss: 0.35088\n","Epoch: 2 | Iteration: 64 | Classification loss: 0.11673 | Regression loss: 0.06690 | Running loss: 0.35090\n","Epoch: 2 | Iteration: 65 | Classification loss: 0.36049 | Regression loss: 0.17922 | Running loss: 0.35165\n","Epoch: 2 | Iteration: 66 | Classification loss: 0.23388 | Regression loss: 0.31781 | Running loss: 0.35175\n","Epoch: 2 | Iteration: 67 | Classification loss: 0.14178 | Regression loss: 0.00000 | Running loss: 0.35078\n","Epoch: 2 | Iteration: 68 | Classification loss: 0.14778 | Regression loss: 0.15638 | Running loss: 0.35139\n","Epoch: 2 | Iteration: 69 | Classification loss: 0.15860 | Regression loss: 0.09987 | Running loss: 0.35123\n","Epoch: 2 | Iteration: 70 | Classification loss: 0.29458 | Regression loss: 0.26667 | Running loss: 0.35204\n","Epoch: 2 | Iteration: 71 | Classification loss: 0.23457 | Regression loss: 0.07138 | Running loss: 0.35265\n","Epoch: 2 | Iteration: 72 | Classification loss: 0.15350 | Regression loss: 0.17456 | Running loss: 0.35242\n","Epoch: 2 | Iteration: 73 | Classification loss: 0.06414 | Regression loss: 0.04866 | Running loss: 0.35149\n","Epoch: 2 | Iteration: 74 | Classification loss: 0.07473 | Regression loss: 0.05919 | Running loss: 0.35089\n","Epoch: 2 | Iteration: 75 | Classification loss: 0.00000 | Regression loss: 0.00055 | Running loss: 0.35009\n","Epoch: 2 | Iteration: 76 | Classification loss: 0.38388 | Regression loss: 0.52035 | Running loss: 0.35120\n","Epoch: 2 | Iteration: 77 | Classification loss: 0.29836 | Regression loss: 0.37235 | Running loss: 0.35254\n","Epoch: 2 | Iteration: 78 | Classification loss: 0.22798 | Regression loss: 0.21069 | Running loss: 0.35254\n","Epoch: 2 | Iteration: 79 | Classification loss: 0.26782 | Regression loss: 0.18370 | Running loss: 0.35258\n","Epoch: 2 | Iteration: 80 | Classification loss: 0.17629 | Regression loss: 0.13636 | Running loss: 0.35291\n","Epoch: 2 | Iteration: 81 | Classification loss: 0.37428 | Regression loss: 0.20137 | Running loss: 0.35406\n","Epoch: 2 | Iteration: 82 | Classification loss: 0.19085 | Regression loss: 0.11640 | Running loss: 0.35431\n","Epoch: 2 | Iteration: 83 | Classification loss: 0.41174 | Regression loss: 0.39868 | Running loss: 0.35593\n","Epoch: 2 | Iteration: 84 | Classification loss: 0.17420 | Regression loss: 0.20601 | Running loss: 0.35669\n","Epoch: 2 | Iteration: 85 | Classification loss: 0.60399 | Regression loss: 0.45999 | Running loss: 0.35789\n","Epoch: 2 | Iteration: 86 | Classification loss: 0.47612 | Regression loss: 0.10617 | Running loss: 0.35736\n","Epoch: 2 | Iteration: 87 | Classification loss: 0.77658 | Regression loss: 0.00000 | Running loss: 0.35777\n","Epoch: 2 | Iteration: 88 | Classification loss: 0.18524 | Regression loss: 0.09637 | Running loss: 0.35805\n","Epoch: 2 | Iteration: 89 | Classification loss: 0.17305 | Regression loss: 0.09053 | Running loss: 0.35823\n","Epoch: 2 | Iteration: 90 | Classification loss: 0.27704 | Regression loss: 0.29359 | Running loss: 0.35909\n","Epoch: 2 | Iteration: 91 | Classification loss: 0.23610 | Regression loss: 0.11762 | Running loss: 0.35850\n","Epoch: 2 | Iteration: 92 | Classification loss: 0.15742 | Regression loss: 0.11770 | Running loss: 0.35849\n","Epoch: 2 | Iteration: 93 | Classification loss: 0.17639 | Regression loss: 0.05350 | Running loss: 0.35747\n","Epoch: 2 | Iteration: 94 | Classification loss: 0.33023 | Regression loss: 0.34112 | Running loss: 0.35808\n","Epoch: 2 | Iteration: 95 | Classification loss: 0.00012 | Regression loss: 0.00050 | Running loss: 0.35808\n","Epoch: 2 | Iteration: 96 | Classification loss: 0.20375 | Regression loss: 0.26285 | Running loss: 0.35901\n","Epoch: 2 | Iteration: 97 | Classification loss: 0.53071 | Regression loss: 0.32772 | Running loss: 0.35989\n","Epoch: 2 | Iteration: 98 | Classification loss: 0.03221 | Regression loss: 0.08568 | Running loss: 0.36012\n","Epoch: 2 | Iteration: 99 | Classification loss: 0.00000 | Regression loss: 0.00016 | Running loss: 0.35922\n","Epoch: 2 | Iteration: 100 | Classification loss: 0.07236 | Regression loss: 0.05876 | Running loss: 0.35796\n","Epoch: 2 | Iteration: 101 | Classification loss: 0.21425 | Regression loss: 0.19040 | Running loss: 0.35806\n","Epoch: 2 | Iteration: 102 | Classification loss: 0.10533 | Regression loss: 0.08077 | Running loss: 0.35808\n","Epoch: 2 | Iteration: 103 | Classification loss: 0.05367 | Regression loss: 0.01914 | Running loss: 0.35812\n","Epoch: 2 | Iteration: 104 | Classification loss: 0.17494 | Regression loss: 0.31506 | Running loss: 0.35842\n","Epoch: 2 | Iteration: 105 | Classification loss: 0.23518 | Regression loss: 0.29321 | Running loss: 0.35852\n","Epoch: 2 | Iteration: 106 | Classification loss: 0.15727 | Regression loss: 0.11654 | Running loss: 0.35862\n","Epoch: 2 | Iteration: 107 | Classification loss: 0.00003 | Regression loss: 0.00023 | Running loss: 0.35763\n","Epoch: 2 | Iteration: 108 | Classification loss: 0.26598 | Regression loss: 0.10705 | Running loss: 0.35838\n","Epoch: 2 | Iteration: 109 | Classification loss: 0.00001 | Regression loss: 0.00037 | Running loss: 0.35798\n","Epoch: 2 | Iteration: 110 | Classification loss: 0.35587 | Regression loss: 0.24905 | Running loss: 0.35835\n","Epoch: 2 | Iteration: 111 | Classification loss: 0.00162 | Regression loss: 0.00000 | Running loss: 0.35835\n","Epoch: 2 | Iteration: 112 | Classification loss: 0.00000 | Regression loss: 0.00013 | Running loss: 0.35796\n","Epoch: 2 | Iteration: 113 | Classification loss: 0.05146 | Regression loss: 0.03252 | Running loss: 0.35698\n","Epoch: 2 | Iteration: 114 | Classification loss: 0.15925 | Regression loss: 0.05123 | Running loss: 0.35682\n","Epoch: 2 | Iteration: 115 | Classification loss: 0.19839 | Regression loss: 0.08145 | Running loss: 0.35625\n","Epoch: 2 | Iteration: 116 | Classification loss: 0.00000 | Regression loss: 0.00015 | Running loss: 0.35625\n","Epoch: 2 | Iteration: 117 | Classification loss: 0.31318 | Regression loss: 0.24512 | Running loss: 0.35681\n","Epoch: 2 | Iteration: 118 | Classification loss: 0.08715 | Regression loss: 0.07752 | Running loss: 0.35661\n","Epoch: 2 | Iteration: 119 | Classification loss: 0.20369 | Regression loss: 0.20715 | Running loss: 0.35663\n","Epoch: 2 | Iteration: 120 | Classification loss: 0.07368 | Regression loss: 0.10496 | Running loss: 0.35662\n","Epoch: 2 | Iteration: 121 | Classification loss: 0.09534 | Regression loss: 0.13650 | Running loss: 0.35627\n","Epoch: 2 | Iteration: 122 | Classification loss: 0.15762 | Regression loss: 0.16303 | Running loss: 0.35626\n","Epoch: 2 | Iteration: 123 | Classification loss: 0.46795 | Regression loss: 0.41538 | Running loss: 0.35688\n","Epoch: 2 | Iteration: 124 | Classification loss: 0.12177 | Regression loss: 0.06222 | Running loss: 0.35717\n","Epoch: 2 | Iteration: 125 | Classification loss: 0.19868 | Regression loss: 0.12348 | Running loss: 0.35761\n","Epoch: 2 | Iteration: 126 | Classification loss: 0.22497 | Regression loss: 0.17834 | Running loss: 0.35712\n","Epoch: 2 | Iteration: 127 | Classification loss: 0.10180 | Regression loss: 0.09661 | Running loss: 0.35608\n","Epoch: 2 | Iteration: 128 | Classification loss: 0.00431 | Regression loss: 0.00000 | Running loss: 0.35530\n","Epoch: 2 | Iteration: 129 | Classification loss: 0.21183 | Regression loss: 0.27778 | Running loss: 0.35503\n","Epoch: 2 | Iteration: 130 | Classification loss: 0.07899 | Regression loss: 0.12667 | Running loss: 0.35484\n","Epoch: 2 | Iteration: 131 | Classification loss: 0.22559 | Regression loss: 0.20071 | Running loss: 0.35539\n","Epoch: 2 | Iteration: 132 | Classification loss: 0.14035 | Regression loss: 0.13775 | Running loss: 0.35515\n","Epoch: 2 | Iteration: 133 | Classification loss: 0.15254 | Regression loss: 0.27863 | Running loss: 0.35495\n","Epoch: 2 | Iteration: 134 | Classification loss: 0.00012 | Regression loss: 0.00042 | Running loss: 0.35404\n","Epoch: 2 | Iteration: 135 | Classification loss: 0.14766 | Regression loss: 0.05955 | Running loss: 0.35413\n","Epoch: 2 | Iteration: 136 | Classification loss: 0.21615 | Regression loss: 0.06501 | Running loss: 0.35434\n","Epoch: 2 | Iteration: 137 | Classification loss: 0.16272 | Regression loss: 0.27797 | Running loss: 0.35416\n","Epoch: 2 | Iteration: 138 | Classification loss: 0.44472 | Regression loss: 0.16775 | Running loss: 0.35536\n","Epoch: 2 | Iteration: 139 | Classification loss: 0.00112 | Regression loss: 0.00000 | Running loss: 0.35464\n","Epoch: 2 | Iteration: 140 | Classification loss: 0.13886 | Regression loss: 0.15526 | Running loss: 0.35489\n","Epoch: 2 | Iteration: 141 | Classification loss: 0.18549 | Regression loss: 0.07967 | Running loss: 0.35505\n","Epoch: 2 | Iteration: 142 | Classification loss: 0.41994 | Regression loss: 0.31119 | Running loss: 0.35651\n","Epoch: 2 | Iteration: 143 | Classification loss: 0.17341 | Regression loss: 0.16633 | Running loss: 0.35580\n","Epoch: 2 | Iteration: 144 | Classification loss: 0.39892 | Regression loss: 0.27233 | Running loss: 0.35633\n","Epoch: 2 | Iteration: 145 | Classification loss: 0.31501 | Regression loss: 0.34427 | Running loss: 0.35604\n","Epoch: 2 | Iteration: 146 | Classification loss: 0.26384 | Regression loss: 0.23247 | Running loss: 0.35661\n","Epoch: 2 | Iteration: 147 | Classification loss: 0.16241 | Regression loss: 0.16398 | Running loss: 0.35706\n","Epoch: 2 | Iteration: 148 | Classification loss: 0.11951 | Regression loss: 0.16281 | Running loss: 0.35736\n","Epoch: 2 | Iteration: 149 | Classification loss: 0.44969 | Regression loss: 0.25104 | Running loss: 0.35765\n","Epoch: 2 | Iteration: 150 | Classification loss: 0.00002 | Regression loss: 0.00084 | Running loss: 0.35707\n","Epoch: 2 | Iteration: 151 | Classification loss: 0.04908 | Regression loss: 0.06827 | Running loss: 0.35730\n","Epoch: 2 | Iteration: 152 | Classification loss: 0.08651 | Regression loss: 0.07147 | Running loss: 0.35762\n","Epoch: 2 | Iteration: 153 | Classification loss: 0.03507 | Regression loss: 0.02513 | Running loss: 0.35761\n","Epoch: 2 | Iteration: 154 | Classification loss: 0.09235 | Regression loss: 0.07233 | Running loss: 0.35794\n","Epoch: 2 | Iteration: 155 | Classification loss: 0.16671 | Regression loss: 0.34258 | Running loss: 0.35810\n","Epoch: 2 | Iteration: 156 | Classification loss: 0.25351 | Regression loss: 0.16177 | Running loss: 0.35855\n","Epoch: 2 | Iteration: 157 | Classification loss: 0.23891 | Regression loss: 0.16675 | Running loss: 0.35861\n","Epoch: 2 | Iteration: 158 | Classification loss: 0.18386 | Regression loss: 0.16328 | Running loss: 0.35930\n","Epoch: 2 | Iteration: 159 | Classification loss: 0.14314 | Regression loss: 0.05721 | Running loss: 0.35970\n","Epoch: 2 | Iteration: 160 | Classification loss: 0.20863 | Regression loss: 0.16670 | Running loss: 0.35870\n","Epoch: 2 | Iteration: 161 | Classification loss: 0.25118 | Regression loss: 0.00000 | Running loss: 0.35845\n","Epoch: 2 | Iteration: 162 | Classification loss: 0.11104 | Regression loss: 0.13230 | Running loss: 0.35822\n","Epoch: 2 | Iteration: 163 | Classification loss: 0.28713 | Regression loss: 0.35388 | Running loss: 0.35950\n","Epoch: 2 | Iteration: 164 | Classification loss: 0.09055 | Regression loss: 0.22611 | Running loss: 0.35939\n","Epoch: 2 | Iteration: 165 | Classification loss: 0.00000 | Regression loss: 0.00050 | Running loss: 0.35832\n","Epoch: 2 | Iteration: 166 | Classification loss: 0.16729 | Regression loss: 0.11950 | Running loss: 0.35759\n","Epoch: 2 | Iteration: 167 | Classification loss: 0.23984 | Regression loss: 0.13852 | Running loss: 0.35834\n","Epoch: 2 | Iteration: 168 | Classification loss: 0.16735 | Regression loss: 0.06763 | Running loss: 0.35767\n","Epoch: 2 | Iteration: 169 | Classification loss: 0.14353 | Regression loss: 0.14470 | Running loss: 0.35688\n","Epoch: 2 | Iteration: 170 | Classification loss: 0.10798 | Regression loss: 0.02751 | Running loss: 0.35522\n","Epoch: 2 | Iteration: 171 | Classification loss: 0.09019 | Regression loss: 0.06926 | Running loss: 0.35507\n","Epoch: 2 | Iteration: 172 | Classification loss: 0.24425 | Regression loss: 0.19128 | Running loss: 0.35419\n","Epoch: 2 | Iteration: 173 | Classification loss: 0.00000 | Regression loss: 0.00026 | Running loss: 0.35382\n","Epoch: 2 | Iteration: 174 | Classification loss: 0.28462 | Regression loss: 0.21462 | Running loss: 0.35442\n","Epoch: 2 | Iteration: 175 | Classification loss: 0.18143 | Regression loss: 0.30644 | Running loss: 0.35380\n","Epoch: 2 | Iteration: 176 | Classification loss: 0.00000 | Regression loss: 0.00086 | Running loss: 0.35238\n","Epoch: 2 | Iteration: 177 | Classification loss: 0.25269 | Regression loss: 0.09250 | Running loss: 0.35307\n","Epoch: 2 | Iteration: 178 | Classification loss: 0.15384 | Regression loss: 0.13517 | Running loss: 0.35365\n","Epoch: 2 | Iteration: 179 | Classification loss: 0.18231 | Regression loss: 0.32042 | Running loss: 0.35326\n","Epoch: 2 | Iteration: 180 | Classification loss: 0.32021 | Regression loss: 0.19983 | Running loss: 0.35247\n","Epoch: 2 | Iteration: 181 | Classification loss: 0.11062 | Regression loss: 0.05879 | Running loss: 0.35152\n","Epoch: 2 | Iteration: 182 | Classification loss: 0.37610 | Regression loss: 0.26947 | Running loss: 0.35281\n","Epoch: 2 | Iteration: 183 | Classification loss: 0.09907 | Regression loss: 0.12807 | Running loss: 0.35128\n","Epoch: 2 | Iteration: 184 | Classification loss: 0.08011 | Regression loss: 0.28369 | Running loss: 0.35200\n","Epoch: 2 | Iteration: 185 | Classification loss: 0.18675 | Regression loss: 0.15914 | Running loss: 0.35220\n","Epoch: 2 | Iteration: 186 | Classification loss: 0.00000 | Regression loss: 0.00024 | Running loss: 0.35174\n","Epoch: 2 | Iteration: 187 | Classification loss: 0.29131 | Regression loss: 0.07436 | Running loss: 0.35160\n","Epoch: 2 | Iteration: 188 | Classification loss: 0.16981 | Regression loss: 0.13094 | Running loss: 0.35065\n","Epoch: 2 | Iteration: 189 | Classification loss: 0.15444 | Regression loss: 0.21338 | Running loss: 0.35078\n","Epoch: 2 | Iteration: 190 | Classification loss: 0.20067 | Regression loss: 0.15728 | Running loss: 0.35118\n","Epoch: 2 | Iteration: 191 | Classification loss: 0.03941 | Regression loss: 0.07130 | Running loss: 0.34986\n","Epoch: 2 | Iteration: 192 | Classification loss: 0.09638 | Regression loss: 0.04814 | Running loss: 0.34895\n","Epoch: 2 | Iteration: 193 | Classification loss: 0.23735 | Regression loss: 0.18527 | Running loss: 0.34950\n","Epoch: 2 | Iteration: 194 | Classification loss: 0.31789 | Regression loss: 0.19793 | Running loss: 0.35003\n","Epoch: 2 | Iteration: 195 | Classification loss: 0.02812 | Regression loss: 0.02053 | Running loss: 0.34911\n","Epoch: 2 | Iteration: 196 | Classification loss: 0.00000 | Regression loss: 0.00037 | Running loss: 0.34907\n","Epoch: 2 | Iteration: 197 | Classification loss: 0.24881 | Regression loss: 0.15022 | Running loss: 0.34963\n","Epoch: 2 | Iteration: 198 | Classification loss: 0.00001 | Regression loss: 0.00039 | Running loss: 0.34853\n","Epoch: 2 | Iteration: 199 | Classification loss: 0.48135 | Regression loss: 0.51788 | Running loss: 0.34976\n","Epoch: 2 | Iteration: 200 | Classification loss: 0.14002 | Regression loss: 0.12238 | Running loss: 0.35028\n","Epoch: 2 | Iteration: 201 | Classification loss: 0.12937 | Regression loss: 0.00000 | Running loss: 0.34956\n","Epoch: 2 | Iteration: 202 | Classification loss: 0.31146 | Regression loss: 0.27898 | Running loss: 0.34879\n","Epoch: 2 | Iteration: 203 | Classification loss: 0.29951 | Regression loss: 0.31083 | Running loss: 0.34975\n","Epoch: 2 | Iteration: 204 | Classification loss: 0.00021 | Regression loss: 0.00031 | Running loss: 0.34907\n","Epoch: 2 | Iteration: 205 | Classification loss: 0.56804 | Regression loss: 0.15301 | Running loss: 0.34914\n","Epoch: 2 | Iteration: 206 | Classification loss: 0.08657 | Regression loss: 0.00000 | Running loss: 0.34844\n","Epoch: 2 | Iteration: 207 | Classification loss: 0.12764 | Regression loss: 0.18048 | Running loss: 0.34905\n","Epoch: 2 | Iteration: 208 | Classification loss: 0.21915 | Regression loss: 0.30197 | Running loss: 0.34954\n","Epoch: 2 | Iteration: 209 | Classification loss: 0.23334 | Regression loss: 0.27923 | Running loss: 0.34995\n","Epoch: 2 | Iteration: 210 | Classification loss: 0.07508 | Regression loss: 0.12894 | Running loss: 0.35035\n","Epoch: 2 | Iteration: 211 | Classification loss: 0.33325 | Regression loss: 0.21879 | Running loss: 0.34994\n","Epoch: 2 | Iteration: 212 | Classification loss: 0.31628 | Regression loss: 0.07545 | Running loss: 0.35010\n","Epoch: 2 | Iteration: 213 | Classification loss: 0.08036 | Regression loss: 0.12289 | Running loss: 0.34958\n","Epoch: 2 | Iteration: 214 | Classification loss: 0.31433 | Regression loss: 0.30234 | Running loss: 0.34966\n","Epoch: 2 | Iteration: 215 | Classification loss: 0.28741 | Regression loss: 0.11181 | Running loss: 0.34747\n","Epoch: 2 | Iteration: 216 | Classification loss: 0.00002 | Regression loss: 0.00046 | Running loss: 0.34658\n","Epoch: 2 | Iteration: 217 | Classification loss: 0.03855 | Regression loss: 0.07402 | Running loss: 0.34576\n","Epoch: 2 | Iteration: 218 | Classification loss: 0.24492 | Regression loss: 0.26929 | Running loss: 0.34645\n","Epoch: 2 | Iteration: 219 | Classification loss: 0.00005 | Regression loss: 0.00066 | Running loss: 0.34605\n","Epoch: 2 | Iteration: 220 | Classification loss: 0.34906 | Regression loss: 0.25625 | Running loss: 0.34726\n","Epoch: 2 | Iteration: 221 | Classification loss: 0.38616 | Regression loss: 0.42357 | Running loss: 0.34888\n","Epoch: 2 | Iteration: 222 | Classification loss: 0.24132 | Regression loss: 0.21759 | Running loss: 0.34979\n","Epoch: 2 | Iteration: 223 | Classification loss: 0.34868 | Regression loss: 0.20597 | Running loss: 0.34963\n","Epoch: 2 | Iteration: 224 | Classification loss: 0.18236 | Regression loss: 0.12280 | Running loss: 0.34947\n","Epoch: 2 | Iteration: 225 | Classification loss: 0.20968 | Regression loss: 0.09243 | Running loss: 0.34812\n","Epoch: 2 | Iteration: 226 | Classification loss: 0.25822 | Regression loss: 0.06708 | Running loss: 0.34851\n","Epoch: 2 | Iteration: 227 | Classification loss: 0.09787 | Regression loss: 0.06046 | Running loss: 0.34825\n","Epoch: 2 | Iteration: 228 | Classification loss: 0.20949 | Regression loss: 0.19751 | Running loss: 0.34765\n","Epoch: 2 | Iteration: 229 | Classification loss: 0.12271 | Regression loss: 0.18255 | Running loss: 0.34699\n","Epoch: 2 | Iteration: 230 | Classification loss: 0.21436 | Regression loss: 0.18247 | Running loss: 0.34718\n","Epoch: 2 | Iteration: 231 | Classification loss: 0.27735 | Regression loss: 0.33263 | Running loss: 0.34704\n","Epoch: 2 | Iteration: 232 | Classification loss: 0.00000 | Regression loss: 0.00032 | Running loss: 0.34629\n","Epoch: 2 | Iteration: 233 | Classification loss: 0.14958 | Regression loss: 0.22899 | Running loss: 0.34643\n","Epoch: 2 | Iteration: 234 | Classification loss: 0.38701 | Regression loss: 0.36215 | Running loss: 0.34748\n","Epoch: 2 | Iteration: 235 | Classification loss: 0.13807 | Regression loss: 0.26626 | Running loss: 0.34676\n","Epoch: 2 | Iteration: 236 | Classification loss: 0.05488 | Regression loss: 0.06369 | Running loss: 0.34603\n","Epoch: 2 | Iteration: 237 | Classification loss: 0.00000 | Regression loss: 0.00018 | Running loss: 0.34603\n","Epoch: 2 | Iteration: 238 | Classification loss: 0.32864 | Regression loss: 0.29643 | Running loss: 0.34654\n","Epoch: 2 | Iteration: 239 | Classification loss: 0.19429 | Regression loss: 0.39438 | Running loss: 0.34729\n","Epoch: 2 | Iteration: 240 | Classification loss: 0.14644 | Regression loss: 0.15499 | Running loss: 0.34745\n","Epoch: 2 | Iteration: 241 | Classification loss: 0.13756 | Regression loss: 0.13542 | Running loss: 0.34600\n","Epoch: 2 | Iteration: 242 | Classification loss: 0.15269 | Regression loss: 0.03938 | Running loss: 0.34562\n","Epoch: 2 | Iteration: 243 | Classification loss: 0.09913 | Regression loss: 0.04598 | Running loss: 0.34548\n","Epoch: 2 | Iteration: 244 | Classification loss: 0.00280 | Regression loss: 0.00000 | Running loss: 0.34311\n","Epoch: 2 | Iteration: 245 | Classification loss: 0.26132 | Regression loss: 0.35519 | Running loss: 0.34408\n","Epoch: 2 | Iteration: 246 | Classification loss: 0.16093 | Regression loss: 0.08990 | Running loss: 0.34348\n","Epoch: 2 | Iteration: 247 | Classification loss: 0.21024 | Regression loss: 0.14755 | Running loss: 0.34351\n","Epoch: 2 | Iteration: 248 | Classification loss: 0.20061 | Regression loss: 0.15935 | Running loss: 0.34385\n","Epoch: 2 | Iteration: 249 | Classification loss: 0.12063 | Regression loss: 0.21567 | Running loss: 0.34359\n","Epoch: 2 | Iteration: 250 | Classification loss: 0.12360 | Regression loss: 0.02820 | Running loss: 0.34253\n","Epoch: 2 | Iteration: 251 | Classification loss: 0.37691 | Regression loss: 0.20245 | Running loss: 0.34313\n","Epoch: 2 | Iteration: 252 | Classification loss: 0.12377 | Regression loss: 0.18797 | Running loss: 0.34346\n","Epoch: 2 | Iteration: 253 | Classification loss: 0.00000 | Regression loss: 0.00031 | Running loss: 0.34346\n","Epoch: 2 | Iteration: 254 | Classification loss: 0.16228 | Regression loss: 0.17414 | Running loss: 0.34309\n","Epoch: 2 | Iteration: 255 | Classification loss: 0.18905 | Regression loss: 0.13214 | Running loss: 0.34269\n","Epoch: 2 | Iteration: 256 | Classification loss: 0.12807 | Regression loss: 0.05920 | Running loss: 0.34277\n","Epoch: 2 | Iteration: 257 | Classification loss: 0.21884 | Regression loss: 0.14117 | Running loss: 0.34067\n","Epoch: 2 | Iteration: 258 | Classification loss: 0.20245 | Regression loss: 0.05899 | Running loss: 0.34049\n","Epoch: 2 | Iteration: 259 | Classification loss: 0.20132 | Regression loss: 0.44469 | Running loss: 0.33964\n","Epoch: 2 | Iteration: 260 | Classification loss: 0.12598 | Regression loss: 0.16709 | Running loss: 0.33852\n","Epoch: 2 | Iteration: 261 | Classification loss: 0.24364 | Regression loss: 0.31156 | Running loss: 0.33814\n","Epoch: 2 | Iteration: 262 | Classification loss: 0.08681 | Regression loss: 0.04013 | Running loss: 0.33639\n","Epoch: 2 | Iteration: 263 | Classification loss: 0.21448 | Regression loss: 0.13028 | Running loss: 0.33600\n","Epoch: 2 | Iteration: 264 | Classification loss: 0.06076 | Regression loss: 0.12986 | Running loss: 0.33606\n","Epoch: 2 | Iteration: 265 | Classification loss: 0.12624 | Regression loss: 0.09568 | Running loss: 0.33608\n","Epoch: 2 | Iteration: 266 | Classification loss: 0.11961 | Regression loss: 0.05603 | Running loss: 0.33572\n","Epoch: 2 | Iteration: 267 | Classification loss: 0.40933 | Regression loss: 0.16955 | Running loss: 0.33520\n","Epoch: 2 | Iteration: 268 | Classification loss: 0.46251 | Regression loss: 0.40394 | Running loss: 0.33623\n","Epoch: 2 | Iteration: 269 | Classification loss: 0.43748 | Regression loss: 0.33317 | Running loss: 0.33721\n","Epoch: 2 | Iteration: 270 | Classification loss: 0.31051 | Regression loss: 0.10407 | Running loss: 0.33761\n","Epoch: 2 | Iteration: 271 | Classification loss: 0.11959 | Regression loss: 0.10451 | Running loss: 0.33781\n","Epoch: 2 | Iteration: 272 | Classification loss: 0.00000 | Regression loss: 0.00020 | Running loss: 0.33748\n","Epoch: 2 | Iteration: 273 | Classification loss: 0.08301 | Regression loss: 0.14899 | Running loss: 0.33720\n","Epoch: 2 | Iteration: 274 | Classification loss: 0.06773 | Regression loss: 0.05155 | Running loss: 0.33708\n","Epoch: 2 | Iteration: 275 | Classification loss: 0.26863 | Regression loss: 0.24873 | Running loss: 0.33749\n","Epoch: 2 | Iteration: 276 | Classification loss: 0.25475 | Regression loss: 0.19061 | Running loss: 0.33809\n","Epoch: 2 | Iteration: 277 | Classification loss: 0.36338 | Regression loss: 0.11919 | Running loss: 0.33905\n","Epoch: 2 | Iteration: 278 | Classification loss: 0.61887 | Regression loss: 0.50818 | Running loss: 0.34051\n","Epoch: 2 | Iteration: 279 | Classification loss: 0.00028 | Regression loss: 0.00095 | Running loss: 0.34005\n","Epoch: 2 | Iteration: 280 | Classification loss: 0.10152 | Regression loss: 0.22246 | Running loss: 0.34069\n","Epoch: 2 | Iteration: 281 | Classification loss: 0.00000 | Regression loss: 0.00093 | Running loss: 0.33985\n","Epoch: 2 | Iteration: 282 | Classification loss: 0.23838 | Regression loss: 0.22025 | Running loss: 0.33952\n","Epoch: 2 | Iteration: 283 | Classification loss: 0.12501 | Regression loss: 0.18058 | Running loss: 0.33957\n","Epoch: 2 | Iteration: 284 | Classification loss: 0.00000 | Regression loss: 0.00021 | Running loss: 0.33896\n","Epoch: 2 | Iteration: 285 | Classification loss: 0.22422 | Regression loss: 0.21185 | Running loss: 0.33983\n","Epoch: 2 | Iteration: 286 | Classification loss: 0.00000 | Regression loss: 0.00015 | Running loss: 0.33983\n","Epoch: 2 | Iteration: 287 | Classification loss: 0.19137 | Regression loss: 0.24340 | Running loss: 0.33908\n","Epoch: 2 | Iteration: 288 | Classification loss: 0.05564 | Regression loss: 0.00000 | Running loss: 0.33813\n","Epoch: 2 | Iteration: 289 | Classification loss: 0.46849 | Regression loss: 0.14598 | Running loss: 0.33856\n","Epoch: 2 | Iteration: 290 | Classification loss: 0.15168 | Regression loss: 0.06210 | Running loss: 0.33846\n","Epoch: 2 | Iteration: 291 | Classification loss: 0.18312 | Regression loss: 0.28321 | Running loss: 0.33939\n","Epoch: 2 | Iteration: 292 | Classification loss: 0.00000 | Regression loss: 0.00018 | Running loss: 0.33794\n","Epoch: 2 | Iteration: 293 | Classification loss: 0.23804 | Regression loss: 0.29385 | Running loss: 0.33837\n","Epoch: 2 | Iteration: 294 | Classification loss: 0.08893 | Regression loss: 0.10185 | Running loss: 0.33750\n","Epoch: 2 | Iteration: 295 | Classification loss: 0.12552 | Regression loss: 0.14479 | Running loss: 0.33705\n","Epoch: 2 | Iteration: 296 | Classification loss: 0.17586 | Regression loss: 0.05237 | Running loss: 0.33739\n","Epoch: 2 | Iteration: 297 | Classification loss: 0.28787 | Regression loss: 0.30865 | Running loss: 0.33816\n","Epoch: 2 | Iteration: 298 | Classification loss: 0.05496 | Regression loss: 0.16223 | Running loss: 0.33784\n","Epoch: 2 | Iteration: 299 | Classification loss: 0.26289 | Regression loss: 0.10437 | Running loss: 0.33858\n","Epoch: 2 | Iteration: 300 | Classification loss: 0.13710 | Regression loss: 0.11444 | Running loss: 0.33829\n","Epoch: 2 | Iteration: 301 | Classification loss: 0.18487 | Regression loss: 0.10861 | Running loss: 0.33807\n","Epoch: 2 | Iteration: 302 | Classification loss: 0.26934 | Regression loss: 0.31024 | Running loss: 0.33827\n","Epoch: 2 | Iteration: 303 | Classification loss: 0.11032 | Regression loss: 0.14791 | Running loss: 0.33795\n","Epoch: 2 | Iteration: 304 | Classification loss: 0.10241 | Regression loss: 0.21492 | Running loss: 0.33819\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"389e5GE18aMx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
